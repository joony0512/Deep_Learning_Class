# Image Classification 성능 개선 방법

## For Better Performances (Single Model가정)

### Better Network Architecture
- Use better model - ex) ImageNet SOTA
- More layers
- More channels
- Bigger resolutions
- Use better activation function - ex)swish
- Use additional architecture = ex)skip connection, SE - module

### Training Tricks
- Bag of Tricks for Image Classification (Bag of Tricks for Image Classification with Convolutional Neural Networks - AWS 논문 기반)
    - Efficient Training
        - Linear scaling learning rate : 배치사이즈 키운만큼 learning rate scaling
          
        - Learning rate warmup : 초반 learning rate 선형으로 크게 만들기
        - Zero gamma in batchnorm : BatchNormalization에서 gamma를 0으로 초기화 한 후 학습
        - No bias decay : L1, L2 Regulization을 bias에 적용하지 않는 것
        - Low - precision training : Floating point를 낮추기
          
    - Training Refinements
        - Cosine Leaning Rate Decay : warmup으로 키운 leaning rate를 cosine을 사용해 낮추는것
        - Label Smoothing : 원핫인코딩으로 레이블링 하지 말고 확률로 주는것(정답 클래스에는 큰 확률부여, 나머지에는 나머지 확률/k-1)
        - Knowledge Distillation : Teacher model이 hard label로 학습한 것을 Student Model받아서 확률을 배우기
        - Mixup Training : data augmentation방법중 하나
          
          <img width="533" alt="스크린샷 2023-12-06 오후 5 40 38" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/0ac1c00a-ff6c-48be-bbf8-2b633512a99f">

            
        - 논문에 소개된 방법은 아니지만 Naver 에서 소개한 CutMix 방법도 있다.

          <img width="476" alt="스크린샷 2023-12-06 오후 5 41 26" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a29cebdf-f357-4f88-8de1-dccad11ec168">
