{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0UmimuF41qo8f/rccEbYY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joony0512/Deep_Learning_Class/blob/main/Part2/P2_Ch01_CH04_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4-4: Sparse Categorical Cross Entropy\n"
      ],
      "metadata": {
        "id": "9B5wS4Kidh35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.4-4-1 : SCCE Calculation\n"
      ],
      "metadata": {
        "id": "QbIGhYHEdtIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "batch_size , n_class = 16, 5\n",
        "predictions = tf.random.uniform(shape = (batch_size, n_class),\n",
        "                                minval = 0, maxval=1,\n",
        "                                dtype=tf.float32)\n",
        "print(\"predictions : \", predictions)\n",
        "\n",
        "# 값을 행별로 다 더한 후 벡터로 변환\n",
        "pred_sum = tf.reshape(tf.reduce_sum(predictions, axis = 1), (-1,1))\n",
        "print(\"pred_sum : \", pred_sum)\n",
        "print(predictions.shape , pred_sum.shape)\n",
        "\n",
        "# prediction 을 다 더한값이 1이 될 수 있도록 변환=> 확률로 변경\n",
        "predictions = predictions/pred_sum\n",
        "\n",
        "print(\"predictions2 : \", predictions)\n",
        "print(\"pred_sum2: \",tf.reshape(tf.reduce_sum(predictions, axis = 1), (-1,1)))\n",
        "\n",
        "\n",
        "labels =tf.random.uniform(shape = (batch_size, ),\n",
        "                          minval = 0, maxval = n_class,\n",
        "                          dtype = tf.int32)\n",
        "\n",
        "print(\"labels: \",labels)\n",
        "\n",
        "loss_object = SparseCategoricalCrossentropy()\n",
        "loss = loss_object(labels, predictions)\n",
        "\n",
        "print(\"loss.numpy: \",loss.numpy())\n",
        "\n",
        "ce = 0\n",
        "for label , prediction in zip(labels, predictions):\n",
        "  print(\"shape\",label.shape, prediction.shape)\n",
        "  #print(label, prediction)\n",
        "  ce += -tf.math.log(prediction[label])\n",
        "ce /= batch_size\n",
        "print( \"ce: \",ce.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgzgOsvAdsEw",
        "outputId": "0551e100-72fd-4724-fae1-862d35f90721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions :  tf.Tensor(\n",
            "[[0.42568803 0.32714844 0.91588485 0.05151379 0.9393418 ]\n",
            " [0.1574285  0.9960433  0.79969513 0.9739343  0.72395194]\n",
            " [0.02427709 0.84835637 0.670138   0.02948737 0.49010515]\n",
            " [0.9394232  0.90196395 0.9452262  0.893072   0.68453276]\n",
            " [0.03382611 0.3966614  0.7024518  0.28857708 0.29094207]\n",
            " [0.9338347  0.9852246  0.27546763 0.97891796 0.5580362 ]\n",
            " [0.7454498  0.71737576 0.45415258 0.4636401  0.8068634 ]\n",
            " [0.45147884 0.87907887 0.9191135  0.32191002 0.77791953]\n",
            " [0.4892075  0.6956248  0.7345369  0.19673014 0.8999753 ]\n",
            " [0.6701274  0.54268897 0.40777183 0.8113576  0.29146016]\n",
            " [0.5256175  0.4269997  0.9489784  0.46959722 0.882185  ]\n",
            " [0.7588899  0.5227231  0.09287179 0.9341757  0.6080345 ]\n",
            " [0.61274314 0.8024304  0.11401749 0.74587333 0.94734967]\n",
            " [0.5799694  0.26895225 0.13650501 0.2935493  0.50907004]\n",
            " [0.68036187 0.90032864 0.91722727 0.675143   0.45681584]\n",
            " [0.0225141  0.8268155  0.6206163  0.5008825  0.86985004]], shape=(16, 5), dtype=float32)\n",
            "pred_sum :  tf.Tensor(\n",
            "[[2.659577 ]\n",
            " [3.651053 ]\n",
            " [2.062364 ]\n",
            " [4.364218 ]\n",
            " [1.7124585]\n",
            " [3.731481 ]\n",
            " [3.1874814]\n",
            " [3.349501 ]\n",
            " [3.0160747]\n",
            " [2.7234058]\n",
            " [3.253378 ]\n",
            " [2.916695 ]\n",
            " [3.222414 ]\n",
            " [1.788046 ]\n",
            " [3.6298766]\n",
            " [2.8406785]], shape=(16, 1), dtype=float32)\n",
            "(16, 5) (16, 1)\n",
            "predictions2 :  tf.Tensor(\n",
            "[[0.16005856 0.1230077  0.3443724  0.01936917 0.35319218]\n",
            " [0.04311866 0.2728099  0.21903136 0.26675436 0.19828579]\n",
            " [0.01177149 0.4113514  0.3249368  0.01429785 0.23764239]\n",
            " [0.21525578 0.20667252 0.21658546 0.20463505 0.15685117]\n",
            " [0.01975295 0.23163271 0.41020077 0.16851625 0.1698973 ]\n",
            " [0.25025845 0.26403046 0.0738226  0.26234034 0.14954819]\n",
            " [0.23386796 0.22506037 0.14248008 0.14545657 0.25313511]\n",
            " [0.13478988 0.2624507  0.27440313 0.09610686 0.2322494 ]\n",
            " [0.16220006 0.23063913 0.24354069 0.06522721 0.29839292]\n",
            " [0.24606226 0.19926849 0.14972863 0.2979202  0.10702047]\n",
            " [0.16156054 0.1312481  0.2916902  0.14434142 0.2711597 ]\n",
            " [0.26018828 0.17921759 0.03184145 0.3202857  0.20846693]\n",
            " [0.19015035 0.2490153  0.03538263 0.23146415 0.29398757]\n",
            " [0.32435933 0.15041685 0.07634312 0.16417323 0.28470746]\n",
            " [0.18743388 0.24803285 0.2526883  0.18599613 0.12584886]\n",
            " [0.00792561 0.29106268 0.21847469 0.17632496 0.30621207]], shape=(16, 5), dtype=float32)\n",
            "pred_sum2:  tf.Tensor(\n",
            "[[1.        ]\n",
            " [1.0000001 ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.0000001 ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.0000001 ]\n",
            " [1.        ]\n",
            " [0.99999994]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]], shape=(16, 1), dtype=float32)\n",
            "labels:  tf.Tensor([4 3 3 0 4 2 0 4 2 2 2 0 2 0 2 0], shape=(16,), dtype=int32)\n",
            "loss.numpy:  2.0004902\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "shape () (5,)\n",
            "ce:  2.0004904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.4-4-2: SCCE with Model/Dataset"
      ],
      "metadata": {
        "id": "DmXCKPE-lEc-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIBz0e-scE7p",
        "outputId": "f45198b6-71b9-47c3-f003-64eb7151a274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 5) (16, 1)\n",
            "1.1347625\n",
            "(16, 5) (16, 1)\n",
            "1.1967789\n",
            "(16, 5) (16, 1)\n",
            "1.0487036\n",
            "(16, 5) (16, 1)\n",
            "1.1925272\n",
            "(16, 5) (16, 1)\n",
            "1.3015285\n",
            "(16, 5) (16, 1)\n",
            "1.1203533\n",
            "(16, 5) (16, 1)\n",
            "6.0102634\n",
            "(16, 5) (16, 1)\n",
            "7.9720635\n",
            "(16, 5) (16, 1)\n",
            "7.785532\n",
            "(16, 5) (16, 1)\n",
            "7.621608\n",
            "(16, 5) (16, 1)\n",
            "7.720002\n",
            "(16, 5) (16, 1)\n",
            "7.3854294\n",
            "(16, 5) (16, 1)\n",
            "6.4874597\n",
            "(16, 5) (16, 1)\n",
            "5.222967\n",
            "(16, 5) (16, 1)\n",
            "5.3369675\n",
            "(16, 5) (16, 1)\n",
            "5.093541\n",
            "(16, 5) (16, 1)\n",
            "5.0721045\n",
            "(16, 5) (16, 1)\n",
            "5.707243\n",
            "(16, 5) (16, 1)\n",
            "6.5345\n",
            "(16, 5) (16, 1)\n",
            "9.998117\n",
            "(16, 5) (16, 1)\n",
            "9.58814\n",
            "(16, 5) (16, 1)\n",
            "9.091463\n",
            "(16, 5) (16, 1)\n",
            "9.869771\n",
            "(16, 5) (16, 1)\n",
            "9.074441\n",
            "(16, 5) (16, 1)\n",
            "10.288221\n",
            "(16, 5) (16, 1)\n",
            "7.7045755\n",
            "(16, 5) (16, 1)\n",
            "7.5879765\n",
            "(16, 5) (16, 1)\n",
            "7.5715384\n",
            "(16, 5) (16, 1)\n",
            "7.649438\n",
            "(16, 5) (16, 1)\n",
            "7.503613\n",
            "(16, 5) (16, 1)\n",
            "7.6821804\n",
            "(4, 5) (4, 1)\n",
            "7.6203623\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "\n",
        "N, n_feature = 100, 2\n",
        "n_class = 5\n",
        "batch_size = 16\n",
        "\n",
        "X = tf.zeros(shape = (0, n_feature))\n",
        "Y = tf.zeros(shape = (0,1), dtype = tf.int32)\n",
        "\n",
        "for class_idx in range(n_class):\n",
        "  center = tf.random.uniform(minval = -15, maxval = 15, shape = (2,))\n",
        "\n",
        "  x1 = center[0] + tf.random.normal(shape=(N,1))\n",
        "  x2 = center[1] + tf.random.normal(shape =(N,1))\n",
        "\n",
        "  x= tf.concat((x1, x2), axis = 1)\n",
        "  y= class_idx*tf.ones(shape=(N,1), dtype = tf.int32)\n",
        "\n",
        "  X = tf.concat((X, x), axis = 0)\n",
        "  Y = tf.concat((Y, y ), axis = 0)\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "model = Dense(units= n_class , activation = 'softmax')\n",
        "loss_object = SparseCategoricalCrossentropy()\n",
        "\n",
        "for x, y in dataset:\n",
        "  predictions = model(x)\n",
        "  print(predictions.shape, y.shape)\n",
        "  loss = loss_object(y, predictions)\n",
        "  print(loss.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4-5 : Categorical Cross Entropy"
      ],
      "metadata": {
        "id": "a1BFqrli1iQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.4-5-1 :CCE Calculation\n"
      ],
      "metadata": {
        "id": "Q25WLJcs1o5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "batchsize, n_class = 16, 5\n",
        "predictions = tf.random.uniform(shape = (batch_size, n_class), \n",
        "                                minval=0, maxval=1,\n",
        "                                dtype=tf.float32)\n",
        "pred_sum = tf.reshape(tf.reduce_sum(predictions, axis =1), (-1,1))\n",
        "predictions = predictions/pred_sum\n",
        "\n",
        "labels = tf.random.uniform(shape=(batch_size, ), \n",
        "                           minval = 0, maxval = n_class,\n",
        "                           dtype = tf.int32)\n",
        "labels = tf.one_hot(labels, n_class)\n",
        "print(labels)\n",
        "\n",
        "loss_object = CategoricalCrossentropy()\n",
        "loss = loss_object(labels, predictions)\n",
        "\n",
        "print(\"CCE(Tensorflow): \", loss.numpy())\n",
        "\n",
        "cce_man =tf.reduce_mean(tf.reduce_sum(-labels*tf.math.log(predictions), axis = 1))\n",
        "print(\"CCE(Manual): \", cce_man.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFv3d0kEdhmd",
        "outputId": "d85a15f2-45e9-4efb-9133-f7a1a5bc2a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]], shape=(16, 5), dtype=float32)\n",
            "CCE(Tensorflow):  2.3423333\n",
            "CCE(Manual):  2.3423333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code.4-5-2: CCE with Model/Dataset"
      ],
      "metadata": {
        "id": "WzqnBeg934PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "N, n_feature = 8, 2\n",
        "n_class = 5\n",
        "\n",
        "X = tf.zeros(shape = (0, n_feature))\n",
        "Y = tf.zeros(shape=(0,), dtype = tf.int32)\n",
        "\n",
        "for class_idx in range(n_class):\n",
        "  center = tf.random.uniform(minval = -15, maxval = 15, shape = (2,))\n",
        "  \n",
        "  x1 = center[0] + tf.random.normal(shape=(N,1))\n",
        "  x2 = center[1] + tf.random.normal(shape=(N,1))\n",
        "\n",
        "  x = tf.concat((x1, x2), axis = 1)\n",
        "  y = class_idx*tf.ones(shape=(N,), dtype=tf.int32)\n",
        "\n",
        "  X = tf.concat((X,x), axis = 0)\n",
        "  Y = tf.concat((Y,y), axis = 0)\n",
        "\n",
        "Y = tf.one_hot(Y, depth= n_class, dtype = tf.int32)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "model = Dense(units = n_class , activation= 'softmax')\n",
        "loss_object = CategoricalCrossentropy()\n",
        "\n",
        "for x, y in dataset:\n",
        "  predictions = model(x)\n",
        "  loss = loss_object(y, predictions)\n",
        "  print(loss.numpy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiUwU9Fa2oaS",
        "outputId": "1d12a53f-6559-44b6-e058-a95e4ad7128e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.027198583\n",
            "13.437323\n",
            "13.907813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pm6Llx0o86BS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}