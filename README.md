># Deep_Learning_Class
>>INTRO
### Chapter 01. 딥러닝 소개	
### Chapter 02. 딥러닝의 원리	
### Chapter 03. 딥러닝 공부법
>>Part 1
### Ch 01. 환경설정
### Ch 02. 데이터 타입과 컬렉션
### Ch 03. 조건문과 반복문
### Ch 04. 함수 이해 및 활용
### Ch 05. 파이썬 모듈
### Ch 06. 클래스와 인스턴스
### Ch 07. 정규 표현식
>>Part 2
## Ch 01. 딥러닝 네트워크의 연산
	- CH00_01. Introduction
	- CH00_02. CoLaboratory
### Lecture.1 Artificial Neuron
	- CH01_01. [이론]Parameteric Functions and Datasets
	- CH01_02. [이론]Artificial_Neurons
	- CH01_03. [구현]Affine_Functions
	- CH01_04. [구현]Artificial_Neurons
### Lecture.2 Dense Layers
	- CH02_01. [이론]_Dense_Layers
	- CH02_02. [이론]_The_First_Dense_Layer.
	- CH02_03. [이론]_The_Second_Dense_Layer.
	- CH02_04. [이론]_Minibatches_in_Dense_Layer.
	- CH02_05. [구현]_Dense_Layers
	- CH02_06. [구현]_Cascaded_Dense_Layers
	- CH02_07. [구현]_Model_Implementation_with_Dense_Layers
### Lecture.3 Sigmoid and Softmax
	- CH03_01. [이론]_Logit_and_Sigmoid
	- CH03_02. [이론]_Softmas_Layer
	- CH03_03. [구현]_Binary_Classifiers
	- CH03_04. [구현]_Multiclass_Classifiers
### Lecture.4 Loss Function
	- CH04_01. [이론]_Mean_Squared_Error
	- CH04_02. [이론]_Binary_Cross_Entropy
	- CH04_03. [이론]_Categorical_Cross_Entropy
	- CH04_04. [구현]_Toy_Datasets_for_Regression_and_Binary_Classification
	- CH04_05. [구현]_Toy_Datasets_for_Multiclass_Classification
### Lecture.5 Convolutional Layers
	- CH05_01. [이론]_image_Tensors_and_Classical_Correlation.
	- CH05_02. [이론]_Computations_of_Conv_Layers.
	- CH05_03. [이론]_Conv_Layers_for_Multichannel_Input
	- CH05_04. [구현]_Conv2D_Layers
	- CH05_05. [구현]_Conv2D_with_Filters
	- CH05_06. [구현]_Model_Implementation_with_Conv2D_Layers
### Lecture.6 Padding Layers
	- CH06_01. [이론]_Pooling_Layers
	- CH06_02. [구현]_Max_and_Average_Pooling_Layers
	- CH06_03. [구현]_Padding_and_Strides
### Lecture.7 Convolutional Neural Network
	- CH07_01. [이론]_Convolutional Neural Network
	- CH07_02. [구현]_Shapes_in_CNNs.
	- CH07_03. [구현]_CNN_Implementation
	- CH07_04. [구현]_LeNet_Implementation
	
	
## Ch.02 Jacobian Matrix와 Backpropagation

### Lecture.0 Orientation
	- CH00_01. Orientation
### Lecture.1 Why Bacpropagation and Jacobians?
	- CH01_01. Trainable_Variables_and_Gradients
	- CH01_02. Gradient-based_Learning_Implementation
	- CH01_03. Backpropagation
	- CH01_04. Why_Jacobian_Matrices
### Lecture.2 Basic Differentiation
	- CH02_01. Rate_of_Changes
	- CH02_02. Differentiation_and_Derivatives
	- CH02_03.Diff_of_Constant_and_Power_Functions
	- CH02_04. Diff_of_Log_and_Exp_Functions
	- CH02_05. Diff_of_Trigonometric_and_Piece-wise_Defined_Functions
	- CH02_06. Constant_Multiplie_and_Sum_Rules
	- CH02_07. LTI_System_and_Differentiation
	- CH02_08. Product_and_Quotient_Rules
	- CH02_09. Composite_Functions_and_Chain_Rule
	- CH02_10.Backpropagation_Modules
### Lecture.3 Multivariate Functions and Jacobians
	- CH03_01.Multivariate_Functions
	- CH03_02.Partial_Derivatives_and_Parameter_Updates
	- CH03_03.Partial_Derivatives_and_Gradients
	- CH03_04.Gradient_and_Parameter_Update
	- CH03_05.Jacobians_of_Affine_Functions
	- CH03_06.Artificial_Neuron_and_Backpropagation
	- CH03_07.Jacobians_of_Minibatches
	- CH03_08.Jacobians_of_MSE_and_BCEE
	- CH03_09.Jacobians_of_CCEE
	- CH03_10.Jacobians_of_Softmax
### Lecture.4 Linear and Logistic Regression1
	- CH04_01.Linear_Regression_(Theory)
	- CH04_02.Linear_Regression_(Implementation, 1 Feature)
	- CH04_03.Linear_Regression_(Implementation, N Feature)
	- CH04_04.Logistic_Regression_(Theory)_and_Sigmoids_Params
	- CH04_05.Properties_of_Logistic_Regression
	- CH04_06.Logistic_Regression_(Implementation, 1 Feature)
	- CH04_07.Logistic_Regression_(Implementation, n Feature)
### Lecture.5 Vector Functions and Jacobians

	- CH05_01.Vector_Functions
	- CH05_02.Jacobians_of_Vector_Functions
	- CH05_03.Affine_Functions_as_a_Vector_Function1
	- CH05_04.Affine_Functions_as_a_Vector_Function2
	- CH05_05.Jacobians_of_Softmax
### Lecture.6 Element-Wise Operations and Jacobians
	- CH06_01.Diagonal_Matrices
	- CH06_02.Unary_Element-wise_Operations
	- CH06_03.Jacobians_of_Activation_Functions
	- CH06_04.Backpropagation_within_Dense_Layers
	- CH06_05.Artificial_Neuron_and_Mini-batches
	- CH06_06.Binary_Element-wise_Operations
	- CH06_07.Backpropagation_within_Loss_Functions
### Lecture.7 Linear and Logistic Regression2
	- CH07_01.Linear_Regression_with_Mini-batches_Theory
	- CH07_02.Linear_Regression_with_Mini-batches_Implementation
	- CH07_03.Logistic_Regression_with_Mini-batches

### Lecture.8 Total Derivatives
	- CH08_01.Multipath_of_Functions
	- CH08_02.Total_Derivatives1
	- CH08_03.Total_Derivatives2
	- CH08_04.Vector_Functions_and_Total_Derivative
	- CH08_05.Linear_Logistics_Regression_and_Total_Derivatives
 

### Lecture.9 Expansion of Jacobians

	- CH09_01.Introduction_to_Expanded_Jacobians
	- CH09_02.Keypoints_to_Expanded_Jacobians
	- CH09_03.Unary_Element-wise_Operations_and_Expanded_Jacobians 
	- CH09_04.Binary_Element-wise_Operations_and_Expanded_Jacobians
  
### Lecture.10 Expanded Jacobians in Deep Learning

	- CH10_01.MSE_BCEE_and_Expanded_Jacobians
	- CH10_02.CCEE_and_Expanded_Jacobians
	- CH10_03.Softmax_and_Expanded_Jacobians
	- CH10_04.Matrix_Multiplication_Revisited
	- CH10_05.Matrix_Multiplication_and_Expanded_Jacobians
	- CH10_06.Bias_Addition_and_Expanded_Jacobians
	
	
### Lecture.11 Application of Expanded Jacobians

	- CH11_01.MLP_Theory
	- CH11_02.Training_MLP_Using_Expanded_Jacobians

>> Basic Mathmatics	
# Basic Algebra

## Chap.1 Algebraic Properties
	- CH01_01 . Orientation
	- CH01_02 . Algebraic Properties
	- CH01_03 . Identities and Inverse
	- CH01_04 . Equations
## Chap.2 Sets

	- CH02_01. Sets
	- CH02_02. Usages of Set
	- CH02_03. Cardimality of Sets
	- CH02_04. Inclusion and Exclusion
	- CH02_05. Unary Set Operation
	- CH02_06. Intersections and Unions1
	- CH02_07. Intersections and Unions2
	- CH02_08. Set Differences1
	- CH02_09. Set Differences2
	- Ch02_10. Cartesian Products
	- CH02_11. Partitions
	
>> Part3
# Part3.딥러닝/인공지능의 이해
## Ch 01_인공지능에 대한 이해
	- CH01_01_AI_Machine Learning
	- CH01_02_Data
	- CH01_03_Artificial Neural Network
	- CH01_04_Training Neural Network
	- CH01_05_Historical Review of Deep Learning
## Ch 02_딥러닝 개발 준비
	- CH02_01. Anaconda, Tensorflow, Pytorch 설치하기, Colab Jupyter Notebook 사용법
	- CH02_02. Numpy Tutorial 1
	- CH02_03. Numpy Tutorial 2
	- CH02_04. Numpy Tutorial 3
	- CH02_05. Data 시각화 - Matplotlib 1
	- CH02_06. Data 시각화 - Matplotlib 2
>> Part4
# Part4. 딥러닝 대표 3대장 프레임워크 기초
## Ch 03_텐서플로우/케라스 이론 및 실습
	- CH03_01. Tensorflow Keras Basic
	- CH03_02. Data pipeline
	- CH03_03. Model
	- CH03_04. Training Validation
	- CH03_05. Model save & restore Tensorboard
## Ch 04_파이토치 이론 및 실습
	- CH04_01. Pytorch Basic
	- CH04_02. Dataset & DataLoader Model
	- CH04_03. Training Validation Model save &restore
	- CH04_04. Tensorboard
>> Part5
# Part5. 딥러닝 기초 알고리즘 및 최신 트렌드 알고리즘
## Ch 01. ML기초
	- CH01_01. AI vs 머신러닝 vs 딥러닝
	- CH01_02.기계학습의 종류
	- CH01_03.선형회귀, 로지스틱회귀, log-likelihood
	- CH01_04.기계학습으로문제를해결하는일반적인순서
	- CH01_05.[TheorySession1]경험적위험도(empirical risk)와ML의일반화(generalization)
	- CH01_06.[TheorySession2]BiasVarianceTrade-off
	- CH01_07.[TheorySession3]정보이론
	- CH01_08.[TheorySession4]CrossEntropy와MaximumLikelihood Estimation(MLE)
	
## Ch 02. Feedforward Network
	- CH02_01.Feedforward Network
	- CH02_02.[실습0]-GoogleColab
	- CH02_03.[실습1]-MLP구현(Pytorch)
	- CH02_03-TF-01.MLP구현part1[PracticeSession1]
	- CH02_03-TF-02.MLP구현part2[PracticeSession1]
	- CH02_04.[TheorySession1]역전파
	- CH02_05.[TheorySession2]왜피드포워드네트워크는충분히잘될까
	- CH02_06.[심화학습]참고하면좋은자료들
	
## Ch 03. Regularization
	- CH03_01.Regularization소개
	- CH03_02.Norm기반Regularization
	- CH03_03.앙상블
	- CH03_04-Regularization-Dropout
	- CH03_05-Regularization-Early-stopping
	- CH03_06-Regularization-파라미터공유
	- CH03_07-Regularization-Multi-taskLearning
	- CH03_08-Regularization-AdversarialLearning
	- CH03_09-Regularization-DataAugmentation
	- CH03_10-Regularization-Dropout구현[PracticeSession1]
	- CH03_11-Regularization-Early-stopping구현[PracticeSession2]
	- CH03_10~11-TF-01.Dropout및Early-stopping구현[PracticeSession1-2]
	- CH03_12-Regularization-L2-norm=Early-stopping[TheorySession1]
	- CH03_13-Regularization-DeepDoubleDescent현상과Regularization[TheorySession2]
	- CH03_14-Regularization-[심화학습]참고하면좋은자료들

## Ch 04. Optimization
	- Ch04.Optimization
	- CH04_01_최적화의개념
	- CH04_02_경사하강법과뉴턴방법
	- CH04_03_학습과최적화의차이와minibatch알고리즘
	- CH04_04_최적화의난제들
	- CH04_05_Stochasticgradientdescent
	- CH04_06_Learningratescheduler
	- CH04_07_Normalization
	- CH04_08_보다나은최적화를위한다른알고리즘들_
	- CH04_09.Weight&BiasWandb소개[PracticeSession0]
	- CH04_10.Optimizer선택&LearningRateScheduler(part1)[PracticSession1]
	- CH04_11.Optimizer선택&LearningRateScheduler(part2)[PracticeSession1]
	- CH04_10~11-TF-01.Optimizer선택&LearningRateScheduler(part1)[PracticeSession1]
	- CH04_10~11-TF-02.Optimizer선택&LearningRateScheduler(part2)[PracticeSession1]
	- CH04_12.[심화학습]참고하면좋은자료들
	


## Ch 05. CNN
	- CH05_01.ConvolutionalNeuralNetwork
	- CH05_02.CNN의구성요소
	- CH05_03.CNN,goingdeeper
	- CH05_04.RecenttrendsofCNNmodels
	- ch05_05_CNN의응용
	- ch05_06_모델학습과정의병렬성(parallelism)
	- ch05_07_CNN-ConvolutionalNeuralNetwork실습[PracticeSession1]
	- CH05_07-TF-01.ConvolutionalNeuralNetwork실습(part1)[PracticeSession1]
	- CH05_07-TF-02.ConvolutionalNeuralNetwork실습(part2)[PracticeSession1]
	- ch05_08_EfficientNetFinetune[PracticeSession2]
	- CH05_08-TF-01.EfficientNetFinetune(part1)[PracticeSession2]
	- CH05_08-TF-02.EfficientNetFinetune(part2)[PracticeSession2]
	- ch05_09_Pytorch-Lightning&Hydra-CNNpart1[PracticeSession3]
	- ch05_10_Pytorch-Lightning&Hydra-CNNpart2[PracticeSession3]
	- ch05_11_Pytorch-Lightning&Hydra-CNNpart3[PracticeSession3]
	- CH05_09~11-TF-01.Hydra-CNNpart1[PracticeSession3]
	- CH05_09~11-TF-02.Hydra-CNNpart2[PracticeSession3]
	- ch05_12_[심화학습]참고하면좋은자료들

 ## Ch 06. RNN
	- CH06_01_시퀀스(sequence)모델과RNN
	- CH06_02_RNN-BackpropagationThroughTime과Long-termDependencych06_03_RNN-LSTM&GRU
	- CH06_04_RNN-RecurrentNetwork의응용
	- CH06_05_RNN-주의집중기반순환신경망(Attention-basedRNN)
	- CH06_06_RNN-기계번역을위한LSTMsequence-to-sequence구현part1[PracticeSession1]
	- CH06_07_RNN-기계번역을위한LSTMsequence-to-sequence구현part2[PracticeSession1]
	- CH06_08_-RNN-기계번역을위한LSTMsequence-to-sequence구현part3[PracticeSession1]
	- CH06_06~08-TF.기계번역을위한RNNsequence-to-sequence구현part1[PracticeSession1]
	- CH06_06~08-TF.기계번역을위한RNNsequence-to-sequence구현part2[PracticeSession1]
	- CH06_06~08-TF.기계번역을위한RNNsequence-to-sequence구현part2[PracticeSession1]
	- CH06_09_RNN-기계번역을위한Attention-basedsequence-to-sequence구현[PracticeSession2]
	- CH06_09-TF-01.기계번역을위한Attention-basedsequence-to-sequence구현part1[PracticeSession2]
	- CH06_09-TF-02기계번역을위한Attention-basedsequence-to-sequence구현part2[PracticeSession2]
	- CH06_10_RNN-[심화학습]참고하면좋은자료들

## Ch07. <Generativemodelseries#1> Autoregressive vs Autoencoder vs EmbeddingvsSeq2Seq
	- CH07_01_intro
	- CH07_02_자가회귀(auto-regressive)모델
	- CH07_03_오토인코더(auto-encoder)모델
	- CH07_04_임베딩(embedding)모델
	- CH07_05_Outro-ReturntoSeq2Seq
	- CH07_06_[심화학습]참고하면좋은자료들
 
## Ch08.트랜스포머(Transformer)
	CH08_01_Transformer
	CH08_02.VariationsofTransformer
	CH08_03_기계번역을위한Transformersequence-to-sequence구현
	CH08_03-TF-01.기계번역을위한Transformersequence-to-sequence구현part1
	[PracticeSession1]
	CH08_03-TF-02.기계번역을위한Transformersequence-to-sequence구현part2
	[PracticeSession1]
	CH08_04.[심화학습]참고하면좋은자료들
## Ch09.PretrainedLarge-ScaleTransformer
	CH09_01.PretrainedBigTransformer가나오기까지
	CH09_02.Pre-trainedTransformerDecoder-Generativepre-training(GPT)
	CH09_03.Pre-trainedTransformerEncoder-BERT을중심으로
	CH09_04.HybridMethods
	CH09_05.[심화학습]참고하면좋은자료들
## Ch10.<Generativemodelseries#2>FlowModels
	CH10_01.DeepGenerativeModel의종류
	CH10_02.Flow와목적함수(objectivefunction)
	CH10_03.VariationsofFlowModels
	CH10_04.Dequantization
	CH10_05.[심화학습]참고하면좋은자료들
## Ch11.<Generativemodelseries#3>LatentVariableModels
	CH11_01.잠재변수모델(LatentVariableModels)
	CH11_02.변분추론(VariationalInference)
	CH11_03.VariationalInference의종류
	CH11_04.VariationalAutoencoder
	CH11_05.VAE의발전된모델들
	CH11_06.VAE구현part1[PracticeSession1]
	CH11_07.VAE구현part2[PracticeSession1]
	CH11_08.VAE구현part3[PracticeSession1]
	CH11-06~08-TF-01-_Generativemodelseries#3_LatentVariableModels-VAE
	구현-part1-[PracticeSession1]
	CH11-06~08-TF-02-_Generativemodelseries#3_LatentVariableModels-VAE
	구현-part2-[PracticeSession1]
	CH11_09.[심화학습]참고하면좋은자료들
 
## Ch12.<Generativemodelseries#4>ImplicitModels
	CH12_01.ImplicitModels(암시적모델)
	CH12_02.GenerativeMomentMatchingNetwork
	CH12_03.GenerativeAdversarialNetwork(GAN)
	CH12_04.GAN의발전-part1
	CH12_05.GAN의발전-part2
	CH12_06.GAN의구현part1[PracticeSession1]
	CH12_07.GAN의구현part2[PracticeSession1]
	CH12_08.GAN의구현part3[PracticeSession1]
	CH12_09.GAN의구현part4[PracticeSession1]
	CH12-06~09-TF-01-_Generativemodelseries#4_ImplicitModels-GAN의구현
	part1[PracticeSession1]
	CH12-06~09-TF-02-_Generativemodelseries#4_ImplicitModels-GAN의구현
	part2[PracticeSession1]
	CH12_10.[심화학습]참고하면좋은자료들
## Ch13.<Generativemodelseries#5>DistributionAlignment
	CH13_01.DistributionAlignment
	CH13_02.MarginalMatching&CycleConsistency(DualLearning)
	CH13_03.Variations&Application
	CH13_04.[심화학습]참고하면좋은자료들
## Ch14.DeepMetricLearning
	CH14_01.MetricLearning
	CH14_02.DeepMetricLearning의종류
	CH14_03.ContrastiveLearning의발달(SimCLR,SupervisedMethod)
	CH14_04.[심화학습]참고하면좋은자료들
## Ch15.DeepReinforcementLearning
	CH15_01.ReinforcementLearning의핵심개념part1
	CH15_02.ReinforcementLearning의핵심개념part2
	CH15_03.Value-basedModel-freeRL
	CH15_04.Policy-basedModel-freeRL
	CH15_05.Off-policyPolicy-basedModel-freeRL
	CH15_06.Model-basedRL
	CH15_07.RepresentationLearningInDeepRL
	CH15_08.[심화학습]참고하면좋은자료들
## Ch16.MetaLearning
	CH16_01.LearningtoLearn
	CH16_02.Metric-basedMetaLearning
	CH16_03.Model-basedMetaLearning
	CH16_04.Optimization-basedMetaLearning
	CH16_05.MetaReinforcementLearning
	CH16_06.[심화학습]참고하면좋은자료들
## Ch17.DeepLearningProduction
	CH17_01.AI모델의수명주기와MLOps
	CH17_02.MLOps를위한Component&Tool
	CH17_03.[심화학습]참고하면좋은자료들
## Ch18.ResearchTopicsforProductions
	CH18_01.ModelCompression(Quantization,Distillation,Pruning)
	CH18_02.OvercomingDataProblem
	CH18_03.Auto-ML
	CH18_04.eXplainableAI(XAI)
## Ch19.마치며
	CH19_01.Next

>> Part6
# Part6. 딥러닝 실전 프로젝트
## Ch 01. 이미지 처리 실습
	CH01_01. Oxford-IIT Pets Dataset 소개
	CH01_02. Oxford-IIT Pets Dataset 소개
	CH02_01. Data Loader 의 구현
	CH02_02. Model 의 구현
	CH02_03. Training Script 의 구현
	CH02_04. Data Augmentation
	CH02_05. Transfer Learning
	CH02_06. TensorFlow Hub
	CH02_07. Multiclass Classification
	CH03_01. Image Segmentation 의 소개
	CH03_02. Loss 함수의 구현
	CH03_03. Data Loader 의 구현
	CH03_04. UNet 소개
	CH03_05. UNet 학습
	CH03_06. TensorBoard 를 이용한 시각화
	CH03_07. Learning Rate 스케줄링
	CH03_08. Multiclass Segmentation
## Ch02.동영상처리실습
	CH02_01.UCF11Dataset소개
	CH02_02.UCF11DatasetEDA
	CH02_03.Datapreparation-CNNapproach
	CH02_04.Modeltraining-CNNapproach
	CH02_05.RollingAverage의적용
	CH02_06.DataPreparation-RNNapproach
	CH02_07.Modeltraining-RNNapproach
## Ch03.자연어처리실습-챗봇
	CH01_01.자연어처리소개
	CH01_02.대화시스템소개
	CH01_03.목적지향대화시스템NLU실습-임베딩
	CH01_04.목적지향대화시스템NLU실습-의도분류
	CH01_05.목적지향대화시스템NLU실습-정보추출
	CH01_06.목적지향대화시스템NLU실습-OOD분류
	CH01_07.목적지향대화시스템NLU실습-NLU시스템구성
	CH01_08.목적지향대화시스템DM실습-NLG시스템구성
	CH01_09.목적지향대화시스템DM실습-DM시스템구성
	CH01_10.오픈도메인대화시스템실습-생성기반방식
	CH01_11.하이브리드대화시스템-시스템구성
	CH01_12.현직자가주목하고있는대화시스템기술및인사이트-DM
	CH01_13.현직자가주목하고있는대화시스템기술및인사이트-NLU
	CH01_14.현직자가주목하고있는대화시스템기술및인사이트-인사이트

>> Part 7
# Part 07. 이미지분류기초
## Ch01.RNN으로손글씨이미지분류하기
	CH01.기초지식개요RNN분류의특색
	CH02.EDA
	CH03.전처리
	CH04.시각화방법
	CH05.Data_augmentation
	CH06.모델링
	CH07.결과확인
	CH08.모델저장및로드,다운
 
## Ch02.인물사진에서성별과표정분석하기
	CH01.기초지식개요-멀티아웃풋모델
	CH02.EDA
	CH03.전처리
	CH04.시각화방법
	CH05.모델링
	CH06.결과확인
	CH07.멀티모델링
	CH08.결과확인
	CH09.모델분리
	CH010.통합모델저장및로드,다운

 ## Ch03.여러의상사진에서옷종류구분하기
	CH01.기초지식개요멀티레이블분류란
	CH02.EDA
	CH03.전처리
	CH04.시각화방법
	CH05.Data_augmentation1
	CH06.Data_augmentation2
	CH07.Data_augmentation3
	CH08.모델링
	CH09.결과확인
	CH010.멀티레이블모델링
	CH011.모델저장및로드,다운
