# Deep Metric Learning - 1. Metric Learning
## Metric learning은 왜 필요할까?
데이터를 다 모아서 학습을 했는데, 실제 서비스 환경에서는 분류해야하는 대상이 달라진다면?
- 예)얼굴인식,음성화자인식,상품검색,추천
  
만약, 아래 조건이라면, metric learning을 고려하는 것이 바람직하다!
- 카테고리가 아닌, 하나의 인스턴스(instance)에 대한 application 일 때
- 이 강의을 듣고 있는 사람은 어떤 사람일까?
- 이 강의와 시너지를 일으킬 다른 강의는 무엇일까?
- 새로운 인스턴스(instance)가 추가되거나 변경/삭제 등이 자주 일어날 때 

참고: metric learning의 결과는 embedding 으로 주로 구분된다!
- Embedding 은 representation learning의 좁은 의미!

## Deep metric learning?
<img width="400" alt="스크린샷 2023-08-24 오후 5 40 21" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5f2226f8-0a4d-4fbe-aeac-27ea1417886c">

<img width="400" alt="스크린샷 2023-08-24 오후 5 40 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/798b6df7-14ec-4360-9f4b-ec91c25a5a35">

## Deep metric learning은 왜 필요할까? - 분류 문제에서의 metric learning
<img width="500" alt="스크린샷 2023-08-24 오후 5 41 25" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/3f912cb7-d1af-4aa3-9cdb-c24e9c10d4a7">

- 성능 향상에 도움!

## Deep metric learning은 왜 필요할까? - 분류 문제에서의 deep metric learning (i.e. contrastive learning)
<img width="423" alt="스크린샷 2023-08-24 오후 5 42 19" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c7f5983f-c546-4439-a3f8-8011cef5913f">

<img width="250" alt="스크린샷 2023-08-24 오후 5 42 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c70f1a38-abcc-4d55-b17c-a54a68a64c42">

- 단순 data-augmentation + cross-entropy loss보다 더 효율적이면서 좋을 수도 있다!

## Deep metric learning의 예
<img width="400" alt="스크린샷 2023-08-24 오후 5 43 22" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7909b43d-b517-4ff4-b0b2-4109e24cc588">

<img width="400" alt="스크린샷 2023-08-24 오후 5 49 23" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/0491b868-4862-40e7-94d5-bd8aae81a739">

## 거리 함수(metric function)이란?
- 데이터간의 유사도(similarity)을 수치화하기 위해 일반적으로 거리함수(metric function)을 이용!
- 아래의 3조건을 만족하는 함수 𝑑 : 𝑋 × 𝑋 → [0,∞) 을 metric function이라고한다,
1. (구분 불가능한 점의 동일성) 임의의 𝑥,𝑦 ∈ 𝑋에 대하여,𝑑(𝑥,𝑦) =0 ↔ 𝑥=𝑦
2. (대칭성) 임의의 𝑥,𝑦∈𝑋에 대하여, 𝑑(𝑥,𝑦) = 𝑑(𝑦,𝑥)
3. (삼각부등식) 임의의 𝑥,𝑦,𝑧∈𝑋에 대하여 𝑑(𝑥,𝑦) + 𝑑(𝑦,𝑧) ≥ 𝑑(𝑥,𝑧)
   
- 우리는 이미 metric function을 쓰고 있었다!
  - Euclidean거리(L2distance),cosinesimilarity,...
 
## Metric learning의 요소
- 어떤 metric (유사도)를 사용할까?
  - i.e. Euclidean, KL divergence, Wasserstein distance, cosine similarity, energy distance..
- Metric learning을 위해 어떤 loss (목적 함수)를 사용할까?
  - i.e. contrastive loss, triplet loss, margin loss, softmax loss... àloss에 따라 선택해야하는 network가 달라진다.
