# <Generative model series #5> Distribution Alignment - 1. Distribution Alignment
## 지도 학습적 분포 동조(supervised distribution alignment)
Conditional distribution(𝑝(𝑥|𝑦) , 𝑝(𝑦|𝑥))을 통해 matching시킨다!
- (𝑥, 𝑦) pair 로 학습!
- 이미 다뤄왔던 토픽들!

예)
- 이미지간 동조: pix2pix
- 이미지 -> 텍스트: 이미지 캡션
- 여러 sequence-to-sequence 문제들
  - 텍스트간 동조: 기계 번역 (machine translation)
  - Speech-to-text (speech recognition)
  - Text-to-speech (speech synthesis)

그런데 만약 (x, y)를 매칭하는 것이 어렵다면 어떨까? 

## 지도 학습적 분포 동조(distribution alignment)의 예 - Text-to-text (machine translation)
<img width="400" alt="스크린샷 2023-08-24 오후 2 59 28" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4d1ed76e-e90f-4294-a87a-0b57307caec8">

## 지도 학습적 분포 동조 문제(distribution alignment problem)의 예 - Image-to-image (pix2pix)
<img width="500" alt="스크린샷 2023-08-24 오후 2 59 50" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7f442f7e-7b8e-4a01-85a3-88bfda31c07d">

<img width="300" alt="스크린샷 2023-08-24 오후 3 00 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c82822ac-b5b7-40c9-a8b0-6785ed338c5c">

## 비지도 학습적 분포 동조(unsupervised distribution alignment)
지도 학습적 분포 동조: Conditional distribution(𝑝(𝑥|𝑦) , 𝑝(𝑦|𝑥))을 통해 matching시킨다! 
  - 즉, 𝑝(𝑥, 𝑦) 로 학습!
    
그런데, 𝑝(𝑥, 𝑦) pair가 비싸다면..? 
  - Unsupervised distribution alignment
    
𝑝(𝑥)와 𝑝(𝑦)을 샘플링 할 수 있을 때, 𝑝(𝑥, 𝑦)로 샘플링하거나 데이터를 구하지 않고, 바로 단순히 conditional distribution(𝑝(𝑥|𝑦) , 𝑝(𝑦|𝑥))을 구한다!

<img width="259" alt="스크린샷 2023-08-24 오후 3 01 56" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5d5a58e3-3216-42aa-bd02-585364e25b26">

## 비지도 학습적 분포 동조(unsupervised distribution alignment)의 예
<img width="636" alt="스크린샷 2023-08-24 오후 3 02 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8b558a96-f41f-4070-98f6-a246c9b77489">

## 분포 동조(distribution alignment) - 왜 필요할까?
Generative model을 포함한 unsupervised/semi-supervised/self-supervised 모델에서 가장 먼저 태
동
- 생성(Generative Model)에서의 application
  - 순수 $p_{data}$ 만 reproduce, $𝑝_{model}$ 만으로는 응용력이 작다.
  - A의 style을 가진 것을 B의 input으로 만들고 싶다면?
  - i.e.: CycleGAN, DiscoGAN, sequence-to-sequence (i.e. machine translation)
- Embedding (representation learning)에서 응용될 수 있고 성능 또한 향상 시킬 수 있다!
- 데이터의 불균형 문제
  - labeled data가 unlabeled data보다 더 작기때문에 “empirical mismatch”문제가 발생!
  - 분포 A에 해당하는 데이터가 분포 B에 해당하는 데이터보다 수가 작다면?
  - 관련 연구: Augmented Distribution Alignment
