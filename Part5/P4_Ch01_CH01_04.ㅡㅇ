# CH01_04.기계학습으로문제를해결하는일반적인순서

## 1.먼저 해야할 일(task)에 대해 input, output이 무엇인지 분석한다.

- 이미지인가 음성인가 텍스트인가
- 레이블이 있는가
- 레이블이 이산적인지 연속적인가
- 분류문제인가 회귀문제인가 군집화문제인가
- 무엇을 해결하고싶은가

## 2.관련된 데이터를 이해한다. EDA

- 데이터의 분포 및 값을 검토
- 데이터에 대한 잠재적인 문제 발견, 본격적인 분석에 들어가기에 앞서 데이터의 수집, 모델링 시 주의할 점 파악
- 데이터 특징을 기반으로 가설수립 ( 어떤 모델이 보다 좋을것이다)

## 3.Train, Test데이터를 대표성을 띄도록 임의로 나누고, 모델의 성능을 평가할 metric을 정한다.

- 용어정의
    - Train Set
    - Validation Set : 학습중인 모델 검증
        - Epoch단위 등으로 train과정의 중간 과정에서 튜닝을 위해 존재
    - Test Set : 학습과 검증이 완료된 모델의 최종적인 성능 평가
- 모델을 평가할 성능 지표(Metrics)을 정한다.
    - Classification(분류)
        - Accuracy, Recall, Precision, Sensitivity, Specificity
        - AUC (Area Under the ROC Curve)
        - F1 Score, Fn Score
        - Cohen’s Kappa Coefficient
    - Regression(회귀분석)
        - Mean Absolute Error, Root Mean Square Error
        - R-squared (결정계수; Coefficient of Determination)
    - Clustering (군집화)
        - Silhouette Score
        - Rand Index, Adjusted Rand Index
        - Mutural Information
        - Calinsk-Harabasz Index, Davies - Bouldin Index

## 4.피처엔지니어링과 모델링을 한다.

- 피처엔지니어링 : 데이터의 도메인 지식을 이용하여 머신러닝 알고리즘을 작동시키는 Feature을 만드는 과정
    - 일종의 전처리과정
    - 고도화된 End-to-end 딥러닝 모델의 경우 이 과정이 생략되는 경우도 있음
- 모델링 : 머신러닝 모델을 정의하는 과정

## 5.모델 최적화의 목표인 손실함수(loss function)를 정의한다.

- 손실함수(loss function)이란?
    - 이벤트로 생성된 값과 실제값 사이의 비용(cost) 즉 차이(loss)을 나타내는 함수
    - 에러함수(error function), 비용함수(cost function)도 비슷한 맥락
    - i.e. cross entropy loss, Bayesian expected loss, logistic loss, L1, L2
- 최적화를 위한 목적함수(objective function)는?
    - 최적화 알고리즘에 태워지는 궁극적인 함수
    - 보통, 손실함수 자체이거나 손실함수의 음수값

## 6.목적함수(objective function)를 최소값으로 최적화(optimization)할 기법을 선택한다.

- 최적화(optimization)문제란?
    - 최적화변수값을 각 탐색범위 내에서 조절함으로써 주어진 목적함수를 최소화 혹은 최대화 하는 해를 찾아내는 기법
    - 경사하강법(gradient descent)
    - 뉴턴법 / 뉴턴 - 랩슨법( Newton’s step, Newton-Rapson)
    - 경사하강법이 일반적으로 많이 쓰이며, 여러 파생연구들이 많음.
        - SGD, Adam, Momentum등
        

## 7.모델학습을 진행하고, 목표한 대로 나왔는지 확인한다.

- 모델학습을 진행하고, 목표한 대로 나왔는지 확인한다.
    - tensorboard - 구글의 무료 logging system
    - wandb - 유료 logging system
- training error를 작게
- test error와 training error의 차이를 작게
- underfit과 overfit은 일어나지 않았는가?
    - underfit (부적합) : Train error를 줄이지 못한 경우 → 모델의 용량(model capacity)를 키우거나, 모델을 깊게 쌓으면 해결된다
    - overfit(과적합) : Train error는 줄였으나, Test Error가 너무 큰 경우! → 일반적으로는 모델의 용량을 줄인다.
        - Overfit을 방지하려면?
            - Traini data를 많이 모은다. 혹은 데이터 증강기법(TBD)을 사용한다.
            - 피처의 개수를 줄여본다. → 정형화가 쉽게 가능하다
            - Regularization(정형화)을 사용한다
        - Deep Double Descent : (recent view ) 딥러닝을 사용하고 데이터가 많으면서 충분히 모델이 깊다면, 보다 더 과적합 시켜도 된다!

## 8.1~7을 반복한다.
