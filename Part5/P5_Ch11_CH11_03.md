# <Generative model series #3> Latent Variable Models - 3. Variational Inference의 종류
## Variational Inference (VI)
<img width="343" alt="스크린샷 2023-08-10 오후 6 30 25" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/16d1c0ff-d889-457a-bcc5-4f93ff5d5313">

VI란 사후확률(posterior) 분포 𝑝(𝑧|𝑥)를 다루기 쉬운 확률분포 $𝑞_x(𝑧)$로 근사(approximation)하는 것이다.
- 여러분야에 적용가능하다.
  - 잠재변수(latent variable)을 이용하는 생성모델(generative model)
  - 상호의존정보(mutual information)의 측정및 학습을 이용한 최대화
  - 학습가능한 dequantization
- 이때 p, q는 모델(파라미터)이 같을수도 있고, 같지 않을 수도 있다.
  - 같은 경우 : stochastic variational inference(SVI)등이 있으며, wake-sleep알고리즘이 속한다.
  - 같지않은 경우 : amortized inference라고 하고, 인코더-디코더구조를 보통 같는다.
    - 식에서는 q: encoder(embedding) , p : decoder(generative model)이다.
    - i.e. Variational Auto-encoder
    - 이경우 notation을 다음과 같이 구체화 가능하다. (x를 받아 z를 inference하는 embedding모델 $q_\pi$)
    - <img width="173" alt="스크린샷 2023-08-10 오후 6 36 04" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8929e026-b5f5-4eca-a51a-ddf5ebc8e23f">

## Variational lower bound(VLB; Evidence lower Bound; ELBO)의 확률적(stochastic) 최적화(최대화)
데이터가 주어졌을때($x \sim$  $p_{data}$ (x)), generative model의 학습과정은 VLB를 maximizing하는 것이다. 

<img width="291" alt="스크린샷 2023-08-10 오후 6 53 19" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/971083eb-55b9-43f5-b7a2-09d7a95b04f7">

stochastic 한 VLB의 최적화
- z가 베르누이 분포에서 샘플링된다고 해보자.

  <img width="631" alt="스크린샷 2023-08-10 오후 6 55 31" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f4f39066-e243-49ff-a0d5-9eeeba8c558d">

- Bernoulli 세팅에서 이것은 곧 다음과 같이 정리된다.

  <img width="631" alt="스크린샷 2023-08-10 오후 6 56 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/92b29aa5-f501-4471-a249-75eac79b3c17">

여기서 핵심문제는 z가 도출되는 기대치를 최적화하는 것이다.

## Variational lower bound (VLB)의 확률적 최적화(stochastic optimization)
확률적(stochastic)인 최적화 - Wake-sleep 알고리즘
- VLB는 <img width="460" alt="스크린샷 2023-08-10 오후 7 06 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2cd5de23-b84e-483a-8ffc-4029d6925657">에서 유도되었고, z가 log $q_x(z)$ 로부터 추출되기 때문에 최적화 되기 어렵다.
- 만약 $D_{KL}$ [p(z|x) || q_x(z)]을 대신 최소화 한다면 어떨까?
  - 여전히 p(z|x)를 모르기 때문에 어려울 것이다.
- 그리고 만약 우리가 직접 generation을 한다면 z를 알수있지 않을까? ($z \sim p_\beta$ (z), $x \sim p_\theta$ (x|z))
  - 즉 x~ $p_{data}$가 아닌, x~ $p_{model}$을 한다면 어떨까?
-> wake-sleep algorithm

## Variational lower bound (VLB)의 확률적 최적화(stochastic optimization) - 확률적(stochastic)인 최적화 - Wake-sleep 알고리즘
Wake phase
- 인식모델을 통해 입력층부터 최상위층까지의 각 노드값이 확률적으로 결정
- 생성모델을 이용해 최상위층부터 입력층까지의 각 노드에서의 확률값을 계산하여 생성모델의 파라미터값을 update
- 샘플링 : x~ $p_{data}$ , $z \sim$ q($z; \phi $(x))한다.
- VLB을 생성 모델의 파라미터 θ와 인식 모델의 파라미터 ϕ에 대해 각각 최대화한다.
  - <img width="393" alt="스크린샷 2023-08-10 오후 7 20 46" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/27b41aed-6332-49b6-88da-af954867146b">

Sleep phase (model dreaming sample)
- 생성모델을 통해 최상위 층부터 입력층까지 각 노드의 값이 확률적으로 결정
- 인식모델을 이용해 입력층부터 최상위층까지의 각 노드에서의 확률값을 계산하여 인식모델의 파라미터값을 update
- 샘플링 : z ~ p(z; $\theta$ ), x ~ $p_{data}$
- $D_{KL}$ [p(z|x) || q(z; $\phi$ (x)]을 $\phi$에 대해 minimize한다. 이떄 x ~ $p_{model}$로 진행된다.
  - Reverse KL : $D_{KL}$ [p(z|x) || q(z; $\phi$ (x)] = $E_{z \sim p(z|x)}$ [log p(z|x) -logq(z; $\phi$ (x))]
    - 여기서 logp(z|x)는 $\phi$ 와 독립적이다.
   
## Variational lower bound (VLB)의 확률적 최적화(stochastic optimization) - Helmholtz machine (1995)
<img width="364" alt="스크린샷 2023-08-10 오후 7 44 33" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/94e829b7-9934-40a6-936b-fabc5ae9e6d5">

- Wake-Sleep알고리즘으로 학습하는 네트워크
- 한계 : Wake-Sleep알고리즘의 한계로, 복잡한 문제에 scale하지 못한다.
- 특히 $p_{model}$ 와 $p_{data}$ 가 떨어져있을때 비효율적이라고 알려져있다.

## Variational lower bound (VLB)을 직접 최적화 해보자. - 점수 함수 추론 (score function estimator) / 가능도 비율 추론(likelihood ratio estimator)
- Wake-Sleep 알고리즘은 특히 p_model이 p_data로 떨어져있을때 비효율적이라면, amortized inference로 하여 한번에 직접 VLB을 최적화하면 어떨까?
- 이경우 VLB을 최적화하여 모델을 학습하는 과정은 아래와 같을것이다. <img width="409" alt="스크린샷 2023-08-10 오후 7 56 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/04664ab1-453c-4a03-8920-df7bf87a711a">
- 파라미터 $\phi$에 대한 최적화하는 문제로 아래와 같이 줄일 수 있을것이다.

  <img width="161" alt="스크린샷 2023-08-10 오후 7 56 54" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d98fcd58-f294-40fe-8fb9-9d278a417ebb">

  - 여기서 f(z)는 log $p_\theta$ (x|z) - log $q_\theta$ (z|x) + log p(z)이 추상화된 함수이다.
  - 그렇다면 위의식을 어떻게 gradient을 계산해 parameter update할수있을까?

## Variational lower bound (VLB)을 직접 최적화 해보자. - 점수 함수 추론 (score function estimator) / 가능도 비율 추론(likelihood ratio estimator)
그러면 $\nabla_{\phi} E_{q_{\phi}(z|x)}[f(z)]$ 는 어떻게 최적화할까?

<img width="555" alt="스크린샷 2023-08-10 오후 8 03 27" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d10a5caa-8bc7-475b-b64f-1c73ea7c32dd">

이다. 그러므로 update rule은 아래와 같다. 
<img width="294" alt="스크린샷 2023-08-10 오후 8 04 33" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7cfef0e0-a63c-41a6-b3d4-eba792c512a3">

- 그러나 high variance gradient(gradient update가 불균형하고 불안정하다)를 가지고 많은 샘플링 역시 좋은 추론을 위해 필요하다.
- 참고 : derivative trick & REINFORCE방법이라고도 불리며 강화학습에서도 쓰인다.

## Variational lower bound (VLB)을 직접 최적화 해보자. - Pathwise derivative (PD) / Pathwise gradient estimator (A.K.A. reparameterization trick; RT)
한편 잠재변수 z가 연속적일떄 z를 standard gaussian과 같은 형태의 고정된 노이즈로 변형시켜 최적화하는 방법도 있다.

<img width="294" alt="스크린샷 2023-08-10 오후 8 09 31" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/93b4087e-5cea-44fe-b7cd-22a5dc8a86d7">

만약 f가 미분가능하다면, <img width="317" alt="스크린샷 2023-08-10 오후 8 10 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7fa33b60-0265-4693-ae77-383787d8077e">
