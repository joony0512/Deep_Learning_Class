# CH01_08.[TheorySession4]CrossEntropy와MaximumLikelihood Estimation(MLE)

- 로그 우도법
    - p는 주어진 확률분포에서 해당 관측값이 나올확률 = pr(data|distribution)
    - L은 주어진 관측값이 해당확률분포에서 나왔을확률(= 연속확률밀도함수의 y값) =L(distribution | data)
    - 데이터가 정규분포에서 나왔다고 가정할때
        
![Untitled (10)](https://user-images.githubusercontent.com/109457820/229532156-98ef2c17-9c60-4087-af1a-88a349e8983f.png)        
- 우리의 목표 : 가능도를 최대로 하는 최적의 $\theta$를 구하는 것이 목표이다 : MLE
    - 최대우도 추정이란 각 관측값에 대한 총 가능도(모든가능도의 곱)가 최대가 되게하는 분포를 찾는 것이라고 할 수 있다.
    - 우리가 관측한 관측값
    
![Untitled (11)](https://user-images.githubusercontent.com/109457820/229532196-45ddfab6-dd98-47bd-ac7f-e450080b816e.png)    
    - 우리가 생각할 수 있는 분포들 과 그에 따른 Likelihood 값 → 검은점이 가장 높은곳이 MLE
    
![Untitled (12)](https://user-images.githubusercontent.com/109457820/229532258-93e91b18-acde-4ae8-a2c7-70145a1feeaa.png)    
- 로지스틱 회귀로 이항분류(binary classification) 할때
    - 각 값은 0혹은 1로 예측될 것이다
    - 이는 베르누이 분포를 따른다고 가정할 수 있고
    - p는 시그모이드를 통과한 관측값 $x$이고 이를 $\sigma(\theta x)$라 표현할 수 있다.
        - $\theta$에따라 시그모이드의 기울기가 달라진다.
    - $P(Y=y | X=x) = \sigma(\theta x)^y * (1-\sigma(\theta x))^{1-y}$가 확률,
        
![Untitled (13)](https://user-images.githubusercontent.com/109457820/229532321-674ac9e6-6ca7-4f6c-82aa-5b1e18966195.png)        
        이 가능도 이다. 우리는 관측치(x)  를 받아 최적의 y-hat 을 구현하는 모델을 만드는 것이 목표이기 때문에, 가능도를 최대로 하는 최적의 $\theta$를 구하는 것이 목표가 된다.
        
    - 이를 풀기위해서는 loss function  형태로 바꾸는 것이 편하다
        
![Untitled (14)](https://user-images.githubusercontent.com/109457820/229532364-7535fdc6-ddc6-408e-bc97-d02c08409f8e.png)        
![Untitled (15)](https://user-images.githubusercontent.com/109457820/229532871-010cda66-4d4f-474c-a875-948b00aeddec.png)        이는 cross entropy 와 같다.
        
    - 크로스 엔트로피 H(p,q)를 풀면
        
![Untitled (16)](https://user-images.githubusercontent.com/109457820/229532939-117657ac-fd19-41c5-978c-f8f7ae819cce.png)        
        로 결국 로지스틱회귀를 최적화 하는 식과 같아진다.
        
- 일반화
- n개의 샘플을 가진 데이터 $X : \{x_1,…,x_n\}$이 있을때, 이를 독립적으로 생성하는 데이터 생성 확률 분포를 $p_{data}$라 하고 매개 변수 $\theta$를 가지는 예측분포를 $q_{model}$이라하면, $\theta$의 최대가능도추정은
    
![Untitled (17)](https://user-images.githubusercontent.com/109457820/229533035-53fe4843-8d85-45be-b6a4-b4d752497c68.png)    
    를 만족하고 편한 계산을 위해 log를 씌우면
    
![Untitled (18)](https://user-images.githubusercontent.com/109457820/229533097-0c600877-6259-4430-a371-76ed03a38b62.png)    
    를 최적화 하는 문제로 된다.
    
- 여기에 우리는 데이터를 놓고, 결과적으로 평균을 내는 작업을 하므로, 위의식은 아래와 같이 정리된다.
    
![Untitled (19)](https://user-images.githubusercontent.com/109457820/229533245-71d826f8-4585-4826-8698-8b4280b2ea2f.png)    
    → KL-divergence 를 생각하면  $p_{data}$와 $q_{model}$의 비유사성을 줄이는 것이다!!!
