# 순환 신경망 (RNN) - 1. 시퀀스(sequence) 모델과 RNN
## 시퀀스 모델 (sequence model)

- 우리의 실생활 데이터는 많은 부분에서 ‘순서’가 중요하다.

예) Text 정보
- “우리는 딥러닝을 공부 중이다”   vs.  “는리우 을러딥닝 부공 이중다”
- Text외에도,
	- 음성(speech) 등 오디오 데이터 
	- 유저 로그 데이터 (User response; interaction data)
	- 주식 데이터
	- 헬스케어 (생체 신호, 병원 내방 기록) 데이터

- 등등.. 수많은 분야는 ‘시퀀스’ 처리가 필요하다.
- 처리를 위한 기본적인 neural network : RNN

## 자가 회귀(auto-regressive) model 
- 미래를 예측하는 상황 고려
  - 보통 시퀀스에서 t일때를 예측한다면, $x_1 \sim x_{t-1}$ 까지의 정보를 이용할 수 있을것이다.
  - 즉 : $x_t \sim P(x_t | x_{t-1},...,x_1)$
  - 이때 $x_1 = P(x_{t-1} | x_{t-2},...,x_1) ... x_1 = P(x_1)$ 으로 순차적 계산 가능
  - $P(x_1, x_2, ..., x_T) =  \prod_{t}^T  P(x_t | x_{t-1},...,x_1)$
- 이런 모델을 자가회귀 (auto regressive)모델이라고 한다.
  - Language model 등이 여기 속한다.
    
<img width="563" alt="스크린샷 2023-07-13 오후 8 59 43" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/04ae6566-5bd7-42bc-be57-f0460922a338">
<img width="563" alt="스크린샷 2023-07-13 오후 9 00 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/cddff145-f5a2-4729-8ca0-f89eabe4d06e">

## 순환신경망 ( Recurrent Neural Network ; RNN)
- $ P(x_t | x_{t-1},...,x_1)$ 계산시 t가 늘어날수록 계산량이 기하급수적으로 많아진다
- 보다 심플하게, 이전을 보는 모든 정보 ( $ x_{t-1},...,x_1$)를 hidden state($h_{t-1}$)가 압축해 담고 있다고 생각해보자.
  - 즉  $ P(x_t | x_{t-1},...,x_1) =  P(x_t |h_{t-1)$ 라 하면 계산 하는 파라미터를 줄일 수 있다.
  - 이때 적절한 f 가 있다고 할때, $h_t = f(x_t, h_{t-1))$등으로 업데이트 할 수 있을것이다
- 이런 방식을 순환(recurrent)하여 학습한다고 하며, 모델이 신경망으로 구성되어 있을 경우 '순환신경망(RNN)' 이라고 한다.
  <img width="724" alt="스크린샷 2023-07-13 오후 9 06 58" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c4f9892d-ac61-43de-b4b9-6d3d90441a85">

## Vanilla (pure) RNN
<img width="807" alt="스크린샷 2023-07-13 오후 9 07 59" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/044c9b21-76a7-464d-9666-4471551a81fa">
- 하나의 feedback 연결 (W)이 있다.
- 이때 파라미터(U,W,V)가 공유된다.
- $h_t = f(U x_t + W h_{t-1})$
- $y_t = f(V h_t)$



