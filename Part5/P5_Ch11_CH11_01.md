# <Generative model series #3> Latent Variable Models - 1. 잠재 변수 모델(Latent Variable Models)
## 잠재 변수 모델(Latent Variable Models; LVM)
- Autoregressive models & Flows 모든 random variable이 관찰된다: (Tractable density을 가진다.)
- Latent Variable Models (LVMs) : 어떤 random variables은 숨겨져(hidden)있다. (Intractable density을 가진다. z를 정확히 파악하지 않는 상태에서 학습)

<img width="397" alt="스크린샷 2023-08-10 오후 5 43 28" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/af0e429e-8dba-4c9a-a46d-e4c17fe36f3b">

## 잠재 변수 모델(Latent Variable Models; LVM)은 왜 필요한가?
- 데이터에서 “차원 축소가 된”, 간단하고 낮은 차원의 representation이 종종 더 필요하다
  - Latent variable model은 숨겨진 대표 정보(latent representation)을 자동으로 식별할 수 있는 가능성을 보유한다.
- AR의 경우, sampling과정이 매우 느리다. 
  - 전후의 pixel/time의 결과에 prediction이 의존적이므로 sequential한 연산이 필요하다.
- Latent variable model들은 통계적인 패턴(statistical pattern)을 활용하여 보다 빠른 샘플링이 가능하다.	 
- 일부 잠재 변수 값을 독립적으로 conditional하게 넣어, observation space을 바꾸고 생성되는 값을 변경할 수 있다.

---
참고: auto-regressive model처럼, latent variable 역시 시간의 흐름(causal process)를 이해하여 데이터를 생성할 수 있다.
  - 일반적으로, unsupervised 모델이기 때문에 잠재 변수가 무엇이고 관측치와 어떻게 상호 작용하는지 알 수 없다.
  - 잠재 변수를 지정하는 가장 좋은 방법은 여전히 활발한 연구 영역이다

## 잠재 변수 모델(Latent Variable Models)의 간단한 예
- 만약 샘플링이 베르누이 분포를 따른다면,

  <img width="314" alt="스크린샷 2023-08-10 오후 5 51 28" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/54910c83-c6d9-4d52-bf72-4b5ae8050fde">

- 파라미터를 가진 모델을 학습한다면? -> Maximum likelihood를 쓴다면?
- 만약 k=32라면, z = 2^32의 경우의 수가 생긴다 (너무 커서 z에 대응하는 x를 찾기가 어려워진다.)

<img width="95" alt="스크린샷 2023-08-10 오후 5 54 08" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8269fd72-8a8b-410f-932b-1ff1ea19f753">

<img width="281" alt="스크린샷 2023-08-10 오후 5 54 23" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/abcabc41-46d7-4b7f-b756-4d24dc60ee3f">

## 잠재 변수 모델(Latent Variable Models)의 조건.
- 궁극적인 목표는 p(x)의 효율적인 컴퓨팅이다.  
- p(z), p(x|z)를 O(1)으로 빠르게 얻는 것도 중요하다. (빠른 생성 결과)
- Baye's rule <img width="114" alt="스크린샷 2023-08-10 오후 5 57 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8c2ebd56-7f8e-4c85-858a-6cdf3b07b8ae"> 에서
- posterior 분포p(z|x)를 구하면 p(x)를 구할 수 있음 -> posterior 분포를 구하기 어렵기 때문에, Variational Inference!(변분 추론)
