# 합성곱 신경망(CNN) - CNN의 응용

## CNN의 응용 분야: 객체 탐색 (object detection) - object detection의 종류

- 어떤 물체인지 분류하는 classification 문제와 그 물체가 어디에 있는지 위치 정보를 추론하는 localization 문제를 동시에 수행한다!
1. 물체 분류 (classification) : 물체가 ‘무엇’인지만 예측
2. 객체 탐색 (object detection) : 물체가 ‘무엇’인지와 물체가 ‘어디에 있는지’ 동시에 예측
3. 의미론적 분할(Semantic segmentation) : object detection을 pixel단위로 구분하고 같은 class는 같은 영역 혹은 색으로 분할!
4. 인스턴스 분할(instance segmentation) : Semantic segmentation에서, 더 나아가 같은 class이더라도 서로 다른 instance들을 구분!

<img width="275" alt="스크린샷 2023-07-03 오후 3 11 56" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fb62576f-63da-4a73-a831-d34432572124">

## CNN의 응용 분야: 객체 탐색 (object detection) - object detection의 metrics
- Intersection Over Union(IoU)을 모델 성능 지표로 많이 사용한다.
- $Iou ={ {A \cap B}\over {A \cup B}}$ <img width="47" alt="스크린샷 2023-07-03 오후 3 15 35" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f725cb17-3d3a-4692-aef6-6d3c7113596f">
- IoU 값이 임계점 이상인 경우를 예측 성공으로 분류하는 방식으로
    - IoU >0.5 면 예측 성공으로 분류
- confusion matrix, recall, precision, ROC curve등을 성능 지표로 사용할 수 있다.
- 그밖에 pixel accuracy, mean accuracy, IoU의 평균 등도 쓰인다.

## CNN의 응용 분야: 객체 탐색 (object detection) - 좋은 object proposal 방법은 어떤 성질을 가지고 있을까?
1. 빠르다 : Localization시 bottleneck이 되지 않아야 한다.
2. Recall이 높다 : 즉, 객체를 포함하고 있는 bounding box를 놓치지 않는다.
3. 최소한의 지도 학습 (minimal supervision) : 비지도 학습(unsupervised)이거나, 약 지도 학습(weakly supervised; 간접적으로 알려주는) 이어야 확장성이 좋다.

## CNN의 응용 분야: 객체 탐색 (object detection) - object detection의 전략
- Sliding window detection :  각각의 윈도우에서, 객체를 인식. 윈도우를 서서히 sliding하면서 움직인다.
- Proposal Approach : 객체를 포함하는 모든 window를 찾은 후, 각 윈도우를 multi-class 분류기로 분류한다.
- Voting from patches/keypoints :  각 패치 및 키포인트를 찾은 후, 그 포인트들에서 Voting을 통해 최종 위치를 얻어낸다.

## CNN의 응용 분야: 객체 탐색 (object detection) - object detection의 전략: Selective Search(2013)
- Segmentation기반 object proposal: Selective search (선택적 검색)
  - 수많은 segmentation을 수행하고, 각 segmentation을 반복적으로 grouping한다.
  - 각 segmentation은 반복작업중에 object proposal이 된다.

 <img width="244" alt="스크린샷 2023-07-03 오후 3 49 45" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8f867f0b-190b-4268-9e69-a54485ca4cb1">

1. 초기 영역들을 지정한다. 무수한 파란 박스가 그려진 상태와 같다.
2. 네모박스로 구분된 영역과 이웃한 다른 네모박스 영역간의 유사도를 계산한다.
   - S(a,b) = S_size (a,b) + S_texture(a,b)
3. Greedy 알고리즘을 이용하여 유사도가 높은 영역끼리 합치고 이를 반복한다. 서로 엉킨것들이 single region이 될때까지 반복한다.
4. r(s)와 r(i) 영역이 합쳐진 새로운 영역을 r(t)라고 할때, r(t)의 특징은 r(s)와 r(i)의 특징을 재활용하여 계산 할 수 있다. 이로써 계산양을 줄일 수 있다.
 
<img width="341" alt="스크린샷 2023-07-03 오후 3 52 17" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2bd8beb4-f575-42de-8e6e-a14bbc154f05">

- Selective search를 거쳐 나온 물체가 존재하는 후보 영역(hypothesis) 중에 ground table과 overlap 되는 부분이 20%~50%되는 것을 "negative example"로 정하고 이를 정답 데이터 (ground truth; positive example)와 함께 SVM에 학습시킨다

<img width="402" alt="스크린샷 2023-07-03 오후 3 53 25" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/50232f61-5ee5-4f36-ab94-8c323bf0474b">

- 반복적으로 false positive를 넣고 재학습을 하여 모델 성능을 개선 시킨다.

## CNN의 응용 분야: 객체 탐색 (object detection) - R-CNN (2014)
<img width="595" alt="스크린샷 2023-07-03 오후 4 00 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1aaabd41-a4d8-468d-8403-aced0428d4ad">

- Regional proposal + CNN = R-CNN : Selective search와 CNN feature를 결합하고, linear SVM으로 최종적으로 분류한다.
- 이미지에서, object-like bounding box를 추출한 후, 자르고(crop) 스케일링(scale)하여 CNN의 인풋을 만든다. 이를 CNN에 넣고 feature map을 얻은 후, 선형 분류기 (linear SVM)을 통해 최종 분류한다.

<img width="668" alt="스크린샷 2023-07-03 오후 4 03 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bd190238-377c-41cf-b109-8ac6fdea8a48">

- 2014년 당시 SOTA. But, 상용화 되기 매우 느렸다. 
- End-to-end가 아니었고, 성능 향상할 수 있는 요소가 많았다.

## CNN의 응용 분야: 객체 탐색 (object detection) - Spatial Pyramid Polling Network (SPP-Net) (2014-2015) & Fast R-CNN (2014-2015)
<img width="604" alt="스크린샷 2023-07-03 오후 4 06 23" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/70c033f0-acf3-4fee-8318-a915286ecb5c">

- 이미지의 조각을 추출해서 각각 CNN 연산을 하지 않고, 전체 이미지를 convnet 에 통과시키는 것만으로도 feature map 을 추출할 수 있다. 
  - 만약 2000개의 후보 군이 있다면, 2000개의 CNN연산 -> 1번! 으로 줄일 수 있는 것이다.

## CNN의 응용 분야: 객체 탐색 (object detection) - Spatial Pyramid Pooling Network (SPP-Net) (2014-2015)

- 다양한 feature에서 pooling의 window size와 stride 만을 조절하여 출력 크기를 결정!
<img width="317" alt="스크린샷 2023-07-03 오후 4 12 33" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/45173c7f-1098-44e6-acef-81f74d61c55c">

- Pyramid Pooling
  - window size = ceiling(feature map size / pooling size)
  - stride = floor(feature map size / pooling size) 

<img width="258" alt="스크린샷 2023-07-03 오후 4 14 10" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/864c80ce-3de8-4b0a-82c0-503779c0cb4e">

- 어떤 feature map이 오더라도 고정된 pyramid size을 얻을 수 있다!  
  - 여러 개의 레벨을 취할 수 있음!
  - i.e. 4 level: {6x6, 3x3, 2x2, 1x1} 
- Region of interest(RoI) pooling = SPP에서 피라미드 레벨이 1인 경우!

## CNN의 응용 분야: 객체 탐색 (object detection) - Fast R-CNN (2014-2015)
<img width="306" alt="스크린샷 2023-07-03 오후 4 21 04" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7c1d83bb-c344-4dc1-9704-e8d0f8186fe1">

- End-to-End 학습!
- R-CNN에 비해 매우 빠르다!
- Test time/ image: R-CNN: 47 sec. Fast R-CNN: 0.32 sec.
1. 먼저 전체 이미지를 미리 학습된 CNN을 통과시켜 피쳐 맵을 추출.
2. Selective Search를 통해서 찾은 각각의 RoI에 대하여 RoI Pooling을 진행하고, 그 결과로 고정된 크기의 feature vector를 얻는다.
3. feature vector는 fully connected layer들을 통과한 뒤, 두 개의 브랜치로 나뉘어 계산한다. -> multi-task loss!
	a. 해당 RoI가 어떤 물체인지 분류한다.
	b. bounding box regression을 통해 selective search의 박스 위치를 조정한다.

## CNN의 응용 분야: 객체 탐색 (object detection) - Faster R-CNN (2015)
<img width="316" alt="스크린샷 2023-07-03 오후 4 23 12" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2e1e7a71-dde8-4a8e-99fd-146b0adfe209">

- Region-proposal network(RPN)을 마지막 convolutional layer 다음에 사용!
- Fast R-CNN의 bottleneck이었던 selective search를 제거하고 RPN을 통해 region proposal을 생성. 
- RPN은 이미지의 일부를 인풋으로 받고, 아래 2개의 task를 수행하는 작은 네트워크를 구성.
1. 존재/비존재를 파악하는 binary classification
2. bounding-box regression(Fast R-CNN에서 사용한 것과 동일) 위치를 보정
- 마지막 공유 컨볼루션 레이어의 컨볼루션 피쳐 맵 출력 위로 작은 네트워크를 slide하며 결과 값을 얻는다.

<img width="392" alt="스크린샷 2023-07-03 오후 4 37 42" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/9b81da7d-218f-477f-9496-3236fffdb58e">
- Selective search + Fast-RCNN 대비 accuracy와 speed 둘다 개선되었다!
- 17fps(frame per seconds)는 거의 real-time!
- 우리가 보는 적당한 퀄리티의 영상은 24fps~30fps이다

# CNN의 응용 분야: 객체 탐색 (object detection) - You Only Look Once (YOLO) (2015: v1, 2016: v2, 2018: v3, 2020: v4, v5, PP-YOLO, …)
- 기존 아래 2단계
1) region proposal
2) classification 
나누던 과정에서 region proposal을 지우고, 한번에 객체 발견을 수행.

<img width="486" alt="image" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1722f06f-b34c-44f5-84fb-19ec8e18c28d">

- How?
1. S x S grid 영역으로 나누고 B개의 bounding box를 예측한다.
  - Bounding box: (x, y, w, h)
    - (x, y): 중심점 좌표
    - (w, h): 넓이 & 높이

2. 신뢰도를 나타내는 confidence score를 계산
  - 해당 그리드에 물체가 있을 확률 X 예측한 박스의 ground truth 박스와의 겹치는 영역을 비율로 나타내는 IoU (intersection over union)을 계산
  - v5까지 나오며 real-time object detection을 이끌고 있는 연구 시리즈!.

## CNN의 응용 분야: 객체 탐색 (object detection) - Single shot multi-box detector (SSD) (2016)
<img width="852" alt="스크린샷 2023-07-03 오후 4 47 13" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/3fc195f9-c0ea-4c6c-8a9d-751601d36095">
<img width="467" alt="스크린샷 2023-07-03 오후 4 48 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/0a1fb2ca-4ec3-4c86-9258-39de722f8ba6">

- VGGNet에 추가적인 layer를 추가하고, skip connection으로 여러 개의 feature map을 구성!
- 다른 feature map이 다른 사이즈의 객체를 인식!
- YOLOv1을 이겼으나, YOLOv2에서 다시 역전당함!

## CNN의 응용 분야: 객체 탐색 (object detection) - Feature Pyramid Networks (FPN) (2017)
<img width="474" alt="스크린샷 2023-07-03 오후 4 52 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4b01686e-f5ed-40c5-8bdc-8ca8edc5ba22">

- 한편, 객체 탐색 분야의 난제 중 하나인, ‘작은 물체’를 탐색하는 문제가 있다.

(a)는 입력 이미지 자체를 여러 크기로 resize 한 뒤, 각각의 이미지에서 물체를 탐지하는 기법 🡪 입력 이미지 자체를 여러 크기로 복사하여 연산량이 많다.

(b) CNN 신경망을 통과하여 얻은 최종 단계의 피쳐맵으로 Object Detection을 수행하는 기법 (YOLO)

(c) CNN 신경망을 통과하는 중간 과정에 생성되는 피쳐맵들 각각에 Object Detection을 수행하는 기법 (SSD)
  - 피처맵의 크기를 다양한 형태로 rescale하는 접근 방식을 사용! 
(d) 먼저 신경망을 통과하면서 단계별로 피쳐 맵들을 생성! 그리고 가장 상위 레이어서부터 거꾸로 내려오면서 피쳐를 합쳐준 뒤, Object Detection을 진행한다.
	- b, c만큼 빠르지만, 보다 정확함.

<img width="369" alt="스크린샷 2023-07-03 오후 4 53 06" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e3c718b4-eee2-4faf-9796-b29513704db5">

논문에서는 “nearest neighbor upsampling” (단순 복사하여 해상도 2배 키움)을 통해 사이즈를 맞춤! 

<img width="668" alt="스크린샷 2023-07-03 오후 4 53 40" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/614b740d-9026-4b76-b201-b9878f9ab632">

## CNN의 응용 분야: 객체 탐색 (object detection) - RetinaNet (2017-2018)
- Object detection 모델은 이미지 내의 객체의 영역을 추정하고 IoU threshold에 따라 positive/negative sample로 구분한 후, 이를 활용하여 학습! 

- 하지만 일반적으로 이미지 내 객체의 수가 적기 때문에 positive sample(객체 영역)은 negative sample(배경 영역)에 비해 매우 적음 ->positive/negative sample 사이에 큰 차이 🡪 class imbalance 문제가 발생 (모델 성능 하락)

- Two-stage detector 계열의 모델(i.e. Fast R-CNN)은 이러한 문제를 해결하기 위해 
	1. two-stage cascade, 즉 region proposals를 추려내는 방법을 적용하여 대부분의 background sample을 걸러주는 방법(i.e. selective search, edge boxes, deepmask, RPN) 활용
	2. positive/negative sample의 수를 적절하게 유지하는 sampling heuristic 방법(i.e. hard negative mining, OHEM)을 적용.  

	- 그러나 one-stage detector에 적용하기 어려움.

- One-stage detector(i.e. YOLO)는 region proposal 과정이 없어 전체 이미지를 빽빽하게 순회하면서 sampling하는 dense sampling 방법을 수행! : two-stage detector에 비해 훨씬 더 많은 후보 영역을 생성.
  	- Class imbalance 문제가 two-stage detector보다 더 심각!

- 새로운 focal-loss를 제시 !

<img width="871" alt="스크린샷 2023-07-03 오후 6 26 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2c1a1795-3c6d-4590-bbc1-63aa6e8c765b">
	- $FL(p_t) = - \alpha_t (1- p_t)^\gamma log(p_t)$
 	- cross entropy loss에 class에 따라 변하는 동적인 scaling factor을 추가한 형태.
  	- easy example의 기여도를 자동적으로 down-weight 하며, hard example에 대해서 가중치를 높여 학습을 집중

## CNN의 응용 분야: 객체 탐색 (object detection) - EfficientDet (2019-2020)
- Auto-ML로 효율적인 구조를 찾았던 efficientNet의 object detection으로의 응용 연구
- 앞선 feature pyramid network (FPN)연구에서 사용하는 feature fusion 방법을 neural architecture search (NAS) 방법을 이용해 찾음.

 <img width="605" alt="스크린샷 2023-07-03 오후 6 36 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2f26f563-8b70-4609-8708-641769a4561f">
 
- 최종적으로는 bi-direction 형태의 BiFPN을 NAS가 변형한 (f)가 선택되어 결과가 나오고, 기존보다 파라미터수가 적고 성능도 좋은 모델이 탄생

<img width="541" alt="스크린샷 2023-07-03 오후 6 35 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b6430ac8-1b3b-43fa-8541-9e4c1ecf70d0">

## CNN의 응용 분야: 객체 탐색 (object detection) - Object detection 들간 성능 비교
<img width="362" alt="스크린샷 2023-07-03 오후 6 39 12" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8cfcb3ed-87c5-47bc-996f-49b5aa6bee49">

#CNN의 응용 분야: 객체 탐색 (object detection) - Semantic Segmentation: Fully Convolution Net (FCN; 2014-2015)
- 맨 마지막, dense (fully connected) layer 대신 1x1 Convnet. 사용하여, 아웃풋의 heatmap을 만들어낸다 !
- 이 heatmap에 upsampling 기법을 활용하여 semantic segmentation 을 만들어낸다.
<img width="242" alt="스크린샷 2023-07-03 오후 6 43 39" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/dfe4e9d7-b30d-4813-a7aa-340a7c387254">
<img width="197" alt="스크린샷 2023-07-03 오후 6 44 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a56b7521-a884-44fb-b2cb-7bca03098dc0">
<img width="228" alt="스크린샷 2023-07-03 오후 6 44 16" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6d9550e0-c076-47e4-a6ad-bd93d3d9babb">

## CNN의 응용 분야: 객체 탐색 (object detection) - Semantic Segmentation: Fully Convolution Net (FCN): Upsampling
<img width="342" alt="스크린샷 2023-07-03 오후 6 45 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8c8a3178-00fe-460c-a659-482df3dd053e">

- heatmap을 여러 레이어에서 upsampling 기법을 활용하여 semantic segmentation 을 만들어낸다. : 어떤 레이어를 쓰느냐에 따라 segmentation이 조금씩 달라진다 ! <img width="244" alt="스크린샷 2023-07-03 오후 6 46 21" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/063d6b00-2e89-4bd5-91e8-ec348429903c">
- Upsampling 방법에는 크게, Unpooling (pooling의 복원)과 transpose convolution (stride에 의한 축소 복원)이 있다!
 
## CNN의 응용 분야: 객체 탐색 (object detection) - Upsampling: Unpooling
<img width="388" alt="스크린샷 2023-07-03 오후 6 47 43" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7267cf02-c945-441e-b495-a1ce06990fdb">

## CNN의 응용 분야: 객체 탐색 (object detection) - Upsampling: Transpose Convolution
<img width="323" alt="스크린샷 2023-07-03 오후 6 48 13" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a77fa827-c2dc-4154-bee5-796a28606bbd">
- feature map(5x5)에서 각 값을 선택하고 선택한 scalar 값과 필터(3x3)를 곱한다.
그리고 출력의 3x3 공간에 그 값을 넣는다. (conv. filter가 각 값을 곱하여 더하는 것과 반대로 값을 그대로 뿌린다.)
- filter 의 크기와 stride 의 크기에 의해 overlap 되는 부분은 전부 더한다.

## CNN의 응용 분야: 객체 탐색 (object detection) - Semantic Segmentation: Deconvolution Net (2015)
<img width="935" alt="스크린샷 2023-07-03 오후 6 49 48" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/677b87b5-90a8-49f6-bef1-f750ff264c52">
- FCN에서 발전시켜 점진적, 대칭적으로 unpooling을 하였음.
- 2개의 Fully connected layer를 Conv, Transposed Conv사이에 사용 
- 2 stage Training 진행 
	- 1 stage에서는 쉬운 예제로 train하고 2 stage는 보다 어려운 데이터로 학습을 진행
		- 1 stage: 실제 정답 object를 crop하여 이를 중앙으로 하는 bounding box를 만들어 학습 (ground-truth annotation)
	- 2차:  실제 정답을 crop하기 전에 실제 정답과 잘 겹치는 것들을 활용하여 2차 학습을 진행 (Zitnick, C. Lawrence, and Piotr Dollár. "Edge boxes: Locating object proposals from edges." European conference on computer vision. Springer, Cham, 2014. 에서 제안됨)

- 논문에는 deconvolution network라고 하였지만, 실제로 deconvolution은 좋지 않는 명명법이기에, 현재는 transposed convolution이라고 불리고 있음!

<img width="316" alt="스크린샷 2023-07-03 오후 6 51 21" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e74ca658-7e03-4f4e-8c50-94f34f087f27">

## CNN의 응용 분야: 객체 탐색 (object detection) - Semantic Segmentation: U-Net (2015-2016)
<img width="260" alt="스크린샷 2023-07-03 오후 6 54 27" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bd4c2769-4dd8-4dad-819e-73ffdb8fafdc">

- U모양이기 때문에, U-Net.
- Pooling indice를 사용하는 대신, 전체 feature map이 encoder에서 decoder로 skip-connect형태로 수행되고 concatenate된다 !

	- 데이터가 적은 Biomedical domain에서 처음 활용하도록 제시되었음.
	- Data augmentation 사용.
	- End-to-end 구조
	- 왼쪽의 인코딩(contracting path): 이미지의 context 포착
	- 오른쪽의 디코딩(expansive path): feature map의 upsampling & contracting path에서의 피처맵의 컨텍스트와 결합하여 보다 정확한 localization을 수행
	- 즉, skip-connection으로 encoder-decoder구조의 bottle-neck구조로 인한, context 인식과 localization의 trade-off에 빠지지 않음!
   
<img width="362" alt="스크린샷 2023-07-03 오후 6 55 28" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1ed45ac9-3c9e-4882-b28d-8c2afc162957">

## CNN의 응용 분야: 객체 탐색 (object detection) - Semantic Segmentation: SegNet (2015-17)
<img width="671" alt="스크린샷 2023-07-03 오후 6 56 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2532871a-6ab6-4543-a95f-5a1810d52067">

- DeConvNet과 Unet과 비슷한 구조.
- DeConvNet과 차이점.
	- Fully connected 사용 X 🡪 모델 크기 감소
	- End-to-End (2stage 학습 X)

- U-Net과 차이점
	- 전체 feature map을 전하는 것이 아닌, max indice만을 전달하고 Upsampling에 사용

## 그밖의 CNN의 응용 분야 - Super Resolution (저화질 -> 고화질)
<img width="219" alt="스크린샷 2023-07-03 오후 6 57 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bb03f606-9596-4e37-85b6-5acb199d20b3">

<img width="570" alt="스크린샷 2023-07-03 오후 6 58 11" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e5507f7a-a7c0-4361-9fa3-5dda55d2b66e">


## 그밖의 CNN의 응용 분야 - 기타 모델들/방법론 들과 연계
a. 강화학습 (i.e. Deep Q-Network)의 이미지/영상 인식을 위한 인코더 모듈 

<img width="390" alt="스크린샷 2023-07-03 오후 7 00 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ae4c5828-652f-425c-ab96-d8c165f100fd">

b. 생성모델 제작과정에서 모듈로서의 CNN 

<img width="547" alt="스크린샷 2023-07-03 오후 7 00 18" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ec73869e-ef5a-482f-a0df-0e53f3c43c90">

c. Neural style transfer

<img width="465" alt="스크린샷 2023-07-03 오후 7 00 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fbfe998b-1f17-409f-b490-1bf98c6ee662">
<img width="343" alt="스크린샷 2023-07-03 오후 7 01 16" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/65f0e1d3-014f-44d7-8fb8-6ee7de433f2d">

