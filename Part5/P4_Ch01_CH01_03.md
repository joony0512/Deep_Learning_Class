 
# CH01_03.선형회귀, 로지스틱회귀, log-likelihood

## 지도학습

- Classification(분류)
    - 이산적(discrete)으로 구성된 레이블을 각각의 학습 데이터로부터 학습시키는 경우
- Regression(회귀)
    - 연속적인 레이블을 각각의 학습 데이터로부터 학습시키는 경우

## 선형회귀

- 선형회귀로 이항분류하기
    - Linear Regression : f(x) = θ1x + θ0라고 하자.
    - f(x)의 에러의 제곱의 합(sum of squared residuals; RSS)을 목적함수로 최소화하여, 최적의 함수를 찾는다.
        
        ![Untitled (1)](https://user-images.githubusercontent.com/109457820/229101415-679c5cad-c195-46c6-ad7a-f839c192578f.png)
        
    - 즉, Rss를 최소화하는데 , 이 최소값은 미분한 값이 0이 될때이다.
        - θ0 = E[y] -θ1E[x]
        - θ1 = Σ(yi -E[y])(xi-E[x]) / Σ(xi-E[x])**2
    
    ![Untitled (2)](https://user-images.githubusercontent.com/109457820/229101483-f10fa4b8-0fb6-4e70-a869-297ae4d58a09.png)
    
    - 선을 기준으로 왼쪽 오른쪽으로 분류 가능 → 이항분류

## 로지스틱 회귀

- 로지스틱회귀로 이항분류를 해보자.
- Linear Regression : f(x) = θ1x + θ0
- Logistic Regression :f(x) =1/(1+e**(-x))
    - Sigmoid함수, Logistic함수라고도 불림
    - **Sigmoid함수**
        - 연속함수이며 대칭함수(symmetric)이다.
        - 미분이 매우 쉬워, gradient descent에 적합하다!
        - f’(x) = f(x) - f(x)**2
    - 로그 우도법(Log Likelihood)
        - 우리가 이항 분류를 하고 있기 때문에, 각 값은 0혹은 1로 예측될 것이다.
        - 즉, 이는 Bernoulli분포를 따른다고 할 수 있다.
            
            ![Untitled (3)](https://user-images.githubusercontent.com/109457820/229101619-757ef6c3-b631-4796-b561-158e43cc121f.png)
            
        - 모든 샘플이 독립일경우 모든 i에 대해 곱할 수 있다.  :  Likelihood
            
            ![Untitled (4)](https://user-images.githubusercontent.com/109457820/229101699-63d30537-8a92-49f1-9c01-e19eb58f704c.png)
            
            - 이는 계산하기 힘드므로 log를 씌우면 :  Log likelihood
                
                ![Untitled (5)](https://user-images.githubusercontent.com/109457820/229101777-2f082ede-628e-47f3-837d-2fca38c09280.png)
                
        - 이를 음수로 취해 줄이는 방향의 손실함수(loss function)으로 사용
            - negative log-likelihood
            
            !![Untitled (6)](https://user-images.githubusercontent.com/109457820/229101844-b61b8b1c-a0db-41df-bc5c-d61dcd96933a.png)
            
            - 이는 Cross Entropy와 같다
