# <Generative model series #1>Autoregressive vs autoencoder vs embedding vs seq2seq - 2. 자가 회귀 (auto-regressive) 모델
## 자가 회귀(Auto-regressive): Explicit한 가능도 기반(likelihood-based)의 생성 모델 (generative model)의 형태

- 생성모델의 정의(generative model) :  $p_{data}(x)$와 유사한 $p_{model}(x)$ 을 학습하는것 -
  -> 원하는 이미지를 복구하거나 새 샘플을 만들어 낼 수 있다.
- 가능도 기반 모델 : $x_1, x_2, ...,x_n \sim p_{data}$를 추론하는 것

- 자가 회귀 모델 (auto-regressive model) : discrete한 상황을 고려하고,
  
  <img width="371" alt="스크린샷 2023-07-26 오후 9 08 49" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7342b58d-3bdc-4510-a13b-9f84edc136ff">
를 계산하는 모델

## 자가 회귀(Auto-regressive) 모델의 예 
1. RNN 등의 recurrent 모델을 이용하는 방법.(i.e. charRNN)
  - 병렬 컴퓨팅이 어려움
    
    <img width="445" alt="스크린샷 2023-07-26 오후 9 11 29" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4fec3d3a-6aff-4b1f-8e07-7692dba95098">

    
2. Masking을 이용하는 방법 (i.e. Masked MLP, convolutions, self-attention)
  - 동일 시간상의 연산들끼리 병렬 컴퓨팅 가능.
  - 또한 이전 계산 값이 쓰이지 않는 다면, 이 역시 계산 가능
  - 파라미터들이 시간이 지남에 따라 공유됨.
    
    <img width="367" alt="스크린샷 2023-07-26 오후 9 11 49" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e8ffdce4-48c7-4f9f-852f-b753f8b22520">

## Masked Autoencoder for Distribution Estimation (MADE; 2015)

- 보통의 auto-regressive를 위한 마스크의 형태:
    - array([
    	      [0., 1., 1.],
          	[0., 0., 1.], 
          	[0., 0., 0.]
            ], dtype=float32) 

- y = MATMUL(x, param * mask)

- x: layer의 input
- y: autoregressive의 결과

## Masked Autoencoder for Distribution Estimation (MADE; 2015)
<img width="418" alt="스크린샷 2023-07-26 오후 9 20 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/040ab464-a3c2-4532-ae37-55afd0697f22">
<img width="386" alt="스크린샷 2023-07-26 오후 9 21 05" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/23018130-633b-4fb8-abe3-29887ec7d686">

## Masked Temporal (1D) Convolution

<img width="560" alt="스크린샷 2023-07-26 오후 9 21 48" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/af104067-b2be-448f-9b1e-850ea1280240">
- padded_x = pad(x,  [(0, 0), (k - 1, 0)]), y = conv1d(padded_x, kernel, padding='VALID’)
- 합성곱 신경망 convolutional layer의  kernel(receptive field)에 masking part의 구현.
  - 보다 단순 마스킹을 사용하기 때문에, 구현하기 쉽다.
  - 큰 크기라 하더라도 파라미터 수가 유지된다. (convolutional layer의 shared weight)
  - CNN자체가 GPU등에서 이미 많이 최적화가 되어있어, computation cost적인 측면에서 효율적이다. 
- 그러나, receptive field에 제약을 거는 것이라 그 자체로 한계는 존재한다 ! (layer 수에 따라 linear하게 증가한다)

## Masked Temporal (1D) Convolution - WaveNet (2016)
<img width="462" alt="스크린샷 2023-07-26 오후 9 42 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/3639cb1b-f9a4-4d97-8d4f-38bf7ada3637">

- Receptive field를 dilated convolution으로 보완하였다 : 선형적으로 증가하는 것이 아닌, exponential 한 dilation이다.
- Gated residual block, skip-connection을 이용해 효율을 높였다 !

<img width="397" alt="스크린샷 2023-07-26 오후 9 42 48" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/82dd2144-8821-4e57-a02d-9b6684048e93">

## Masked Temporal (2D) Convolution - PixelCNN | Gated PixelCNN (2016)
- 이미지를 1D로 flatten할 수 있지만, 2D의 spatial한 정보를 잃을 수 있다.
- 2D 이미지를 mask하여 order를 지킬 수 있을까?
  -  Auto-regressive ordering을 정한 mask를 쓰자
  -  Pixel CNN

<img width="516" alt="스크린샷 2023-07-26 오후 9 46 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/729e448d-8730-4844-8ae0-c39369b0720b">
<img width="161" alt="스크린샷 2023-07-26 오후 9 47 04" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/477d6c16-a390-4283-b835-21b256a875f3">

- 한가지 문제는 blind spot이 생길 수 있다
  -  Horizontal stack과 Vertical 한 부분을 나누고, 두개의 stream을 결합할 수 있다
  -  Gated PixelCNN!

## Masked Temporal (2D) Convolution - PixelCNN | Gated PixelCNN (2016)
<img width="221" alt="스크린샷 2023-07-26 오후 9 48 32" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7ed141f2-b7dc-4b81-bbc7-51b08e89a0dd">

- 한가지 문제는 blind spot이 생길 수 있다
  -  Horizontal stack과 Vertical 한 부분을 나누고, 두개의 stream을 결합할 수 있다
  -  Gated PixelCNN!

- 2개의 layer의 stack을 사용하여 blind spot 을 없앤다 !
  - Horizontal Stack : 현재 행을 기준으로 조절하여 horizontal stack 뿐만 아니라 이전 레이어의 출력도 입력으로 사용!
  
  - Vertical Stack : 현재 픽셀 부분 윗부분의 모든 행(row)에 mask 없이 적용한다. 이 출력물이 horizontal stack에 공급되고 receptive field가 직사각형 형태로 계속 커진다.

<img width="516" alt="스크린샷 2023-07-26 오후 9 50 25" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/84991bcd-9641-4c43-b030-1f4cc2238b7b">

<img width="398" alt="스크린샷 2023-07-26 오후 9 50 49" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/75a840a0-488b-4c06-875c-c14257426252">

- 위 이미지는 Gated ConvNet의 layer다. feature map을 두개의 p그룹으로 나누고 다른 activation을 취한 뒤 결합한다. <img width="271" alt="스크린샷 2023-07-26 오후 9 54 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a130a8a5-c413-4b3a-a1d9-09ea01156ee1">

## Masked Temporal (2D) Convolution - PixelCNN++ (2017)
- Pixel CNN을 개선하여 보다 나은 성능을 냈다.
  1. Discretized logistic mixture likelihood: Pixel 값들에 따라 softmax를 적용하면 memory적으로 비싸고, gradient를 너무 빠르게 sparse하게 만든다.
     -> softmax는 비싼데, 우리는 이미 주변의 pixel color intensity값들이 거의 동시에 일어나는것을 알고있다.
     -> color intense를 나타내는 것이 discrete한 8bit(2**8=256)이 아닌 0~255를 추론하는 확률 분포값을 나타낸다고 하여 계산해보자.
     <img width="443" alt="스크린샷 2023-07-26 오후 9 58 49" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8e203bd6-0d82-402e-a194-81216476d8f5">
  2. 다운 샘플링 (down sampling)
     - Pixel CNN은 장거리 종속성을 계산할 수 없었다
     - 이를 극복하기 위해 Stride 2의 convolution layer로 다운샘플링한다.
     - 다운샘플링은 입력 크기를 줄여 수신 필드의 상대적 크기를 개선하여 정보 손실을 가져오지만, 단축 연결을 추가하여 보완할 수 있다!

  3. Skip-connection
     - U-Net과 같이 다운샘플링 & 업샘플링 중 인코더 디코더에 skip-connection을 가진다!

    <img width="537" alt="스크린샷 2023-07-26 오후 10 02 13" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/654b4374-d79c-4a60-9887-a7dc17e98c7d">
<img width="409" alt="스크린샷 2023-07-26 오후 10 02 37" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/43ce42a3-4aa9-4068-b75e-ca6f0c129be2">

## Masked Attention - Self-attention? | Recap: Attention
- Attention이 encoder decoder구조를 가지는 seq2seq에서 정의되었지만.. 다른 분야에서도 쓸 수 있다. 
- How?
  - 만약 Attention 구조에서, key, value외에 query역시 같은 소스에서 계산하면 된다.
  - 이를 self-attention이라고 한다!
<img width="350" alt="스크린샷 2023-07-26 오후 10 03 52" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/12c541cc-7100-40d7-8e9a-7e69396c1354">
<img width="261" alt="스크린샷 2023-07-26 오후 10 04 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7a88e2fd-d4b7-4468-98a2-31845b66ff69">

- CNN 등은 receptive field의 크기만큼만 볼 수 있는 단점을 가지고 있었다 🡪 long-range 영역의 dependency를 잡기 어려웠다 !
- (self-)attention은? 
  - 무제한의 receptive field
  - 데이터 사이즈에 따라 O(1) parameter scaling을 가진다. 데이터가 커져도 괜찮은 편!
  - RNN등에 비해 parallel computing이 쉽다! 

## Masked Attention
- Attention score를 구할 때 masking을 취한다 !
  
<img width="364" alt="스크린샷 2023-07-26 오후 10 07 57" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/14b6d3bc-fc2a-4f83-acb2-39af73aaebe2">

- 장점? CNN 마스킹 보단 자유롭다!
  - 원하는 순서로 auto-regressive masking이 가능!

예:
<img width="211" alt="스크린샷 2023-07-26 오후 10 08 44" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/35d3901d-1aed-4065-9817-660320052e3e">
<img width="248" alt="스크린샷 2023-07-26 오후 10 08 58" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/3d143300-a9ff-4b07-ac26-fec5ad8e40a5">

## Masked Attention + Convolution (PixelSNAIL; 2018)

<img width="448" alt="스크린샷 2023-07-26 오후 10 13 59" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f40cb5b0-5b5b-4e08-a911-fe6639a41912">
<img width="876" alt="스크린샷 2023-07-26 오후 10 14 44" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/504fc0bd-14c5-4a47-8867-96701ec26b1a">
<img width="643" alt="스크린샷 2023-07-26 오후 10 15 18" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/07ed4566-5d73-470b-8241-30a6e917eea9">

## Masked Attention - Applied to “Transformer based models” (TBD)
<img width="237" alt="스크린샷 2023-07-26 오후 10 16 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/9eb98bad-c785-4bf2-b367-039955ecd079">


## Neural auto-regressive 모델의 장단점
- 장점:
  - 모델 성능에 있어 일반적으로 가장 좋다!
  - Expressivity:  autoregressive factorization이 일반적이고 또 코드를 작성하기 쉬운 편이다!
  - Generalization: 의미있는 parameter sharing이 좋은 귀납적인 편향 (inductive bias)를 주어 일반화가 잘 된다 !
  - 많은 데이터 셋과 도메인에서 state-of-art를 이룬다!

- 단점:
  - 샘플 하나당 한번의 forward pass를 하여야 한다! 🡪 여러 forward하여야 할 시 매우 느리다 !
  - 예: Tesla K40 GPU로 32 x 32 이미지를 생성하면…  개당 1분 내외로 걸릴 수도 있다

## Neural auto-regressive 모델의 단점 보완법?
- Dynamic programming 스럽게 caching 을 할 수 있다 ! (연산이 겹치는 부분이 존재한다)
- O(d) > O(log(d))
- 단, 구현 엔지니어링 난이도는 높은 편이다.
<img width="343" alt="스크린샷 2023-07-26 오후 10 21 52" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ebd9b28c-f3ab-41f6-81c8-418bf384fc66">

  예). 
  fast-wavenet
  multi-scale PixelCNN

## Neural auto-regressive 모델의 단점 보완법? - Multi-scale PixelCNN
<img width="414" alt="스크린샷 2023-07-26 오후 10 22 45" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2ccd9703-0eba-4dca-829c-cfe427a8ebad">
- 모델 Inference 속도 향상!
<img width="290" alt="스크린샷 2023-07-26 오후 10 23 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1e40d1ac-7759-4a12-bc0a-aed4b4e44695">
