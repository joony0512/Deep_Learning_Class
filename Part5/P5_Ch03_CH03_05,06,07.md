# CH03_05-Regularization-Early-stopping

### Early Stopping (수치 최적화(numerical optimization)에 따른 정형화)

- 큰모델을 학습할 때,  Train error는 학습이 진행되면서 점점 내려가지만, Validation error는 감소하다가 어느 순간부터 다시 증가한다.
    - 이때 멈춘다면, 최적의 결과를 얻을 수 있지 않을까?
    - → Early Stopping
    ![Untitled (12)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b38d6a77-ce23-426c-9e3e-3488567bb8bb)

    
- Early Stopping은 사실 L2정형화와 같다.
    - w*로 가기전, $\tilde{w}$에서 멈춰라!
    
    ![Untitled (13)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ddff68d0-8af8-4dd7-8bee-3a83cbc3e0db)

- Early Stopping은 모델을 한번만 학습하면 되는 반면, L2을 위한 weight decay는 적절한 hyperparameter값을 찾기 위해 여러번 학습을 돌려야한다.
- 사람마다 선호하는 방법이 다르기 때문에 사용하면서 선택한다.

# CH03_06-Regularization-파라미터공유

- 학습과정에서 weight 를 두번이상 사용해 표현을 변환하는데, 그 변환과정이 서로 거의 같아야 한다는 것을 알고있을때 사용하는 방법
    - 각 파라미터가 가까워지게 n-norm의 penalty를 사용하면 $**\Omega(w_a, w_b) =||w_a, w_b||^n_n$** 라고 표현할 수 있다.
    - 이때,  weight들이 서로 같아진다면, 즉 $w_a =w_b$라면, weight를 공유한 상태라고 말할 수 있고, 이를 parameter sharing 이라고 부른다.
        - 파라미터를 공유하면, 모델의 수용량 및 복잡도를 줄일 수 있다.
- CNN의 파라미터 공유
    - 일반적인 이미지 처리에서, 이미지의 특정한부분을 변환할때 유용한 방법이 다른부분을 변환할때도 유용한경우가 통계적으로 높게 나타난다.
        - 모든 다른 이미지 필드의 위치에서, 같은종류의 변환을 해도 된다면 파라미터( weight)를 공유해 볼 수 있다.
        - 이는 또한 학습하여야 하는 파라미터를 매우 줄인다.
        - 메모리와 연산속도에서 이득이다.
        ![Untitled (14)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/89c34b99-2af0-4f27-8771-6ef894ca89b5)

        
        
- RNN의 파라미터 공유( parameter sharing)
    - RNN역시 각각 다른 time step마다 같은 변형을 취하면 된다는 가정에 세운 모델이므로 파라미터를 공유할 수 있다.
    - 파라미터가 공유되어있기 때문에, RNN을 다른 시퀀스 사이즈로 바꾸면서 학습이 가능하다.
    ![Untitled (15)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2ab6fda1-3474-4b7f-b727-107700c6cd73)


# CH03_07-Regularization-Multi-taskLearning

### 다중작업학습(multi-task learning: MTL)

- 공통된 포괄적인 파라미터(generic parameter)를 공유하면서 여러개의 작업을 동시에 학습하는 과정
    - 주요작업(main task) 이외에의 부수작업(auxiliary task)이 모델의 일반화를 돕는다.
    - Baxter, Jonathan(1995)에서. MTL이 파라미터 공유가 generalized error bounds을 줄이는 것을 보였다.
    
    ![Untitled (16)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a1c14ea3-754d-4914-813c-c9ac26ae12fc)

    
- MTL은 왜 잘될까?
    1. Data Augmentation(데이터증강) 효과가 있다.
        1. 여러 다른 테스크 역시 학습하기 때문에, 일반적인 학습이 가능하고, 이는 여러 데이터 증강(샘플사이즈)을 키우는 효과가 있다.
    2. 중요 피처 집중(Attention focusing)
        1. Task가 noisy하거나 데이터가 제한되었거나 고차원의 문제라면, 어떤 feature가 중요한지 구분하기 어려워진다.
        2. MTL은 다른작업들이 feature의 연관성을 판단하는 보조수단이 되어, 중요한 feature에 집중할 수 있도록 도와준다.
        3. 다른 Task가 제시한 방법으로 현Task의 각 feature의 관련성/무관성을 구분하는 기준을 준다.
    3. 엿듣기 효과(eavesdropping)
        1. 어떤 feature는 특정 Task에서 학습하기 쉽지만, 다른 Task에서는 안그럴수 있다.
        2. 이때 MTL이라면 모델의 학습을 도울 힌트가 된다.
    4. 표현 편향(representation bias)
        1. MTL은 다른 Task또한 선호하는 표현방식(representation)을 선호하도록 편향(bias)를 준다.
        2. 이는 다른 Task가 추가될 때에도 모델이 일반화하는데 도움이 될것이다.
    5. 정형화(regularization)
        1. 일반화된 여러 Task들에 유도성편향(inductive bias)가 도입됨에 따라 regularizer의 효과를 가지게 된다.
