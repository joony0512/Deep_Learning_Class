{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joony0512/Deep_Learning_Class/blob/main/Part5/P5_Ch05_CH05_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JwieSnxSwTg"
      },
      "source": [
        "# Efficient Net Fine-tune\n",
        "# Hydra & Pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EalUkrNxU6jV"
      },
      "source": [
        "**## 외부 파일 가져오기 & requirments  설치**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quAUtzK5Rl4T",
        "outputId": "e440d222-8615-4df8-db04-43e2d2107dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBD_BuzQTwOu",
        "outputId": "d457ec91-771c-4d9d-b9cf-8c83150848ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "drive_project_root = \"content/drive/Mydrive/#fastcampus\"\n",
        "sys.path.append(drive_project_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPbIPt_RTyPB"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/#fastcampus\n",
        "!pwd\n",
        "!ls\n",
        "!pip install -r '/content/drive/MyDrive/#fastcampus/requirements.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgd3p4l3VO9E"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info ='\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5v8Wnx86wmP"
      },
      "outputs": [],
      "source": [
        "!pip install omegaconf\n",
        "!pip install torch_optimizer\n",
        "!pip install wandb\n",
        "!pip install efficientnet_pytorch==0.7.1\n",
        "!pip install hydra-core==1.1\n",
        "!pip install pytorch-lightning\n",
        "!pip install --upgrade torchmetrics\n",
        "!pip install --upgrade pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4AqLhzIUNJW"
      },
      "outputs": [],
      "source": [
        "from abc import abstractmethod\n",
        "from abc import ABC\n",
        "from typing import Optional\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Union\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf import DictConfig\n",
        "import hydra\n",
        "from hydra.core.config_store import ConfigStore\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch_optimizer import RAdam\n",
        "from torch_optimizer import AdamP\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERpG-7CdUsxp",
        "outputId": "977bc0f6-8071-4d0e-b83e-3aa652fd8e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/#fastcampus\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/#fastcampus\n",
        "from data_utils import dataset_split\n",
        "from config_utils import flatten_dict\n",
        "from config_utils import register_config\n",
        "from config_utils import configure_optimizers_from_cfg\n",
        "from config_utils import get_loggers\n",
        "from config_utils import get_callbacks\n",
        "from custom_math import softmax\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPZBXAhZVOcP"
      },
      "source": [
        "## 모델정의(Multi-layer Perceptron)(MLP) 정의\n",
        "## 모델 MLPWithDropout 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWGKU9va43iV"
      },
      "source": [
        "### pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "a_FlliiK1zQp"
      },
      "outputs": [],
      "source": [
        "class BaseLightningModule(pl.LightningModule):\n",
        "  def __init__(self, cfg : DictConfig):\n",
        "    pl.LightningModule.__init__(self)\n",
        "    self.cfg = cfg\n",
        "    self.loss_function = nn.CrossEntropyLoss()\n",
        "  @abstractmethod\n",
        "  def forward(self, x):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    self._optimizers , self._schedulers = configure_optimizers_from_cfg(self.cfg, self)\n",
        "    return self._optimizers, self._schedulers\n",
        "\n",
        "  def _forward(self, images, labels, mode:str):\n",
        "    assert mode in [\"train\", \"val\", \"test\"]\n",
        "\n",
        "    #get predictions\n",
        "    outputs = model(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    #get loss (Loss 계산)\n",
        "    loss = self.loss_function(outputs, labels)\n",
        "    corrects = torch.sum(preds==labels.data)\n",
        "    acc = corrects/len(outputs)\n",
        "\n",
        "    return {\n",
        "        f\"{mode}_loss\":loss,\n",
        "        f\"{mode}_acc\":acc,\n",
        "    }, {\n",
        "        f'{mode}_outputs': outputs,\n",
        "        f'{mode}_preds' : preds,\n",
        "        f'{mode}_images' : images,\n",
        "        f'{mode}_labels' : labels,\n",
        "        f'{mode}_corrects' : corrects,\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    images, labels = batch\n",
        "    logs, _ = self._forward(images, labels, mode =\"train\")\n",
        "    self.log_dict(logs)\n",
        "    logs['loss'] = logs['train_loss']\n",
        "    return logs\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    images, labels = batch\n",
        "    logs, _ = self._forward(images, labels, mode =\"val\")\n",
        "    self.log_dict(logs)\n",
        "    logs['loss'] = logs['val_loss']\n",
        "    return logs\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    images, labels = batch\n",
        "    logs, logs_detail = self._forward(images, labels, mode =\"test\")\n",
        "    self.log_dict(logs)\n",
        "    logs['loss'] = logs['test_loss']\n",
        "    logs.update(logs_detail)\n",
        "    return logs\n",
        "\n",
        "  def test_epoch_end(self, step_end_outputs):\n",
        "    #flatten 후 torch->numpylist\n",
        "    model_outputs = torch.cat([o['test_outputs'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    labels = torch.cat([o['test_labels'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    preds = torch.cat([o['test_preds'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    corrects = torch.cat([o['test_corrects'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    losses = torch.cat([o['test_loss'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "\n",
        "    final_outs = softmax(model_outputs, axis = 1)\n",
        "\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    thresh = {}\n",
        "    n_class = self.dfg.data.n_class\n",
        "\n",
        "    for i in range(n_class):\n",
        "      fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, model_outputs[:,i], pos_label =i)\n",
        "\n",
        "    # plot\n",
        "    for i in range(n_class):\n",
        "      plt.plot(fpr[i], tpr[i], linestyle ='--', label =f'Class {i} vs Rest')\n",
        "    plt.title('Multi-class ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc = 'best')\n",
        "    plt.show()\n",
        "\n",
        "    auc_score = roc_auc_score(test_labels_list, test_outputs_list, multi_class ='ovo', average ='macro')\n",
        "    acc = corrects /len(corrects)\n",
        "    mean_loss = np.mean(losses)\n",
        "\n",
        "    return{\n",
        "        'test_auc_score': auc_score,\n",
        "        'test_accuracy' : acc,\n",
        "        'test_loss' : mean_loss,\n",
        "\n",
        "    }\n",
        "\n",
        "# TODO : add below things in the configs\n",
        "# cfg.data.n_class\n",
        "# cfg.opt.lr_schedulers\n",
        "# cfg.opt.optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ZFwY9r4vVKfT"
      },
      "outputs": [],
      "source": [
        "# Define Model.\n",
        "# nn.Module 을 꼭 import해야한다!!class에서 꼭 불러서 써야함\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_dim : int, h1_dim : int, h2_dim : int, out_dim : int):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(in_dim, h1_dim)\n",
        "    self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
        "    self.linear3 = nn.Linear(h2_dim, out_dim)\n",
        "    self.relu = F.relu\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = torch.flatten(input, start_dim = 1) # input index 1부터 flatten 이므로 torch.Size([100, 1, 28, 28])에서 1부터 flatten\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.relu(self.linear2(x))\n",
        "    out = self.linear3(x)\n",
        "    #out = F.softmax(out)\n",
        "    return out\n",
        "\n",
        "class PLMLP(BaseLightningModule):\n",
        "  def __init__(self, cfg : DictConfig):\n",
        "    BaseLightningModule.__init__(self,cfg = cfg)\n",
        "    self.linear1 = nn.Linear(cfg.model.in_dim, cfg.model.h1_dim)\n",
        "    self.linear2 = nn.Linear(cfg.model.h1_dim, cfg.model.h2_dim)\n",
        "    self.linear3 = nn.Linear(cfg.model.h2_dim, cfg.model.out_dim)\n",
        "    self.relu = F.relu\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = torch.flatten(input, start_dim = 1) # input index 1부터 flatten 이므로 torch.Size([100, 1, 28, 28])에서 1부터 flatten\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.relu(self.linear2(x))\n",
        "    out = self.linear3(x)\n",
        "    #out = F.softmax(out)\n",
        "    return out\n",
        "\n",
        "class MLPWIthDropout(MLP):\n",
        "  def __init__(self, in_dim : int, h1_dim : int, h2_dim : int, out_dim : int, dropout_prob : float):\n",
        "    super().__init__( in_dim , h1_dim , h2_dim, out_dim)\n",
        "    self.dropout1 = nn.Dropout(dropout_prob)\n",
        "    self.dropout2 = nn.Dropout(dropout_prob)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = torch.flatten(input, start_dim = 1) # input index 1부터 flatten 이므로 torch.Size([100, 1, 28, 28])에서 1부터 flatten\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.dropout1(x)\n",
        "    x = self.relu(self.linear2(x))\n",
        "    x = self.dropout2(x)\n",
        "    out = self.linear3(x)\n",
        "    #out = F.softmax(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYzDZzavIn90"
      },
      "source": [
        "## config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlncjYb1IhE9",
        "outputId": "4ce112cc-d7c7-4444-8d26-c3f6ae28ec72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data:\n",
            "  name: fashion_mnist\n",
            "  data_root: /content/data\n",
            "  W: 28\n",
            "  H: 28\n",
            "  C: 1\n",
            "model:\n",
            "  name: MLP\n",
            "  in_dim: 784\n",
            "  h1_dim: 128\n",
            "  h2_dim: 64\n",
            "  out_dim: 10\n",
            "  feature:\n",
            "    normalize:\n",
            "      mean:\n",
            "      - 0.5\n",
            "      std:\n",
            "      - 0.5\n",
            "opt:\n",
            "  optimizers:\n",
            "  - name: RAdam\n",
            "    kwargs:\n",
            "      lr: 0.001\n",
            "      betas:\n",
            "      - 0.9\n",
            "      - 0.999\n",
            "      eps: 1.0e-08\n",
            "      weight_decay: 0\n",
            "  lr_schedulers:\n",
            "  - name: null\n",
            "    kwargs: {}\n",
            "train:\n",
            "  train_batch_size: 128\n",
            "  val_batch_size: 32\n",
            "  test_batch_size: 32\n",
            "  train_val_split:\n",
            "  - 0.9\n",
            "  - 0.1\n",
            "  run_root_dir: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "  trainer_kwargs:\n",
            "    accelerator: gpu\n",
            "    num_nodes: 0\n",
            "    max_epochs: 50\n",
            "    val_check_interval: 1.0\n",
            "    log_every_n_steps: 100\n",
            "log:\n",
            "  loggers:\n",
            "    WandbLogger:\n",
            "      project: fastcampus_fashion_mnist_tutorials\n",
            "      name: 2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "      tags:\n",
            "      - fastcampus_fashion_mnist_tutorials\n",
            "      save_dir: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "    TensorBoardLogger:\n",
            "      save_dir: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs\n",
            "      name: 2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "  callbacks:\n",
            "    ModelCheckpoint:\n",
            "      save_top_k: 3\n",
            "      monitor: val_loss\n",
            "      mode: min\n",
            "      verbose: true\n",
            "      dirpath: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist/weights\n",
            "      filename: '{epoch}-{val_loss:.3f}-{val_acc:.2f}'\n",
            "    EarlyStopping:\n",
            "      monitor: val_loss\n",
            "      mode: min\n",
            "      patience: 3\n",
            "      verbose: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# data configs\n",
        "data_fashion_mnist_cfg = {\n",
        "    'name': 'fashion_mnist',\n",
        "    'data_root': os.path.join(os.getcwd(), 'data'),\n",
        "    'W': 28,\n",
        "    'H': 28,\n",
        "    'C': 1,\n",
        "\n",
        "\n",
        "}\n",
        "# cfg = OmegaConf.create(data_fashion_mnist_cfg)\n",
        "# print(OmegaConf.to_yaml(cfg))\n",
        "\n",
        "# model configs\n",
        "model_mnist_mlp_cfg = {\n",
        "    'name': 'MLP',\n",
        "    'in_dim': 28*28,\n",
        "    'h1_dim' : 128,\n",
        "    'h2_dim' : 64,\n",
        "    'out_dim' : 10,\n",
        "    'feature' : {\n",
        "        'normalize':{\n",
        "            'mean' : [0.5],\n",
        "             'std' : [0.5],\n",
        "            }\n",
        "        }\n",
        "\n",
        "}\n",
        "\n",
        "# optimizer configs\n",
        "opt_cfg ={\n",
        "    'optimizers':[\n",
        "   {'name':'RAdam',\n",
        "    'kwargs': {\n",
        "        'lr':  1e-3,\n",
        "        'betas': (0.9, 0.999),\n",
        "        'eps': 1e-8,\n",
        "        'weight_decay': 0,\n",
        "        },\n",
        "    }\n",
        "  ],\n",
        "    'lr_schedulers': [\n",
        "        {\n",
        "            'name' : None,\n",
        "            'kwargs' :{}\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "_merged_cfg_presets = {\n",
        "    'mlp_fashion_mnist':{\n",
        "        'data': data_fashion_mnist_cfg,\n",
        "        'model': model_mnist_mlp_cfg,\n",
        "        'opt': opt_cfg,\n",
        "    }\n",
        "}\n",
        "\n",
        "### hydra composition ###\n",
        "# clear hydra instance first\n",
        "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
        "\n",
        "#register preset configs\n",
        "register_config(_merged_cfg_presets)\n",
        "\n",
        "# initializing\n",
        "hydra.initialize(config_path=None)\n",
        "\n",
        "# Compose\n",
        "cfg = hydra.compose('mlp_fashion_mnist')\n",
        "\n",
        "###\n",
        "\n",
        "# overide some cfg\n",
        "run_name =f\"{datetime.now().isoformat(timespec='seconds')}-{cfg.model.name}-{cfg.data.name}\"\n",
        "\n",
        "# Define train configs\n",
        "project_root_dir = os.path.join(\n",
        "    drive_project_root, 'runs', 'dnn-tutorial-mnist-runs'\n",
        ")\n",
        "save_dir = os.path.join(project_root_dir, run_name)\n",
        "run_root_dir = os.path.join(project_root_dir ,run_name)\n",
        "\n",
        "# train configs\n",
        "train_cfg ={\n",
        "    'train_batch_size' : 128,\n",
        "    'val_batch_size' : 32,\n",
        "    'test_batch_size' : 32,\n",
        "    'train_val_split' : [0.9,0.1],\n",
        "    'run_root_dir' : run_root_dir,\n",
        "    'trainer_kwargs' : {\n",
        "        'accelerator': 'gpu',\n",
        "        'num_nodes' : 0,\n",
        "        'max_epochs' :50,\n",
        "        'val_check_interval': 1.0, #train 1epoch당 val 1회\n",
        "        'log_every_n_steps' : 100,\n",
        "        # 'flush_logs_every_n_steps' : 100, #100번 step마다\n",
        "    }\n",
        "\n",
        "}\n",
        "# logger configs\n",
        "log_cfg = {\n",
        "    'loggers' : {\n",
        "        'WandbLogger' : {\n",
        "            'project' : 'fastcampus_fashion_mnist_tutorials',\n",
        "            'name' : run_name,\n",
        "            'tags' : ['fastcampus_fashion_mnist_tutorials'],\n",
        "            'save_dir' : run_root_dir,\n",
        "\n",
        "        },\n",
        "        'TensorBoardLogger' : {\n",
        "            'save_dir' : project_root_dir,\n",
        "            'name' : run_name,\n",
        "        }\n",
        "    },\n",
        "    'callbacks' : {\n",
        "        'ModelCheckpoint' : {\n",
        "            'save_top_k' : 3,\n",
        "            'monitor' : 'val_loss',\n",
        "            'mode' : 'min',\n",
        "            'verbose' : True,\n",
        "            'dirpath' : os.path.join(run_root_dir, 'weights'),\n",
        "            'filename' : '{epoch}-{val_loss:.3f}-{val_acc:.2f}',\n",
        "\n",
        "        },\n",
        "        'EarlyStopping' : {\n",
        "            'monitor' : 'val_loss',\n",
        "            'mode' : 'min',\n",
        "            'patience' : 3,\n",
        "            'verbose' : True\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# unlock config & set train, log config\n",
        "OmegaConf.set_struct(cfg, False)\n",
        "cfg.train =train_cfg\n",
        "cfg.log = log_cfg\n",
        "\n",
        "# lock config\n",
        "OmegaConf.set_struct(cfg, True)\n",
        "print(OmegaConf.to_yaml(cfg))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "GI5J0-ZVThGJ"
      },
      "outputs": [],
      "source": [
        "data_root = cfg.data.data_root\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            cfg.model.feature.normalize.mean,\n",
        "            cfg.model.feature.normalize.std\n",
        "            ), #mean, #std\n",
        "    ]\n",
        ")\n",
        "fashion_mnist_dataset = FashionMNIST(data_root, download = True, train = True, transform = transform)\n",
        "\n",
        "#좀 바꾼 모듈 직접 임포트 하여 사용 from data_utils import dataset_split , train과 validation 자르기\n",
        "datasets = dataset_split(fashion_mnist_dataset, split=cfg.train.train_val_split)\n",
        "test_dataset = FashionMNIST(data_root, download = True, train = False, transform  = transform)\n",
        "\n",
        "train_dataset = datasets['train']\n",
        "val_dataset = datasets['val']\n",
        "\n",
        "train_batch_size = cfg.train.train_batch_size\n",
        "val_batch_size = cfg.train.val_batch_size\n",
        "\n",
        "# dataloader : 배치단위로 묶는걸 도움\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size = train_batch_size, shuffle = True, num_workers =0\n",
        ")\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size = val_batch_size, shuffle = False, num_workers =0\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size = val_batch_size, shuffle = False, num_workers =0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P61OoZHxWh1V"
      },
      "source": [
        "## 모델 선언 및 손실함수, 최적화(Optimizer)정의, Tensorboard Logger정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tomk5zyVRlE",
        "outputId": "4b18f74c-3de0-4e19-eb45-c7168fcdff79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PLMLP(\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# model define\n",
        "# optional : # pretrained model 대비\n",
        "def get_pl_model(cfg : DictConfig , checkpoint_path : Optional[str] = None):\n",
        "\n",
        "  if cfg.model.name ==\"MLP\":\n",
        "    model = PLMLP(cfg)\n",
        "  else :\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  if checkpoint_path is not None :\n",
        "    model.load_from_checkpoint(cfg = cfg, checkpoint_path=checkpoint_path)\n",
        "  return model\n",
        "\n",
        "model = get_pl_model(cfg)\n",
        "print(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328,
          "referenced_widgets": [
            "92cba11c1c80418cb67e5bcf2c2c8242",
            "89a2860ed9594c1bb6399aaf61b5d1d5",
            "2a3a38f591294dc28bec7a6b34047e81",
            "198760c7fc7b47e894284de287597585",
            "77b3922462084a77ac301d8a2ffba914",
            "ad9dbc31476f4bb4a011834871af57e1",
            "fdec7150bb8a49e48d6145791391390b",
            "0e2263a2fddb4c1baccc817b44099f35"
          ]
        },
        "id": "wULzlMor4V-6",
        "outputId": "4ec6d5fe-52cb-4e59-87b0-9bb84101d644"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.014 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.077435…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92cba11c1c80418cb67e5bcf2c2c8242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">2023-07-09T10:06:11-MLP-fashion_mnist</strong> at: <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/szkcg7n2' target=\"_blank\">https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/szkcg7n2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:06:11-MLP-fashion_mnist/wandb/run-20230709_100617-szkcg7n2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist/wandb/run-20230709_100852-oigx9l55</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/oigx9l55' target=\"_blank\">2023-07-09T10:08:46-MLP-fashion_mnist</a></strong> to <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials' target=\"_blank\">https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/oigx9l55' target=\"_blank\">https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/oigx9l55</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
          ]
        }
      ],
      "source": [
        "logger = get_loggers(cfg)\n",
        "callbacks = get_callbacks(cfg)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    callbacks = callbacks,\n",
        "    logger = logger,\n",
        "    default_root_dir=cfg.train.run_root_dir,\n",
        "    num_sanity_val_steps=2,\n",
        "    **cfg.train.trainer_kwargs,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-totorial-fashion-mnist-runs/\n",
        "\n",
        "trainer.fit(model, train_dataloader, val_dataloader)\n",
        "# trainer.test(model, test_dataloader)"
      ],
      "metadata": {
        "id": "VT1eQY0p_lgP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hw7qJRVynN0t",
        "IuE8K9aTXyIS"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyN6320j2w1p42XJ9q9tWVEQ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92cba11c1c80418cb67e5bcf2c2c8242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89a2860ed9594c1bb6399aaf61b5d1d5",
              "IPY_MODEL_2a3a38f591294dc28bec7a6b34047e81"
            ],
            "layout": "IPY_MODEL_198760c7fc7b47e894284de287597585"
          }
        },
        "89a2860ed9594c1bb6399aaf61b5d1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b3922462084a77ac301d8a2ffba914",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9dbc31476f4bb4a011834871af57e1",
            "value": "0.001 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "2a3a38f591294dc28bec7a6b34047e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdec7150bb8a49e48d6145791391390b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e2263a2fddb4c1baccc817b44099f35",
            "value": 0.07743552536112394
          }
        },
        "198760c7fc7b47e894284de287597585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77b3922462084a77ac301d8a2ffba914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9dbc31476f4bb4a011834871af57e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdec7150bb8a49e48d6145791391390b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2263a2fddb4c1baccc817b44099f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}