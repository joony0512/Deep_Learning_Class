{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joony0512/Deep_Learning_Class/blob/main/Part5/P5_Ch05_CH05_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JwieSnxSwTg"
      },
      "source": [
        "# Efficient Net Fine-tune\n",
        "# Hydra & Pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EalUkrNxU6jV"
      },
      "source": [
        "**## 외부 파일 가져오기 & requirments  설치**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quAUtzK5Rl4T",
        "outputId": "e440d222-8615-4df8-db04-43e2d2107dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBD_BuzQTwOu",
        "outputId": "d457ec91-771c-4d9d-b9cf-8c83150848ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "drive_project_root = \"content/drive/Mydrive/#fastcampus\"\n",
        "sys.path.append(drive_project_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPbIPt_RTyPB"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/#fastcampus\n",
        "!pwd\n",
        "!ls\n",
        "!pip install -r '/content/drive/MyDrive/#fastcampus/requirements.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgd3p4l3VO9E"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info ='\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5v8Wnx86wmP"
      },
      "outputs": [],
      "source": [
        "!pip install omegaconf\n",
        "!pip install torch_optimizer\n",
        "!pip install wandb\n",
        "!pip install efficientnet_pytorch==0.7.1\n",
        "!pip install hydra-core==1.1\n",
        "!pip install pytorch-lightning\n",
        "!pip install --upgrade torchmetrics\n",
        "!pip install --upgrade pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4AqLhzIUNJW"
      },
      "outputs": [],
      "source": [
        "from abc import abstractmethod\n",
        "from abc import ABC\n",
        "from typing import Optional\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Union\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf import DictConfig\n",
        "import hydra\n",
        "from hydra.core.config_store import ConfigStore\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch_optimizer import RAdam\n",
        "from torch_optimizer import AdamP\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERpG-7CdUsxp",
        "outputId": "977bc0f6-8071-4d0e-b83e-3aa652fd8e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/#fastcampus\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/#fastcampus\n",
        "from data_utils import dataset_split\n",
        "from config_utils import flatten_dict\n",
        "from config_utils import register_config\n",
        "from config_utils import configure_optimizers_from_cfg\n",
        "from config_utils import get_loggers\n",
        "from config_utils import get_callbacks\n",
        "from custom_math import softmax\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPZBXAhZVOcP"
      },
      "source": [
        "## 모델정의(Multi-layer Perceptron)(MLP) 정의\n",
        "## 모델 MLPWithDropout 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWGKU9va43iV"
      },
      "source": [
        "### pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "a_FlliiK1zQp"
      },
      "outputs": [],
      "source": [
        "class BaseLightningModule(pl.LightningModule):\n",
        "  def __init__(self, cfg : DictConfig):\n",
        "    pl.LightningModule.__init__(self)\n",
        "    self.cfg = cfg\n",
        "    self.loss_function = nn.CrossEntropyLoss()\n",
        "  @abstractmethod\n",
        "  def forward(self, x):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    self._optimizers , self._schedulers = configure_optimizers_from_cfg(self.cfg, self)\n",
        "    return self._optimizers, self._schedulers\n",
        "\n",
        "  def _forward(self, images, labels, mode:str):\n",
        "    assert mode in [\"train\", \"val\", \"test\"]\n",
        "\n",
        "    #get predictions\n",
        "    outputs = model(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    #get loss (Loss 계산)\n",
        "    loss = self.loss_function(outputs, labels)\n",
        "    corrects = torch.sum(preds==labels.data)\n",
        "    acc = corrects/len(outputs)\n",
        "\n",
        "    return {\n",
        "        f\"{mode}_loss\":loss,\n",
        "        f\"{mode}_acc\":acc,\n",
        "    }, {\n",
        "        f'{mode}_outputs': outputs,\n",
        "        f'{mode}_preds' : preds,\n",
        "        f'{mode}_images' : images,\n",
        "        f'{mode}_labels' : labels,\n",
        "        f'{mode}_corrects' : corrects,\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    images, labels = batch\n",
        "    logs, _ = self._forward(images, labels, mode =\"train\")\n",
        "    self.log_dict(logs)\n",
        "    logs['loss'] = logs['train_loss']\n",
        "    return logs\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    images, labels = batch\n",
        "    logs, _ = self._forward(images, labels, mode =\"val\")\n",
        "    self.log_dict(logs)\n",
        "    logs['loss'] = logs['val_loss']\n",
        "    return logs\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    images, labels = batch\n",
        "    logs, logs_detail = self._forward(images, labels, mode =\"test\")\n",
        "    self.log_dict(logs)\n",
        "    logs['loss'] = logs['test_loss']\n",
        "    logs.update(logs_detail)\n",
        "    return logs\n",
        "\n",
        "  def test_epoch_end(self, step_end_outputs):\n",
        "    #flatten 후 torch->numpylist\n",
        "    model_outputs = torch.cat([o['test_outputs'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    labels = torch.cat([o['test_labels'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    preds = torch.cat([o['test_preds'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    corrects = torch.cat([o['test_corrects'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "    losses = torch.cat([o['test_loss'] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "\n",
        "    final_outs = softmax(model_outputs, axis = 1)\n",
        "\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    thresh = {}\n",
        "    n_class = self.dfg.data.n_class\n",
        "\n",
        "    for i in range(n_class):\n",
        "      fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, model_outputs[:,i], pos_label =i)\n",
        "\n",
        "    # plot\n",
        "    for i in range(n_class):\n",
        "      plt.plot(fpr[i], tpr[i], linestyle ='--', label =f'Class {i} vs Rest')\n",
        "    plt.title('Multi-class ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc = 'best')\n",
        "    plt.show()\n",
        "\n",
        "    auc_score = roc_auc_score(test_labels_list, test_outputs_list, multi_class ='ovo', average ='macro')\n",
        "    acc = corrects /len(corrects)\n",
        "    mean_loss = np.mean(losses)\n",
        "\n",
        "    return{\n",
        "        'test_auc_score': auc_score,\n",
        "        'test_accuracy' : acc,\n",
        "        'test_loss' : mean_loss,\n",
        "\n",
        "    }\n",
        "\n",
        "# TODO : add below things in the configs\n",
        "# cfg.data.n_class\n",
        "# cfg.opt.lr_schedulers\n",
        "# cfg.opt.optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ZFwY9r4vVKfT"
      },
      "outputs": [],
      "source": [
        "# Define Model.\n",
        "# nn.Module 을 꼭 import해야한다!!class에서 꼭 불러서 써야함\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, in_dim : int, h1_dim : int, h2_dim : int, out_dim : int):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(in_dim, h1_dim)\n",
        "    self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
        "    self.linear3 = nn.Linear(h2_dim, out_dim)\n",
        "    self.relu = F.relu\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = torch.flatten(input, start_dim = 1) # input index 1부터 flatten 이므로 torch.Size([100, 1, 28, 28])에서 1부터 flatten\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.relu(self.linear2(x))\n",
        "    out = self.linear3(x)\n",
        "    #out = F.softmax(out)\n",
        "    return out\n",
        "\n",
        "class PLMLP(BaseLightningModule):\n",
        "  def __init__(self, cfg : DictConfig):\n",
        "    BaseLightningModule.__init__(self,cfg = cfg)\n",
        "    self.linear1 = nn.Linear(cfg.model.in_dim, cfg.model.h1_dim)\n",
        "    self.linear2 = nn.Linear(cfg.model.h1_dim, cfg.model.h2_dim)\n",
        "    self.linear3 = nn.Linear(cfg.model.h2_dim, cfg.model.out_dim)\n",
        "    self.relu = F.relu\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = torch.flatten(input, start_dim = 1) # input index 1부터 flatten 이므로 torch.Size([100, 1, 28, 28])에서 1부터 flatten\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.relu(self.linear2(x))\n",
        "    out = self.linear3(x)\n",
        "    #out = F.softmax(out)\n",
        "    return out\n",
        "\n",
        "class MLPWIthDropout(MLP):\n",
        "  def __init__(self, in_dim : int, h1_dim : int, h2_dim : int, out_dim : int, dropout_prob : float):\n",
        "    super().__init__( in_dim , h1_dim , h2_dim, out_dim)\n",
        "    self.dropout1 = nn.Dropout(dropout_prob)\n",
        "    self.dropout2 = nn.Dropout(dropout_prob)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = torch.flatten(input, start_dim = 1) # input index 1부터 flatten 이므로 torch.Size([100, 1, 28, 28])에서 1부터 flatten\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.dropout1(x)\n",
        "    x = self.relu(self.linear2(x))\n",
        "    x = self.dropout2(x)\n",
        "    out = self.linear3(x)\n",
        "    #out = F.softmax(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw7qJRVynN0t"
      },
      "source": [
        "## CNN 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUGzxJQWnQvQ",
        "outputId": "7a6eda42-5e1f-4b6f-cbf5-645eb5ee7285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer_1:\n",
            "  conv2d_in_channels: 1\n",
            "  conv2d_out_channels: 32\n",
            "  conv2d_kernel_size: 3\n",
            "  conv2d_padding: 1\n",
            "  maxpool2d_kernel_size: 2\n",
            "  maxpool2d_stride: 2\n",
            "layer_2:\n",
            "  conv2d_in_channels: 32\n",
            "  conv2d_out_channels: 64\n",
            "  conv2d_kernel_size: 3\n",
            "  conv2d_padding: 0\n",
            "  maxpool2d_kernel_size: 2\n",
            "  maxpool2d_stride: 2\n",
            "fc_1:\n",
            "  in_features: 2304\n",
            "  out_features: 512\n",
            "fc_2:\n",
            "  in_features: 512\n",
            "  out_features: 128\n",
            "fc_3:\n",
            "  in_features: 128\n",
            "  out_features: 10\n",
            "dropout_prob: 0.25\n",
            "\n"
          ]
        }
      ],
      "source": [
        "_cnn_cfg_dict : dict ={\n",
        "    \"layer_1\" : {\n",
        "        \"conv2d_in_channels\" :1, #흑백이라서\n",
        "        \"conv2d_out_channels\" : 32,\n",
        "        \"conv2d_kernel_size\" : 3, #3x3 receptive field\n",
        "        \"conv2d_padding\" : 1,\n",
        "        \"maxpool2d_kernel_size\": 2,\n",
        "        \"maxpool2d_stride\" : 2,\n",
        "    },\n",
        "    \"layer_2\" : {\n",
        "        \"conv2d_in_channels\" :32,\n",
        "        \"conv2d_out_channels\" : 64,\n",
        "        \"conv2d_kernel_size\" : 3,\n",
        "        \"conv2d_padding\" : 0,\n",
        "        \"maxpool2d_kernel_size\": 2,\n",
        "        \"maxpool2d_stride\" : 2,\n",
        "\n",
        "    },\n",
        "    \"fc_1\" : {\n",
        "        \"in_features\": 2304, #수정필요\n",
        "        \"out_features\" : 512,\n",
        "    },\n",
        "    \"fc_2\" : {\n",
        "        \"in_features\": 512,\n",
        "        \"out_features\" : 128,\n",
        "\n",
        "    },\n",
        "    \"fc_3\" : {\n",
        "        \"in_features\": 128,\n",
        "        \"out_features\" : 10,\n",
        "    },\n",
        "    \"dropout_prob\": 0.25,\n",
        "\n",
        "}\n",
        "_cnn_cfg = OmegaConf.create(_cnn_cfg_dict)\n",
        "# print(_cnn_cfg)\n",
        "print(OmegaConf.to_yaml(_cnn_cfg))\n",
        "# with open(\"cnn_test.yaml\",\"w\") as f:\n",
        "#   OmegaConf.save(_cnn_cfg, f) # 저장\n",
        "# print(_cnn_cfg.layer_1, _cnn_cfg[\"layer_1\"])\n",
        "# OmegaConf.1oad # 불러오기\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, cfg : DictConfig =_cnn_cfg):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = cfg.layer_1.conv2d_in_channels,\n",
        "            out_channels = cfg.layer_1.conv2d_out_channels,\n",
        "            kernel_size = cfg.layer_1.conv2d_kernel_size,\n",
        "            padding =cfg.layer_1.conv2d_padding\n",
        "        ),\n",
        "        nn.BatchNorm2d(cfg.layer_1.conv2d_out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(\n",
        "            kernel_size = cfg.layer_1.maxpool2d_kernel_size,\n",
        "            stride = cfg.layer_1.maxpool2d_stride\n",
        "        )\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = cfg.layer_2.conv2d_in_channels,\n",
        "            out_channels = cfg.layer_2.conv2d_out_channels,\n",
        "            kernel_size = cfg.layer_2.conv2d_kernel_size,\n",
        "            padding =cfg.layer_2.conv2d_padding\n",
        "        ),\n",
        "        nn.BatchNorm2d(cfg.layer_2.conv2d_out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(\n",
        "            kernel_size = cfg.layer_2.maxpool2d_kernel_size,\n",
        "            stride = cfg.layer_2.maxpool2d_stride\n",
        "        )\n",
        "    )\n",
        "    self.fc1 = nn.Linear(\n",
        "        in_features = cfg.fc_1.in_features,\n",
        "        out_features = cfg.fc_1.out_features,\n",
        "\n",
        "    )\n",
        "    self.fc2 = nn.Linear(\n",
        "        in_features = cfg.fc_2.in_features,\n",
        "        out_features = cfg.fc_2.out_features,\n",
        "\n",
        "    )\n",
        "    self.fc3 = nn.Linear(\n",
        "        in_features = cfg.fc_3.in_features,\n",
        "        out_features = cfg.fc_3.out_features,\n",
        "\n",
        "    )\n",
        "    self.dropout = nn.Dropout2d(cfg.dropout_prob)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.view(out.size(0), -1) # 배치는 놔두고 나머지만 flatten\n",
        "    out = self.fc1(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.fc3(out)\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuE8K9aTXyIS"
      },
      "source": [
        "## Efficient Net\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSsEiRDqXjBN",
        "outputId": "8876a8b6-b18c-4dc8-c7d3-ee326c183c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "efficient_net_model_name: efficientnet-b1\n",
            "num_classes: 10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "_efficient_finetune_cfg_dict : dict ={\n",
        "    \"efficient_net_model_name\": \"efficientnet-b1\",\n",
        "    \"num_classes\" :10,\n",
        "\n",
        "}\n",
        "_efficient_finetune_cfg = OmegaConf.create(_efficient_finetune_cfg_dict)\n",
        "print(OmegaConf.to_yaml(_efficient_finetune_cfg))\n",
        "\n",
        "class EfficientNetFinetune(nn.Module):\n",
        "  def __init__(self, cfg : DictConfig =_efficient_finetune_cfg):\n",
        "    super().__init__()\n",
        "    self.efficientnet = EfficientNet.from_pretrained(\n",
        "        cfg.efficient_net_model_name,\n",
        "        cfg.num_classes,\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    out = self.efficientnet(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYzDZzavIn90"
      },
      "source": [
        "## config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlncjYb1IhE9",
        "outputId": "4ce112cc-d7c7-4444-8d26-c3f6ae28ec72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data:\n",
            "  name: fashion_mnist\n",
            "  data_root: /content/data\n",
            "  W: 28\n",
            "  H: 28\n",
            "  C: 1\n",
            "model:\n",
            "  name: MLP\n",
            "  in_dim: 784\n",
            "  h1_dim: 128\n",
            "  h2_dim: 64\n",
            "  out_dim: 10\n",
            "  feature:\n",
            "    normalize:\n",
            "      mean:\n",
            "      - 0.5\n",
            "      std:\n",
            "      - 0.5\n",
            "opt:\n",
            "  optimizers:\n",
            "  - name: RAdam\n",
            "    kwargs:\n",
            "      lr: 0.001\n",
            "      betas:\n",
            "      - 0.9\n",
            "      - 0.999\n",
            "      eps: 1.0e-08\n",
            "      weight_decay: 0\n",
            "  lr_schedulers:\n",
            "  - name: null\n",
            "    kwargs: {}\n",
            "train:\n",
            "  train_batch_size: 128\n",
            "  val_batch_size: 32\n",
            "  test_batch_size: 32\n",
            "  train_val_split:\n",
            "  - 0.9\n",
            "  - 0.1\n",
            "  run_root_dir: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "  trainer_kwargs:\n",
            "    accelerator: gpu\n",
            "    num_nodes: 0\n",
            "    max_epochs: 50\n",
            "    val_check_interval: 1.0\n",
            "    log_every_n_steps: 100\n",
            "log:\n",
            "  loggers:\n",
            "    WandbLogger:\n",
            "      project: fastcampus_fashion_mnist_tutorials\n",
            "      name: 2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "      tags:\n",
            "      - fastcampus_fashion_mnist_tutorials\n",
            "      save_dir: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "    TensorBoardLogger:\n",
            "      save_dir: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs\n",
            "      name: 2023-07-09T10:08:46-MLP-fashion_mnist\n",
            "  callbacks:\n",
            "    ModelCheckpoint:\n",
            "      save_top_k: 3\n",
            "      monitor: val_loss\n",
            "      mode: min\n",
            "      verbose: true\n",
            "      dirpath: content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist/weights\n",
            "      filename: '{epoch}-{val_loss:.3f}-{val_acc:.2f}'\n",
            "    EarlyStopping:\n",
            "      monitor: val_loss\n",
            "      mode: min\n",
            "      patience: 3\n",
            "      verbose: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# data configs\n",
        "data_fashion_mnist_cfg = {\n",
        "    'name': 'fashion_mnist',\n",
        "    'data_root': os.path.join(os.getcwd(), 'data'),\n",
        "    'W': 28,\n",
        "    'H': 28,\n",
        "    'C': 1,\n",
        "\n",
        "\n",
        "}\n",
        "# cfg = OmegaConf.create(data_fashion_mnist_cfg)\n",
        "# print(OmegaConf.to_yaml(cfg))\n",
        "\n",
        "# model configs\n",
        "model_mnist_mlp_cfg = {\n",
        "    'name': 'MLP',\n",
        "    'in_dim': 28*28,\n",
        "    'h1_dim' : 128,\n",
        "    'h2_dim' : 64,\n",
        "    'out_dim' : 10,\n",
        "    'feature' : {\n",
        "        'normalize':{\n",
        "            'mean' : [0.5],\n",
        "             'std' : [0.5],\n",
        "            }\n",
        "        }\n",
        "\n",
        "}\n",
        "\n",
        "# optimizer configs\n",
        "opt_cfg ={\n",
        "    'optimizers':[\n",
        "   {'name':'RAdam',\n",
        "    'kwargs': {\n",
        "        'lr':  1e-3,\n",
        "        'betas': (0.9, 0.999),\n",
        "        'eps': 1e-8,\n",
        "        'weight_decay': 0,\n",
        "        },\n",
        "    }\n",
        "  ],\n",
        "    'lr_schedulers': [\n",
        "        {\n",
        "            'name' : None,\n",
        "            'kwargs' :{}\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "_merged_cfg_presets = {\n",
        "    'mlp_fashion_mnist':{\n",
        "        'data': data_fashion_mnist_cfg,\n",
        "        'model': model_mnist_mlp_cfg,\n",
        "        'opt': opt_cfg,\n",
        "    }\n",
        "}\n",
        "\n",
        "### hydra composition ###\n",
        "# clear hydra instance first\n",
        "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
        "\n",
        "#register preset configs\n",
        "register_config(_merged_cfg_presets)\n",
        "\n",
        "# initializing\n",
        "hydra.initialize(config_path=None)\n",
        "\n",
        "# Compose\n",
        "cfg = hydra.compose('mlp_fashion_mnist')\n",
        "\n",
        "###\n",
        "\n",
        "# overide some cfg\n",
        "run_name =f\"{datetime.now().isoformat(timespec='seconds')}-{cfg.model.name}-{cfg.data.name}\"\n",
        "\n",
        "# Define train configs\n",
        "project_root_dir = os.path.join(\n",
        "    drive_project_root, 'runs', 'dnn-tutorial-mnist-runs'\n",
        ")\n",
        "save_dir = os.path.join(project_root_dir, run_name)\n",
        "run_root_dir = os.path.join(project_root_dir ,run_name)\n",
        "\n",
        "# train configs\n",
        "train_cfg ={\n",
        "    'train_batch_size' : 128,\n",
        "    'val_batch_size' : 32,\n",
        "    'test_batch_size' : 32,\n",
        "    'train_val_split' : [0.9,0.1],\n",
        "    'run_root_dir' : run_root_dir,\n",
        "    'trainer_kwargs' : {\n",
        "        'accelerator': 'gpu',\n",
        "        'num_nodes' : 0,\n",
        "        'max_epochs' :50,\n",
        "        'val_check_interval': 1.0, #train 1epoch당 val 1회\n",
        "        'log_every_n_steps' : 100,\n",
        "        # 'flush_logs_every_n_steps' : 100, #100번 step마다\n",
        "    }\n",
        "\n",
        "}\n",
        "# logger configs\n",
        "log_cfg = {\n",
        "    'loggers' : {\n",
        "        'WandbLogger' : {\n",
        "            'project' : 'fastcampus_fashion_mnist_tutorials',\n",
        "            'name' : run_name,\n",
        "            'tags' : ['fastcampus_fashion_mnist_tutorials'],\n",
        "            'save_dir' : run_root_dir,\n",
        "\n",
        "        },\n",
        "        'TensorBoardLogger' : {\n",
        "            'save_dir' : project_root_dir,\n",
        "            'name' : run_name,\n",
        "        }\n",
        "    },\n",
        "    'callbacks' : {\n",
        "        'ModelCheckpoint' : {\n",
        "            'save_top_k' : 3,\n",
        "            'monitor' : 'val_loss',\n",
        "            'mode' : 'min',\n",
        "            'verbose' : True,\n",
        "            'dirpath' : os.path.join(run_root_dir, 'weights'),\n",
        "            'filename' : '{epoch}-{val_loss:.3f}-{val_acc:.2f}',\n",
        "\n",
        "        },\n",
        "        'EarlyStopping' : {\n",
        "            'monitor' : 'val_loss',\n",
        "            'mode' : 'min',\n",
        "            'patience' : 3,\n",
        "            'verbose' : True\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# unlock config & set train, log config\n",
        "OmegaConf.set_struct(cfg, False)\n",
        "cfg.train =train_cfg\n",
        "cfg.log = log_cfg\n",
        "\n",
        "# lock config\n",
        "OmegaConf.set_struct(cfg, True)\n",
        "print(OmegaConf.to_yaml(cfg))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "GI5J0-ZVThGJ"
      },
      "outputs": [],
      "source": [
        "data_root = cfg.data.data_root\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            cfg.model.feature.normalize.mean,\n",
        "            cfg.model.feature.normalize.std\n",
        "            ), #mean, #std\n",
        "    ]\n",
        ")\n",
        "fashion_mnist_dataset = FashionMNIST(data_root, download = True, train = True, transform = transform)\n",
        "\n",
        "#좀 바꾼 모듈 직접 임포트 하여 사용 from data_utils import dataset_split , train과 validation 자르기\n",
        "datasets = dataset_split(fashion_mnist_dataset, split=cfg.train.train_val_split)\n",
        "test_dataset = FashionMNIST(data_root, download = True, train = False, transform  = transform)\n",
        "\n",
        "train_dataset = datasets['train']\n",
        "val_dataset = datasets['val']\n",
        "\n",
        "train_batch_size = cfg.train.train_batch_size\n",
        "val_batch_size = cfg.train.val_batch_size\n",
        "\n",
        "# dataloader : 배치단위로 묶는걸 도움\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size = train_batch_size, shuffle = True, num_workers =0\n",
        ")\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size = val_batch_size, shuffle = False, num_workers =0\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size = val_batch_size, shuffle = False, num_workers =0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P61OoZHxWh1V"
      },
      "source": [
        "## 모델 선언 및 손실함수, 최적화(Optimizer)정의, Tensorboard Logger정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tomk5zyVRlE",
        "outputId": "4b18f74c-3de0-4e19-eb45-c7168fcdff79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PLMLP(\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# model define\n",
        "# optional : # pretrained model 대비\n",
        "def get_pl_model(cfg : DictConfig , checkpoint_path : Optional[str] = None):\n",
        "\n",
        "  if cfg.model.name ==\"MLP\":\n",
        "    model = PLMLP(cfg)\n",
        "  else :\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  if checkpoint_path is not None :\n",
        "    model.load_from_checkpoint(cfg = cfg, checkpoint_path=checkpoint_path)\n",
        "  return model\n",
        "\n",
        "model = get_pl_model(cfg)\n",
        "print(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328,
          "referenced_widgets": [
            "92cba11c1c80418cb67e5bcf2c2c8242",
            "89a2860ed9594c1bb6399aaf61b5d1d5",
            "2a3a38f591294dc28bec7a6b34047e81",
            "198760c7fc7b47e894284de287597585",
            "77b3922462084a77ac301d8a2ffba914",
            "ad9dbc31476f4bb4a011834871af57e1",
            "fdec7150bb8a49e48d6145791391390b",
            "0e2263a2fddb4c1baccc817b44099f35"
          ]
        },
        "id": "wULzlMor4V-6",
        "outputId": "4ec6d5fe-52cb-4e59-87b0-9bb84101d644"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.014 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.077435…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92cba11c1c80418cb67e5bcf2c2c8242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">2023-07-09T10:06:11-MLP-fashion_mnist</strong> at: <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/szkcg7n2' target=\"_blank\">https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/szkcg7n2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:06:11-MLP-fashion_mnist/wandb/run-20230709_100617-szkcg7n2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-mnist-runs/2023-07-09T10:08:46-MLP-fashion_mnist/wandb/run-20230709_100852-oigx9l55</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/oigx9l55' target=\"_blank\">2023-07-09T10:08:46-MLP-fashion_mnist</a></strong> to <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials' target=\"_blank\">https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/oigx9l55' target=\"_blank\">https://wandb.ai/hyejun12123/fastcampus_fashion_mnist_tutorials/runs/oigx9l55</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
          ]
        }
      ],
      "source": [
        "logger = get_loggers(cfg)\n",
        "callbacks = get_callbacks(cfg)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    callbacks = callbacks,\n",
        "    logger = logger,\n",
        "    default_root_dir=cfg.train.run_root_dir,\n",
        "    num_sanity_val_steps=2,\n",
        "    **cfg.train.trainer_kwargs,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-totorial-fashion-mnist-runs/\n",
        "\n",
        "trainer.fit(model, train_dataloader, val_dataloader)\n",
        "# trainer.test(model, test_dataloader)"
      ],
      "metadata": {
        "id": "VT1eQY0p_lgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-zCA8THW9_j"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-totorial-fashion-mnist-runs/\n",
        " #runs라는 폴더만들고 거기에 실행시켜라, logging 쌓고 플로팅해줘\n",
        "\n",
        "# Define EarlyStopping.\n",
        "early_stopper = EarlyStopping(\n",
        "    patience =3, verbose =True, path = os.path.join(log_model_path, 'model.ckpt')\n",
        ")\n",
        "\n",
        "# do train with validation\n",
        "train_step =0\n",
        "for epoch in range(1, max_epoch+1):\n",
        "  #valid_step\n",
        "  with torch.no_grad():\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "    model.eval() #어디부터 eval인지 지정 #Dropout시 중요\n",
        "\n",
        "    for val_batch_idx, (val_images, val_labels) in enumerate(\n",
        "        tqdm(val_dataloader, position = 0, leave = True, desc ='validation')\n",
        "    ):\n",
        "        if gpu is not None:\n",
        "          val_images =val_images.cuda(gpu)\n",
        "          val_labels =val_labels.cuda(gpu)\n",
        "\n",
        "        #forward\n",
        "        val_outputs = model(val_images)\n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "\n",
        "        #loss & acc\n",
        "        val_loss +=loss_function(val_outputs, val_labels) / val_outputs.shape[0] #batch size로 평균내기\n",
        "        val_corrects +=torch.sum(val_preds== val_labels.data) / val_outputs.shape[0]\n",
        "  #valid step logging\n",
        "  val_epoch_loss = val_loss /len(val_dataloader)\n",
        "  val_epoch_acc = val_corrects /len(val_dataloader)\n",
        "\n",
        "\n",
        "  print(\n",
        "      f'{epoch}epoch, {train_step}step:val_loss: {val_epoch_loss}, val_acc : {val_epoch_acc}'\n",
        "  )\n",
        "\n",
        "  #tensorboard log\n",
        "  writer.add_scalar('Loss/val', val_epoch_loss, train_step)\n",
        "  writer.add_scalar('Acc/val', val_epoch_acc, train_step)\n",
        "  writer.add_images('Images/val', val_images, train_step)\n",
        "\n",
        "  #wandblog\n",
        "  wandb.log({\n",
        "      'Loss/val': val_epoch_loss,\n",
        "      'Acc/val': val_epoch_acc,\n",
        "      'Images/val': wandb.Image(val_images),\n",
        "      'Ouputs/val': wandb.Histogram(val_outputs.detach().cpu().numpy()), # gpu를 쓰고있어서 detach, tensor를 numpy로 변경\n",
        "      'Preds/val': wandb.Histogram(val_preds.detach().cpu().numpy()),\n",
        "      'Labels/val': wandb.Histogram(val_labels.data.cpu().detach().numpy())\n",
        "\n",
        "  }, step =train_step)\n",
        "\n",
        "  #check model early stopping point & dave model if the model reached the best performance.\n",
        "  early_stopper(val_epoch_loss, model)\n",
        "  if early_stopper.early_stop:\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "  # train_step\n",
        "  current_loss = 0\n",
        "  current_corrects = 0\n",
        "  for batch_idx, (images, labels) in enumerate(\n",
        "      tqdm(train_dataloader, position = 0, leave = True, desc ='training')\n",
        "    ):\n",
        "\n",
        "      if gpu is not None:\n",
        "        images = images.cuda(gpu)\n",
        "        labels = labels.cuda(gpu)\n",
        "\n",
        "      current_loss =0.0\n",
        "      current_corrects = 0\n",
        "      model.train() #어디부터 train인지  지정 #Dropout시 중요\n",
        "\n",
        "      #Forward\n",
        "      #get predictions\n",
        "      outputs = model(images)\n",
        "      _, preds = torch.max(outputs, 1) #배치수 유지, 최대값 저장x, 열의 위치만 반환=1\n",
        "\n",
        "\n",
        "      #get loss (Loss 계산)\n",
        "      loss = loss_function(outputs, labels) #input과 target\n",
        "\n",
        "      #Backpropagation\n",
        "      # optimizer 초기화\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      #Perform Optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      #Perform LR Scheduler Work\n",
        "      if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "      current_loss += loss.item()\n",
        "      current_corrects += torch.sum(preds==labels.data)\n",
        "\n",
        "      if train_step % log_interval ==0:\n",
        "        train_loss = current_loss /log_interval\n",
        "        train_acc = current_corrects / log_interval\n",
        "\n",
        "        print(\n",
        "            f'{train_step}: train_loss : {train_loss}, train_acc : {train_acc}'\n",
        "        )\n",
        "\n",
        "        cur_lr =optimizer.param_groups[0]['lr'] if scheduler is None else scheduler.get_last_lr()[0]\n",
        "\n",
        "\n",
        "        # tensorboard log\n",
        "        writer.add_scalar('Loss/train', train_loss, train_step)\n",
        "        writer.add_scalar('Acc/train', train_acc, train_step)\n",
        "        writer.add_images('Images/train', images, train_step)\n",
        "        writer.add_scalar('Learning_Rate', cur_lr, train_step)\n",
        "        writer.add_graph(model, images)\n",
        "\n",
        "        # wandblog\n",
        "        wandb.log({\n",
        "            'Loss/train': train_loss,\n",
        "            'Acc/train': train_acc,\n",
        "            'Images/train': wandb.Image(images),\n",
        "            'Ouputs/train': wandb.Histogram(outputs.detach().cpu().numpy()), # gpu를 쓰고있어서 detach, tensor를 numpy로 변경\n",
        "            'Preds/train': wandb.Histogram(preds.detach().cpu().numpy()),\n",
        "            'Labels/train': wandb.Histogram(labels.data.detach().cpu().numpy()),\n",
        "            'Learning Rate': cur_lr,\n",
        "\n",
        "        }, step =train_step)\n",
        "\n",
        "        current_loss = 0\n",
        "        current_corrects = 0\n",
        "\n",
        "      train_step +=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nkl9RSu7slY"
      },
      "source": [
        "--------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JndLxkz0ZVcb"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "loaded_model = torch.load(os.path.join(log_model_path, '/content/drive/MyDrive/#fastcampus/content/drive/Mydrive/#fastcampus/runs/dnn-tutorial-fashion-mnist-runs/2023-07-05T09:49:28-EfficientNetFinetune-RAdam_optim_0.001_lr_with_no_scheduler/models/val_loss-0.9057186841964722-model.ckpt'))\n",
        "\n",
        "loaded_model.eval()\n",
        "loaded_model.cpu()\n",
        "print(loaded_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lehinaVSZkuL"
      },
      "outputs": [],
      "source": [
        "test_batch_size = 100\n",
        "test_dataset = FashionMNIST(data_root, download =True, train=False, transform =transforms.ToTensor())\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size =test_batch_size, shuffle = False, num_workers =1 )\n",
        "\n",
        "test_labels_list =[]\n",
        "test_preds_list =[]\n",
        "test_outputs_list =[]\n",
        "for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave =True, desc ='testing')):\n",
        "  #forward\n",
        "  test_outputs = loaded_model(test_images)\n",
        "  _, test_preds = torch.max(test_outputs, 1)\n",
        "\n",
        "  final_outs = softmax(test_outputs.detach().numpy(), axis = 1) # detach : gpu->cpu # axis = 1 배치수 유지\n",
        "  test_outputs_list.extend(final_outs)                    ## softmax 한 model 결과 전체 list(확률화)   #append는 x 그 자체를 원소로 넣고 extend는 iterable의 각 항목들을 넣는다\n",
        "  test_preds_list.extend(test_preds.detach().numpy())     ## model 예측 라벨 결과 전체 list\n",
        "  test_labels_list.extend(test_labels.detach().numpy())   ## 실제 라벨 전체 list                       #최종적으로는 numpy로 바꾸는게 시각화나 변형이 쉽다\n",
        "\n",
        "test_preds_list = np.array(test_preds_list)\n",
        "test_labels_list = np.array(test_labels_list)\n",
        "\n",
        "print(f'\\nacc: {np.mean(test_preds_list == test_labels_list)*100}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4g5ULdkZm7b"
      },
      "outputs": [],
      "source": [
        "\n",
        "#ROC Curve 성능지표\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "thresh = {}\n",
        "n_class =10\n",
        "\n",
        "for i in range(n_class):\n",
        "  fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:,i], pos_label =i)\n",
        "\n",
        "# plot\n",
        "for i in range(n_class):\n",
        "  plt.plot(fpr[i], tpr[i], linestyle ='--', label =f'Class {i} vs Rest')\n",
        "plt.title('Multi-class ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()\n",
        "\n",
        "print('auc_score', roc_auc_score(test_labels_list, test_outputs_list, multi_class ='ovo', average ='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUO8rLXse4Le"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hw7qJRVynN0t",
        "IuE8K9aTXyIS"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMaQk4Vk8NKzfHLDuLi+zxD",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92cba11c1c80418cb67e5bcf2c2c8242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89a2860ed9594c1bb6399aaf61b5d1d5",
              "IPY_MODEL_2a3a38f591294dc28bec7a6b34047e81"
            ],
            "layout": "IPY_MODEL_198760c7fc7b47e894284de287597585"
          }
        },
        "89a2860ed9594c1bb6399aaf61b5d1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b3922462084a77ac301d8a2ffba914",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9dbc31476f4bb4a011834871af57e1",
            "value": "0.001 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "2a3a38f591294dc28bec7a6b34047e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdec7150bb8a49e48d6145791391390b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e2263a2fddb4c1baccc817b44099f35",
            "value": 0.07743552536112394
          }
        },
        "198760c7fc7b47e894284de287597585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77b3922462084a77ac301d8a2ffba914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9dbc31476f4bb4a011834871af57e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdec7150bb8a49e48d6145791391390b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2263a2fddb4c1baccc817b44099f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}