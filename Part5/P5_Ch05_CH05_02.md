# 합성곱 신경망 (CNN) - 2 CNN의 구성요소
## CNN의 구성요소
   <img width="575" alt="스크린샷 2023-06-30 오후 5 16 22" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6e17a3be-c0d3-42bc-b1a5-72858cd3c44f">
   <img width="486" alt="스크린샷 2023-06-30 오후 5 17 18" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/66064e1b-187f-461a-a9ac-cf70440499f4">

- 크게 아래와 같이 나눌 수 있다
1. Convolution layer (합성곱 층, 주황색) : 학습 가능한 필터들로 구성되어있다 
2. Pooling layer (통합 층, 파란색)  : 다운 샘플링을 한다 
3. Fully connected layer (MLP 층, 초록색)

## 1. 합성곱 층 (convolutional layer) – 국소적 연결 (local connectivity)
- 각 뉴런이 이전 층과 연결될 때, 모든 부분과 연결(fully-connected)되는 것이 아닌, 작은 국소적인 일부 영역에 연결(local connected)한다.
- 근접한 영역의 픽셀(피처)들에 집중하여, 특징을 더 잘 관찰하는 효과, 메모리 & 컴퓨팅 코스트를 줄이는 효과.
  <img width="592" alt="스크린샷 2023-06-30 오후 5 25 11" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/240e1a3c-e06a-43a3-9b8b-e90e2b5d5c09">

## 1. 합성곱 층 (convolutional layer) – 파라미터 공유 (parameter sharing) 
- 파라미터 공유(weight tying): 만약, 우리가 미리 학습과정에서 2번 이상 weight를 사용해 표현(representation)을 변환하는데, 그 변환 과정이 서로 거의 같아야 한다는 사전 지식(prior knowledge)가 있다면, 이를 이용할 수 있다.
  - 학습하여야 하는 파라미터를 줄인다.
- 그렇기 때문에 CNN에서 이미지 객체가 어떤 곳에 있든 그 객체의 특징을 일관되게 관찰할 수 있는 것이다.
  - Translate invariant (병진 대칭)하게 작동한다!
<img width="477" alt="스크린샷 2023-06-30 오후 5 27 53" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f621376a-01a2-4165-80d5-2f40130a5046">

## MLP에서 CNN까지

<img width="502" alt="스크린샷 2023-06-30 오후 5 28 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/03a692ff-a4cf-4ab5-88be-7f2967055134">

1. Connection을 local connected하게 자르고 
2. Weight sharing을 한다!

## 1. 합성곱 층(convolutional layer) - 합성곱(convolution)과 필터(filter) 
- 필터(filter) : 이미지의 특징을 찾아내기 위한 공용 파라미터 (shared parameter)
  - CNN에서는 동의어로 커널(kernel)이라고도 한다


- 컨볼루션(convolution) : 전제 인풋에, 필터를 순차적으로 감아(convolve(slide)), 결과를 낸다.
<img width="300" alt="스크린샷 2023-06-30 오후 5 31 10" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/73339bf1-5602-4350-9651-10a58107de31">
<img width="300" src ="http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif">

## 1. 합성곱 층(convolutional layer) - 채널(channel)
- 채널 (channel)
  - 이미지 픽셀 하나하나는 실수!

  - 그럼 컬러는?
    - 각 픽셀을 RGB 3개의 실수로 표현한 3차원 데이터인데, 여기서 각 차원을 채널!.

  - 만약 필터(kernel, shared weight)로 작용하는 것이 n개라면? : n개의 채널을 갖는다!

  - 전제 인풋에, 필터를 순차적으로 감아(convolve(slide)), 결과를 낸다.
    <img width="300" src ="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8e52d42f-d0fe-44ea-a782-ef2cbbac4340)">
    
    <img width="300" src ="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8680df77-8363-4164-8b43-532e18a65a67">

## 1. 합성곱 층(convolutional layer) - 걸음(stride)과 필터 사이즈 (filter size)
- 걸음 (stride) : 몇 걸음 단위로 convolution 을 진행할지 의미!
- 필터 사이즈 (filter size): Kernel size라고도 한다.
  - 필터의 크기의 사이즈
<img width="300" src ="http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif">
- stride = 1, filter size (노란 부분) = 3 x3 이다.
- 만약 stride = 2 라면?
  <img width="83" alt="스크린샷 2023-06-30 오후 5 38 18" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/57f894ab-e28d-449c-82fb-e8050e7fef19">

## 1. 합성곱 층(convolutional layer) - 1x1 convolution 
- 특수하게 1x1필터 사이즈의 convolution을 쓰는 경우가 많다.
  
  <img width="100" alt="스크린샷 2023-06-30 오후 5 42 57" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c547fff2-49fc-46f3-92ef-799b1b97f2a9">

- Why?
  - 인풋 값의 shape을 유지하면서 채널 수를 조절 할 수 있다.
  - 비선형 변환 효과(non-linearity)가 있다. (convolution 뒤에 activation 함수를 사용하므로..)
  - 계산하는 파라미터 수가 줄어들 수 있다!

- 예를 들면, 인풋이 128 채널이고, 3x3 필터를 가진 128채널의 convolution layer를 적용한다 했을 때, 파라미터 수는 3x3x128x128 = 147,456 개이다 ! 
  - 만약, 이전에 먼저 3x3 필터를 가진 128 채널의 convolution layer적용 이전에, 1x1 필터를 가진 32개 채널을 거친 뒤 간다면, 1x128x32 + 3x3x32x128 = 4,096 + 36,864 = 40,960 개로 줄어든다 ! 
  - Bottleneck 효과를 가질 수 있다!
## 1.합성곱 층(convolutional layer) - 확장 간격(dilation rate)
- 필터 사이의 간격을 의미한다. 3x3으로 filter size가 같을 때, 1, 2, 4 dilation rate일 때는 아래와 같다

<img width="486" alt="스크린샷 2023-06-30 오후 5 45 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/39d4529b-d586-4e91-b277-d2ea0cc973e9">

## 1. 합성곱 층(convolutional layer) - 패딩 (padding)
- convolution을 적용하면 보통  filter size와 stride, 그리고 dilation에 따라, 결과값(feature map)의 shape이 바뀐다.
  - 만약 feature map의 크기를 조절하고 싶다면? Padding 이 고려될 만 하다! 
  - 크게 full, same, valid를 가장 많이 쓴다!
  - 만약 패딩 값(padding value)이 모두 0이라면, zero-padding이라고도 부른다.

<img width="204" alt="스크린샷 2023-06-30 오후 5 46 04" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/cd4f122b-a20d-4b82-8688-01955a2c6858">

## 2. 통합 층(pooling layer) - 통합 (pooling)
- convolution layer에서 필터가 많아지면 feature map이 쌓이게 되는데 -> CNN차원이 커지고, 상응하는 많은 파라미터들이 생김 -> overfitting?
- 차원을 감소시켜보다. 또 계층적으로 (hierarchical) feature를 학습하는데 도움이 될 것이다 -> Pooling : 다운샘플링
- 경사하강(back-propagation시에도 연산을 줄여준다. <img width="146" alt="스크린샷 2023-06-30 오후 5 51 35" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/0c1cf8ce-abf8-46c9-9170-4cfece6ab5c4">

<img width="436" alt="스크린샷 2023-06-30 오후 5 51 57" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5268c884-cc63-4346-9ada-6432ca16ae65">

## 2. 통합 층(pooling layer) - Pooling의 종류
- General pooling layer
  - Filter size와 stride를 갖는다.
  - 필터 사이즈 내에 down sampling 가능한 aggregation함수를 사용한다. (min, max, average 등).

- Global pooling layer
  - Filter size와 stride를 갖지 않고, 모든 범위에 대하여 pooling을 한다.
  - 전체에 down sampling 가능한 aggregation함수를 사용한다. (min, max, average 등)

<img width="298" alt="스크린샷 2023-06-30 오후 5 54 27" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d28d9642-48d9-46db-92a1-1e82171eb4ca">

## FYI: 통합 층(pooling layer)의 대체 가능성
- 최초의 CNN은 pooling layer를 기본으로 가지고 있지만, 최근 연구 트랜드는 다른 cost를 줄일 수 있는 방법이 나오거나 컴퓨팅 파워가 더 나아져, 과감히 pooling을 쓰지 않기도 한다!
- 한편, pooling layer가 다운샘플링을 함으로서 field of view (시야각)을 넓히는 역할을 한다. (넓은 범위를 볼 수 있다.)
- 그런데 생기는 문제점? CNN은 오른쪽의 이미지들을 같은 얼굴이라고 인식한다.<img width="169" alt="스크린샷 2023-06-30 오후 5 55 29" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/3f17fc4d-d8fd-4a0b-9e22-d46554ceb95d">
  - (실제 사람의 시각 프로세스는 CNN과 다르게 그렇지 않다..)
- 이를 해결하기 위해, capsule net 등 아이디어가 나오고 있다. 
- 한편, data augmentation (cut mix 등)기법으로 어느정도 해결 가능 하다.

## 3. Fully connected layers 층
<img width="263" alt="스크린샷 2023-06-30 오후 5 56 20" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/cef81568-e66d-4495-8df5-a0986ac82a7f">

- 마지막으로 fully connected layer가 흩어져 있는 여러 채널정보들을 non-linear transform을 하고, output layer와 잇는다. 
- Output layer에서 나오는 결과로 loss를 계산한다. 여기서 만약 multi-class 분류라면, Softmax가 보통 사용될 것이다!

## CNN과 다른 기법들과 합치기.
- 활성 함수(activation), 드랍 아웃(dropout), 배치 정규화(batch normalization) 등을 배웠는데 그럼 이 기법들은 어느 타이밍에 적용해야 할까?
- Dropout: 저자에 따르면, activation function뒤에 적용하는 것이 좋다고 함! 
- Batch normalization: 원 논문에 따르면 convolution layer 또는 fully-connected layer 뒤에 적용되는 것이 좋다고 한다. 또한 ReLU와 같은 activation function을 적용하기 전에 적용하는 것을 추천하고 있음.
  - why? 배치 정규화의 목적이 네트워크 연산 결과가 원하는 방향의 분포 대로 나오는 것이기 때문에, 핵심 연산인 convolution 연산 뒤에 바로 적용하여 정규화 하는 것이 좋다!. 즉, activation function이 적용되어 분포가 달라지기 전에 적용하는 것이 좋다.

- 정리하면, Convolutional layer -> batch normalization -> activation -> dropout 순서!
- Pooling의 경우 task별로 달라질 수 있으나, 맨 뒤에 적용되는 것이 일반적!

## CNN의 종류 - 1D, 2D, 3D
- CNN은 2D로 한정되는 것이 아닌, 목적에 따라 여러 차원으로 확장될 수 있다.
- 1d : 오디오 등 시계 열 데이터, 2d : Pixel기반, 3d : Voxel기반

## CNN과 보통 결합하는 기술들 - 데이터 증강법 (data augmentation)
<img width="247" alt="스크린샷 2023-06-30 오후 6 00 26" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d56bcb9f-6d8c-4897-8fcd-338473575ea3">

## CNN과 보통 결합하는 기술들 - Transfer learning (전이 학습) - Fine-tuning (미세조정)
1. 소스 모델을, 데이터가 많은 소스 데이터로 학습!
2. 새 타겟 모델을 만든다. 이때, 새 모델을 이전 모델의 파라미터를 output layer 및 필요한 몇 부분만 남기고 가져온다. 
  - 이때, 이 모델은 소스 데이터의 knowledge prior를 가지고 있다고 하자!
3. 타겟 모델의 output layer 등 필요한 부분을 새로 추가한다.
4. 이렇게 만들어진 모델을 타겟 데이터로 학습을 진행한다. 
  - (보통 원래 train보다 작은 learning rate를 골라 “미세조정” 한다.)

<img width="250" alt="스크린샷 2023-06-30 오후 5 59 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e7b18f30-2b19-42f7-90db-57fb4eed3210">

## CNN과 보통 결합하는 기술들 - Network-in-network
- CNN의 구성 중에, 다른 MLP, self-attention 등을 사용하여 성능 / 컴퓨팅 코스트를 개선할 수 있다.
  - Network-in-network 에서, Mlpconv는 conv와 conv사이 mlp연산을 넣고, 맨 뒤 output layer 근처의 MLP를 축소하거나 없앰으로써, 파라미터 연산을 줄였다 !

<img width="421" alt="스크린샷 2023-06-30 오후 6 02 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/40506352-8882-4e7f-8396-ffb8db7205ab">


## 정리: AlexNet의 성능은?
- 1000개의 class를 분류할 때, 77% 의 정확도!
- 만약 top 5 accuracy라고 한다면 96.43% 로 매우 좋은 성과!
- Top 5 정확도?
- Logits (모델의 아웃풋)에서 ‘상위 5개를 뽑았을 때 그 안에 label이 있을 때를 맞췄다.’고 가정하고 측정한 정확도

<img width="270" alt="스크린샷 2023-06-30 오후 6 05 16" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8ff7eb7a-08b0-4341-a615-4ff4103e3b1e">






