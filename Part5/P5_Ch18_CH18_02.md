# Research Topics for Productions - 2. Overcoming Data Problem
## Production 상황에서 Data문제
Production 상황에서 data문제는 언제든 일어날 수 있다.
  - 모든 ML은 데이터에 의존적이다.
  - End-to-end로 설계되는 딥러닝은 데이터 의존도가 더높다.

어떤 문제들이 일어날 수 있을까?
  - 데이터부족
  - 데이터 Imbalance 문제
  - Label 부족
  - Data Sparsity 문제
  - + 데이터 noise 가 심하게 낀 상황 (outlier + 악성 attack)

## 데이터 부족 문제를 해결하는 방법 - Flow chart
<img width="663" alt="스크린샷 2023-09-06 오후 9 06 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a52c16a8-cdf2-4ad7-9202-408245d3f78f">

+ data anomaly detection, data imputation으로 더 개선!

## 데이터 부족 문제를 해결하는 방법 - Active Learning
기계학습에서 라벨링되지 않은 데이터에 대해 사람이 라벨을 랜덤 데이터에서 부여하면 이를 기계가 학습하는 방식으로 이루어진다.  
사람보다도 태스크를 잘 수행하는 모델이 등장하였는데, 이렇게 잠재적으로 뛰어난 기계를 두고 사람이 모든 라벨링을 진행하는 것은 조금 아깝다.  
어떤 데이터의 label이 더 필요한지를 판단하여 사람에게 labeling을 부탁하면 사람은 더 적은 labeling 비용을 들이고 좋은 모델을 학습할 수 있지 않을까?
  - Active learning!

<img width="500" alt="스크린샷 2023-09-06 오후 9 10 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4d918ca7-e5bc-4a4d-a1f0-f2a7c69f3e00">

## 데이터 부족 문제를 해결하는 방법 - Active Learning vs Semi-supervised learning?
- 같은 목표: 많은 레이블링 없이 좋은 퍼포먼스를 얻는 것이 목표!
- 다른 방법:
  - Semi-supervised learning: 레이블링이 되지 않는 것을 같이 이용! (왼쪽 그림)
  - Active learning: 레이블링 된 예제를 선택한다. (오른쪽 그림)

<img width="600" alt="스크린샷 2023-09-06 오후 9 12 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bda324a3-1371-4471-b803-28b21314b233">

## 데이터 부족 문제를 해결하는 방법 - Active learning을 위한 세팅 종류: learner가 데이터 인스턴스에 대한 라벨을 쿼리하는 세팅
Query synthesis

<img width="330" alt="스크린샷 2023-09-06 오후 9 15 05" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/018a933e-619a-420d-889f-1225f7b6a369">

- Learner 가 주어진 분포에 의거하여 데이터 인스턴스를 생성 혹은 구성하여 쿼리하는 것을 의미한다.
- 예를 들어, 숫자 이미지 분류 문제를 풀고자 할 때 학습 모델은 숫자 이미지와 비슷한 이미지(rotation, crop 등 data augmentation)을 만들어내고, 이를 라벨러에게 전송하여 라벨링을 요구한다.
  - Self-supervised learning?

Selective sampling

<img width="330" alt="스크린샷 2023-09-06 오후 9 15 31" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a84f7f79-d490-466d-aa7c-8763090590b5">

- 러너는 라벨링되지 않은 인스턴스를 보고, 해당 인스턴스가 가진 정보량에 의거해 이것이 라벨링 될 가치가 있는지 아닌지를 query strategy로 결정한다.
- 모델이 라벨링이 필요하다고 판단한 이미지는 쿼리하고, 아닌 것은 버리는 과정을 반복하며 학습이 이루어진다.
- 보통 라벨링되지 않은 데이터를 쉽게 얻을수 있는 경우에 사용하는 전략.

Pool-based active learning

<img width="330" alt="스크린샷 2023-09-06 오후 9 16 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/df94121b-9372-4fec-baf2-453c36ed93b8">

- 데이터풀에서 정보량 측도에 의거해 인스턴스들을 가지고 온다.
- 이때 정보량 측도는 데이터 풀에 있는 모든 인스턴스들에 대해 적용을 하고, 그중 가장 정보량이 많은 것들을 선택하는 식이다.
- 이 방식은 가장 널리 사용되는 방식으로 라벨링 되지 않은 큰 데이터 풀이 존재할때 사용하는 전략.

## 데이터 부족 문제를 해결하는 방법 - Query 전략의 예 (uncertainty measure)
<img width="340" alt="스크린샷 2023-09-06 오후 9 29 45" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c569a984-09c1-479b-951f-745866488aad">

<img width="340" alt="스크린샷 2023-09-06 오후 9 33 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b0409a8d-3f43-4393-ba8d-9ea30663df39">

최소 신뢰도(Least Confidence; LC): $𝒙_{LC}^*= 𝒂𝒓𝒈𝒎𝒂𝒙_x (𝟏 − 𝑷_\theta (\hat{𝒚} | 𝒙))$
  - 이 전략에서 학습자는 가장 "확실하게" 예측한 라벨에 대해 가장 확신도가 낮은 예제를 선택한다.
  - 예를 들면, d1은 라벨 A을 0.9의 confidence로, d2는 라벨 B를 0.5의 confidence로 가지고 있다면 러너는 d2의 실제 라벨을 골라 알고 싶어하는 전략이다.
  - 이 방법은 가장 그럴듯한 라벨에 대한 확신도만을 사용하고, 다른 라벨에 대한 확률은 고려하지 않는다.
  
마진 샘플링 (Margie sampling) :  $𝒙_{M}^* = argmin_x (𝑷_\theta (\hat{𝒚_1} | 𝒙) - 𝑷_\theta (\hat{𝒚_2} | 𝒙))$
  - LC전략의 단점은 가장 개연성이 높은 라벨만 고려하고, 다른라벨 확률을 무시한다는 것.
  - 마진 샘플링 전략은 발생가능성이 가장 높은 첫번째 라벨과 두번째 라벨사이에 가장 작은차이를 가진 인스턴스를 선택하여 이러한 단점을 극복한다.
  - d1을 보면, 첫 번째와 두 번째로 가능성이 높은 라벨 사이의 차이는 0.81(0.9 - 0.09)이고 d2의 경우 0.2(0.5 - 0.3)이다.
  - 그러므로, 차이가 작은 d2를 다시 선택한다.

엔트로피 샘플링 (Entropy sampling): $𝒙_{H}^*= 𝒂𝒓𝒈𝒎𝒂𝒙_x (-\Sigma_i  𝑷_\theta (\hat{𝒚_i} | 𝒙) log 𝑷_\theta (\hat{𝒚_i} | 𝒙))$
- 가능한 모든 레이블 확률을 활용하기 위해 엔트로피(정보량)을 사용한다.
- 엔트로피 공식(𝑝𝑙𝑜𝑔/𝑝)이 각 인스턴스에 적용되고 값이 가장 큰 인스턴스가 쿼리된다.
- 이 예에서 d1의 값은 0.155이고 d2의 값은 0.447이므로 학습자는 다시 d2를 선택한다.

## 데이터 부족 문제를 해결하는 방법 - Pooling 기반 active learning 의 예
<img width="400" alt="스크린샷 2023-09-06 오후 9 34 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5c236c86-e778-4b5e-b230-3975d3a6a8f9">

## 데이터 문제를 해결하는 방법 - Data anomaly detection
<img width="450" alt="스크린샷 2023-09-06 오후 9 37 06" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/dba1154d-0f5a-4b8e-9f9e-57e6050155e5">

## 데이터 문제를 해결하는 방법 - Normal vs Data anomalies
<img width="450" alt="스크린샷 2023-09-06 오후 9 38 53" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b14cb11b-8ac9-40de-829e-477c6f76c60b">

- 현재 보유중인 데이터셋 분포에 이전에 없던 형태의 새로운 데이터 형태가 등장하는 경우, 이러한 sample을 Novel sample, Unseen sample 등으로 부를 수 있다.
- 이러한 sample을 찾아내는 방법론을 Novelty Detection이라 부른다.
- Unseen sample 중 도메인과 관련이 없는 것은 anomaly, 관련이 있는 것은 novelty 라 한다. (논문에서는 혼용하여 사용하기도 한다.)
