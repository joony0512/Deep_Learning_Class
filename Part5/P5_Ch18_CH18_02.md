# Research Topics for Productions - 2. Overcoming Data Problem
## Production 상황에서 Data문제
Production 상황에서 data문제는 언제든 일어날 수 있다.
  - 모든 ML은 데이터에 의존적이다.
  - End-to-end로 설계되는 딥러닝은 데이터 의존도가 더높다.

어떤 문제들이 일어날 수 있을까?
  - 데이터부족
  - 데이터 Imbalance 문제
  - Label 부족
  - Data Sparsity 문제
  - + 데이터 noise 가 심하게 낀 상황 (outlier + 악성 attack)

## 데이터 부족 문제를 해결하는 방법 - Flow chart
<img width="663" alt="스크린샷 2023-09-06 오후 9 06 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a52c16a8-cdf2-4ad7-9202-408245d3f78f">

+ data anomaly detection, data imputation으로 더 개선!

## 데이터 부족 문제를 해결하는 방법 - Active Learning
기계학습에서 라벨링되지 않은 데이터에 대해 사람이 라벨을 랜덤 데이터에서 부여하면 이를 기계가 학습하는 방식으로 이루어진다.  
사람보다도 태스크를 잘 수행하는 모델이 등장하였는데, 이렇게 잠재적으로 뛰어난 기계를 두고 사람이 모든 라벨링을 진행하는 것은 조금 아깝다.  
어떤 데이터의 label이 더 필요한지를 판단하여 사람에게 labeling을 부탁하면 사람은 더 적은 labeling 비용을 들이고 좋은 모델을 학습할 수 있지 않을까?
  - Active learning!

<img width="500" alt="스크린샷 2023-09-06 오후 9 10 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4d918ca7-e5bc-4a4d-a1f0-f2a7c69f3e00">

## 데이터 부족 문제를 해결하는 방법 - Active Learning vs Semi-supervised learning?
- 같은 목표: 많은 레이블링 없이 좋은 퍼포먼스를 얻는 것이 목표!
- 다른 방법:
  - Semi-supervised learning: 레이블링이 되지 않는 것을 같이 이용! (왼쪽 그림)
  - Active learning: 레이블링 된 예제를 선택한다. (오른쪽 그림)

<img width="600" alt="스크린샷 2023-09-06 오후 9 12 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bda324a3-1371-4471-b803-28b21314b233">

## 데이터 부족 문제를 해결하는 방법 - Active learning을 위한 세팅 종류: learner가 데이터 인스턴스에 대한 라벨을 쿼리하는 세팅
Query synthesis

<img width="330" alt="스크린샷 2023-09-06 오후 9 15 05" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/018a933e-619a-420d-889f-1225f7b6a369">

- Learner 가 주어진 분포에 의거하여 데이터 인스턴스를 생성 혹은 구성하여 쿼리하는 것을 의미한다.
- 예를 들어, 숫자 이미지 분류 문제를 풀고자 할 때 학습 모델은 숫자 이미지와 비슷한 이미지(rotation, crop 등 data augmentation)을 만들어내고, 이를 라벨러에게 전송하여 라벨링을 요구한다.
  - Self-supervised learning?

Selective sampling

<img width="330" alt="스크린샷 2023-09-06 오후 9 15 31" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a84f7f79-d490-466d-aa7c-8763090590b5">

- 러너는 라벨링되지 않은 인스턴스를 보고, 해당 인스턴스가 가진 정보량에 의거해 이것이 라벨링 될 가치가 있는지 아닌지를 query strategy로 결정한다.
- 모델이 라벨링이 필요하다고 판단한 이미지는 쿼리하고, 아닌 것은 버리는 과정을 반복하며 학습이 이루어진다.
- 보통 라벨링되지 않은 데이터를 쉽게 얻을수 있는 경우에 사용하는 전략.

Pool-based active learning

<img width="330" alt="스크린샷 2023-09-06 오후 9 16 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/df94121b-9372-4fec-baf2-453c36ed93b8">

- 데이터풀에서 정보량 측도에 의거해 인스턴스들을 가지고 온다.
- 이때 정보량 측도는 데이터 풀에 있는 모든 인스턴스들에 대해 적용을 하고, 그중 가장 정보량이 많은 것들을 선택하는 식이다.
- 이 방식은 가장 널리 사용되는 방식으로 라벨링 되지 않은 큰 데이터 풀이 존재할때 사용하는 전략.

## 데이터 부족 문제를 해결하는 방법 - Query 전략의 예 (uncertainty measure)
<img width="340" alt="스크린샷 2023-09-06 오후 9 29 45" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c569a984-09c1-479b-951f-745866488aad">

<img width="340" alt="스크린샷 2023-09-06 오후 9 33 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b0409a8d-3f43-4393-ba8d-9ea30663df39">

최소 신뢰도(Least Confidence; LC): $𝒙_{LC}^*= 𝒂𝒓𝒈𝒎𝒂𝒙_x (𝟏 − 𝑷_\theta (\hat{𝒚} | 𝒙))$
  - 이 전략에서 학습자는 가장 "확실하게" 예측한 라벨에 대해 가장 확신도가 낮은 예제를 선택한다.
  - 예를 들면, d1은 라벨 A을 0.9의 confidence로, d2는 라벨 B를 0.5의 confidence로 가지고 있다면 러너는 d2의 실제 라벨을 골라 알고 싶어하는 전략이다.
  - 이 방법은 가장 그럴듯한 라벨에 대한 확신도만을 사용하고, 다른 라벨에 대한 확률은 고려하지 않는다.
  
마진 샘플링 (Margie sampling) :  $𝒙_{M}^* = argmin_x (𝑷_\theta (\hat{𝒚_1} | 𝒙) - 𝑷_\theta (\hat{𝒚_2} | 𝒙))$
  - LC전략의 단점은 가장 개연성이 높은 라벨만 고려하고, 다른라벨 확률을 무시한다는 것.
  - 마진 샘플링 전략은 발생가능성이 가장 높은 첫번째 라벨과 두번째 라벨사이에 가장 작은차이를 가진 인스턴스를 선택하여 이러한 단점을 극복한다.
  - d1을 보면, 첫 번째와 두 번째로 가능성이 높은 라벨 사이의 차이는 0.81(0.9 - 0.09)이고 d2의 경우 0.2(0.5 - 0.3)이다.
  - 그러므로, 차이가 작은 d2를 다시 선택한다.

엔트로피 샘플링 (Entropy sampling): $𝒙_{H}^*= 𝒂𝒓𝒈𝒎𝒂𝒙_x (-\Sigma_i  𝑷_\theta (\hat{𝒚_i} | 𝒙) log 𝑷_\theta (\hat{𝒚_i} | 𝒙))$
- 가능한 모든 레이블 확률을 활용하기 위해 엔트로피(정보량)을 사용한다.
- 엔트로피 공식(𝑝𝑙𝑜𝑔/𝑝)이 각 인스턴스에 적용되고 값이 가장 큰 인스턴스가 쿼리된다.
- 이 예에서 d1의 값은 0.155이고 d2의 값은 0.447이므로 학습자는 다시 d2를 선택한다.

## 데이터 부족 문제를 해결하는 방법 - Pooling 기반 active learning 의 예
<img width="400" alt="스크린샷 2023-09-06 오후 9 34 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5c236c86-e778-4b5e-b230-3975d3a6a8f9">

## 데이터 문제를 해결하는 방법 - Data anomaly detection
<img width="450" alt="스크린샷 2023-09-06 오후 9 37 06" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/dba1154d-0f5a-4b8e-9f9e-57e6050155e5">

## 데이터 문제를 해결하는 방법 - Normal vs Data anomalies
<img width="450" alt="스크린샷 2023-09-06 오후 9 38 53" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b14cb11b-8ac9-40de-829e-477c6f76c60b">

- 현재 보유중인 데이터셋 분포에 이전에 없던 형태의 새로운 데이터 형태가 등장하는 경우, 이러한 sample을 Novel sample, Unseen sample 등으로 부를 수 있다.
- 이러한 sample을 찾아내는 방법론을 Novelty Detection이라 부른다.
- Unseen sample 중 도메인과 관련이 없는 것은 anomaly, 관련이 있는 것은 novelty 라 한다. (논문에서는 혼용하여 사용하기도 한다.)

## 데이터 문제를 해결하는 방법 - Data anomaly detection 의 주요 사례
- Cyber-Intrusion Detection: 컴퓨터 시스템 상에 침입을 탐지하는 사례. 주로 시계열 데이터!
- Fraud Detection: 보험, 신용, 금융 관련 데이터에서 불법 행위를 검출하는 사례. 주로 표로 나타낸(tabular) 데이터!
- Malware Detection: Malware(악성코드)를 검출해내는 사례.
- Medical Anomaly Detection: 의료 영상, 뇌파 기록 등의 의학 데이터에 대한 이상치 탐지 사례.
- Social Networks Anomaly Detection: Social Network 상의 이상치들을 검출하는 사례.
- Log Anomaly Detection: 시스템이 기록한 log를 보고 실패 원인을 추적하는 사례. 주로 Text 데이터를 다룬다!
- IoT Big-Data Anomaly Detection: 사물 인터넷에 주로 사용되는 장치, 센서들로부터 생성된 데이터에 대해 이상치를 탐지하는 사례. 주로 시계열 데이터!
- Industrial Anomaly Detection: 산업 속 제조업 데이터에 대한 이상치를 탐지하는 사례.
- Video Surveillance: 비디오 영상에서 이상한 행동이 발생하는 것을 모니터링하는 사례. 주로 CCTV를 이용한 경우가 많음.

## 데이터 문제를 해결하는 방법 - Data anomaly detection 의 종류
<img width="400" alt="스크린샷 2023-09-07 오후 4 44 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/481bedc1-9e7c-447b-86d5-d94aa899f10d">

Supervised Anomaly Detection
  - 주어진 학습 데이터 셋에 정상 sample과 비정상 sample의 Data와 Label이 모두 존재하는 경우 Supervised Learning 방식이기 때문에 Supervised Anomaly Detection이라 부른다!
  - 실제로 Production에 적용하기에 labeling 문제를 해결 (class-unbalance 문제 등)하여야 하므로 잘 사용하지 X.

Semi-supervised (One-Class) Anomaly Detection

<img width="300" alt="스크린샷 2023-09-07 오후 4 43 20" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d3187d63-4b0e-4e13-835c-2dc521d66635">

  - 정상 비정상 binary classification / 혹은 metric learning setting 등으로 나누자!
  - 정상인 샘플을 중심으로, discrimination boundary를 정하고 가깝고 먼 것을 통해 outlier를 정한다.
  - 정상인 sample들에 대한 label 구분은 필요하다!

## 데이터 문제를 해결하는 방법 - Data anomaly detection 의 종류
Unsupervised Anomaly Detection

<img width="400" alt="스크린샷 2023-09-07 오후 4 49 33" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e731462c-a61a-43fb-9e67-b2fbdd3f1877">

- 대부분 데이터가 정상일 것이라 가정하고 unsupervised learning (VAE; metric learning 등)을 이용해 구분하자!
- Auto-encoder를 사용하는 방법?
- Autoencoder를 이용하면 데이터에 대한 labeling을 하지 않아도 데이터의 주성분이 되는 정상 영역의 특징들을 stochastic하게 정의하여 배울 수 있다!
- 이때, 학습된 autoencoder에 정상 sample을 넣어주면 위의 그림과 같이 잘 복원을 하므로 input과 output의 차이가 거의 발생하지 않는 반면, 비정상적인 sample을 넣으면 autoencoder는 정상 sample처럼 복원하기 때문에 input과 output의 차이를 구하는 과정에서 차이가 도드라지게 발생하므로 비정상 sample을 검출할 수 있다.

## 데이터 문제를 해결하는 방법 - Data Imputation
Data 가 sparse하다면 어떻게 하여야 할까? -> Data imputation!

<img width="500" alt="스크린샷 2023-09-07 오후 4 50 22" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/55fa5639-71c9-43b9-aa2c-920e1f4129ec">

가장 간단한 방법으로 평균을 채워넣는 방법도 있고, Machine learning 방법론으로는 MICE (multiple imputation by Chained equation) 방법 이 유명하다

## 데이터 문제를 해결하는 방법 - Data Imputation - MICE
<img width="500" alt="스크린샷 2023-09-07 오후 4 51 03" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bbdcf7e8-f738-49c1-b5ee-b1a80bdfec6d">

## 데이터 문제를 해결하는 방법 - Data Imputation ‒ DNN / semi-supervised setting을 이용하는 방법도 있다.
<img width="300" alt="스크린샷 2023-09-07 오후 4 51 29" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f4ef98a5-455b-4ef2-8fde-c00a0a7476dd">
