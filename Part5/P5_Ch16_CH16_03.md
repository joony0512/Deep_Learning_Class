# Meta Learning - 3. Model-based Meta Learning
## Model-based Meta Learning
- Model-based Meta Learning Model은 𝑝(𝑦|𝑥)의 형태를 특별하게 가정하지 않는다.  
- 대신 training step 을 많이 거치지 않아도 빠르게 학습할 수 있는 특별한 모델을 고안하여 사용한다.   
- 내부 모델 구조 변경 혹은 다른 meta-learner model 의 제어 등으로 빠른 매개 변수 학습이 가능하다.

## Model-based Meta Learning - Memory-Augmented Neural Network (MANN)
모델 외에 “외부 메모리”을 이용할 수 있지 않을까? (cf. LSTM의 메모리는 internal memory만을 가진다.) 
- 새로운 정보를 쉽게 결합하고, 정보를 잊지 않고 보존할 수 있음.
- 이런 종류의 모델을 memory-augmented neural network라고 한다!
- Neural Turing Machine & Memory Network 등이 대표적이다.

<img width="300" alt="스크린샷 2023-09-01 오후 4 56 45" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/81bc4a7d-b9da-4399-8fbd-8f942b687f7b">
<img width="300" alt="스크린샷 2023-09-01 오후 4 57 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a90cbe84-9e80-40d0-bf6b-bbd78a169f98">

## Model-based Meta Learning - Meta-learning with memory-augmented neural networks (2016)
<img width="500" alt="스크린샷 2023-09-01 오후 5 01 35" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4dd505bb-bccc-4958-90be-9206031486d1">

MANN은 새로운 정보를 빠르게 인코딩하여 몇 개의 샘플 후에 새로운 작업에 적응할 것으로 예상되기 때문에 메타 러닝에 적합  
Neural Turing Machine을 기본 모델로 삼아, training 설정과 메모리 검색 메커니즘 (또는 메모리 벡터에 주의 가중치를 할당하는 방법을 결정하는 "주소 메커니즘”)에 대한 메타 러닝 학습을 위한 방향 제안!

## Model-based Meta Learning - Meta-learning with memory-augmented neural networks (2016)
<img width="250" alt="스크린샷 2023-09-01 오후 5 06 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/0dce9356-371b-4da6-a999-455fdaeef154">

- Meta learning에 MANN을 사용하려면, 메모리가 새로운 작업의 정보를 빠르게 인코딩하고 캡처할 수 있고 그 동안 저장된 표현에 쉽고 안정적으로 액세스할 수 있는 방식으로 MANN을 훈련해야 한다.
  - NTM
    - NTM은 컨트롤러 신경망을 외장 메모리 저장 장치와 결합.
    - 컨트롤러는 메모리 행을 soft-attention로 읽고 쓰는 방법을 학습하는반면, 메모리는 지식 저장소 역할
    - Attention weights는 content 기반 + location 기반에 의해 생성된다.

<img width="300" alt="스크린샷 2023-09-01 오후 5 10 01" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/cb41ccca-8092-40b4-b1b7-b4f75e65830a">

- MANN for meta-learning의 meta-learning setup
  - 적절한 label 이 제시되기 전까지 long-term memory 에 정보를 저장.
  - Training episode마다, true label $𝑦_t$ 가 one step offset ( $𝑥_{t+1} ,𝑦_t$ )과 같이 존재.
  - 이전 time step t에서의 input에 대한 true label이지만, time step t+1에서도 주어진다!
  - 해당되는 label이 추후 제시될 때까지 메모리에 정보를 저장하고 있으므로, 새 데이터의 정보를 기억하게 모델이 디자인 되어있고 old information에서 prediction을 적절히 찾아올 수 있게 되어있다.
  

<img width="300" alt="스크린샷 2023-09-01 오후 5 11 00" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/573b2592-32bb-4d2e-89a0-0edff5d44686">

- Controller는 LSTM 혹은 feed-forward 네트워크를 이용. Controller는 external memory module에서 정보를 읽고 쓴다.  
== [READ] ==
- Input $𝑥_t$ 가 주어졌을 때 memory matrix $𝑀_t$ 의 row에 key( $𝑘_t$ )를 저장하 거나, 특정 메모리 i 정보 $𝑀_t(𝑖)$ 를 뽑는다.  
- 메모리 $𝑀_t$ 을 뽑을 때, cosine-similarity로 뽑는다. <img width="150" alt="스크린샷 2023-09-01 오후 5 12 18" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/598ad355-be62-4512-b642-5bf487086482">
- 이 measure를 read-weight, $𝑤^r_t$ 를 계산하는데 쓰고, softmax를 적용하여, 다음과 같이 계산. <img width="150" alt="스크린샷 2023-09-01 오후 5 13 52" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7535c13c-5f3f-4777-96e4-964d19b81617">
- 결과적으로 메모리 <img width="150" alt="스크린샷 2023-09-01 오후 5 14 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/052ca461-0237-4f71-8cec-fa6e1277b0ff"> 로 얻어지고, controller의 input으로 classification을 위해 사용된다.

== [Write] ==
- LRUA(least recently used access) writer라는 방식을 제안하고, 아래 단계를 따른다.
- Usage weight $w_t^u$ 를 t에서의 current read( $w_t^\gamma$ ← 𝑠𝑜𝑓𝑡𝑚𝑎𝑥 (𝑐𝑜𝑠𝑖𝑛𝑒( $𝑘_t, 𝑀_t (𝑖)$ ))와
- write vector( $w_t^w$ ), 그리고 γ가 decay parameter 가 적용된 이전 usage weight를 더해 구한다.
  - <img width="150" alt="스크린샷 2023-09-01 오후 5 19 06" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/565ad3ee-5639-4ab9-99b9-abac91cbf885">
- write vector는 <img width="200" alt="스크린샷 2023-09-01 오후 5 19 34" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5d0816c1-c4a0-40c6-89fd-e4176ef5da40"> 로,
  - 이전 read weights와 least-used weight <img width="150" alt="스크린샷 2023-09-01 오후 5 20 21" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4b9e5bce-7bb7-45d3-86cb-2aa1a3424cdb">의 convex combination로 구해진다.
  - 이때 𝜎는 sigmoid, 𝛼는 weight들간 interpolation을 위한 scalar gate parameter, $𝑚(w^u_t, n)$ 는 vector $𝑤_t^u$ 에서 n번째로 작은
element이다.
- $w_t^{lu}$ 가 $w_t^{u} (i)$ 의 계산 값으로부터 0로 set될 때, memory의 모든 row update는 다음과 같이 진행된다.
  - <img width="200" alt="스크린샷 2023-09-01 오후 5 27 55" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/627a9454-f5a9-4a42-a8da-6dafee809705">

## Model-based Meta Learning - Meta-learning with memory-augmented neural networks (2016) - 결과
<img width="500" alt="스크린샷 2023-09-01 오후 5 28 34" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/71f05a5e-1be2-4111-a82c-394149ca1662">
<img width="300" alt="스크린샷 2023-09-01 오후 5 28 50" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1061598a-0e9a-45ee-9391-5f3e970186bd">

## Model-based Meta Learning - Meta Networks (MetaNet; 2017)
2가지 서브 시스템으로 구성: base-learner 와 meta-learner.  
- Base-learner( $𝑏_\theta$ )는 task를 수행하고, meta-learner에게 loss gradient와 같은 meta-information을 전달한다.
- Meta-learner는 빠른 task-specific한 weight를 주어진 테스크에서 더 잘 수행할
수 있게, base-learner와 meta-learner자신을 위해 계산한다. ( $𝑇 = (𝐷_{T_j}^{tr}, 𝐷_{T_j}^{test})$ )
  - 3개의 neural networks로 $𝑢_\phi , 𝑚_\varphi , 𝑑_\psi$ 구성.
  - $𝑢_\phi$ : input representation function으로 사용된다.
  - $𝑚_\varphi , 𝑑_\psi$ : task-specific한 weight $𝜙^∗$ 와 base-learner의 example-level fast weights $𝜃^∗$ 를 계산하는데 사용된다. => base-learner의 task를 수행하는데 반영

- External한 memory을 사용
  - representation $𝑟_i$, 와 fast weights $𝜃_i^*$ 와 같은 위 컴포턴트의 support set과 관찰 값( $𝑥_i$)을 저장하고, attention-based representation을 얻는데 사용된다.
 
## Model-based Meta Learning - Meta Networks (MetaNet; 2017)
<img width="500" alt="스크린샷 2023-09-01 오후 5 38 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c966314a-c248-4f02-84b4-cf649a19cbf3">

<img width="250" alt="스크린샷 2023-09-01 오후 5 38 23" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/381df737-e131-40cb-ac6d-4e5d0ad4bd7e">

- [1] Sample T개를 support set으로 부터 만든다.
- [2-5] Sample로 Task-specific weight를 representation network( $𝑢_\phi$ ) 에 대해 계산한다.
- 이때, $𝑢_\phi$ 는 2개의 task를 진행한다.
  1. [10, 15]를 위한, input에 대한 representation을 학습한다.
  2. Input에 대한 prediction을 만들고, loss를 계산한다. [3]
    - Cross entropy나 contrastive loss가 사용가능하다.
- [6-12] 는 support set $𝐷_{T_j}^{tr}$ 에서, 모든 example ( $𝑥_i, 𝑦_i$ )을 이용. 
- [7] base-learner $𝑏_\theta$ 는 주어진 example로 prediction하고, loss를 계산한다.
- [8] [7]에서 구한 loss의 gradient를 구하고 이 값은, $𝑚_\varphi$ 를 통해 fast weight( $𝜃^∗_i$ )를 계산한다.
- [9] [8]의 계산을 example-level weight memory M의 i번째에 저장한다.
- [10-11] $𝑢_\phi$ 을 통해, representation( $𝑟_i$ )을 계산하고, representation memory R에 저장한다.
- [11-20] meta network의 query set $𝐷_{T_j}^{test}$ 을 처리한다.
  - [15] 모든 example (x, y)의 representation r을 $𝑢_\phi$ 로 얻는다.
  - [16] r을 memory matrix R에 저장되어있는 support set의 representation과 매칭하여 cosine similarity “ $𝑎_k$ ”을 구한다.
    - K는 k번째 R matrix row와 representation사이의 similarity의 의미
  - [17] similarity vector에 softmax를 취해, 확률 값으로 normalize 한 후, [9]에서 저장했던 example-level weight memory에 곱한다.
  - [18] weights ( $𝜃^∗$ )는 base learner b에 의해 사용되고, input에 대한 predict를 수행한다. 그리고, error를 구해, $𝐿_{task}$ 를 구한다.
  - [20] 모든 query_set의 example을 수행한후, $∇_\Theta L_{task}$ 으로, 각 모델 파라미터(Θ = {𝜃, 𝜙, 𝜓, 𝜑})를 업데이트 한다.

- 몇몇 neural network는 slow, fast weights를 동시에 사용할 경우가 있으므로, 다음과 같이 augmentation setup과 같은 형태를 취했다!

  <img width="250" alt="스크린샷 2023-09-01 오후 5 38 23" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/381df737-e131-40cb-ac6d-4e5d0ad4bd7e">

## Model-based Meta Learning - Simple Neural Attentive Meta-Learner (SNAIL; 2018)
<img width="400" alt="스크린샷 2023-09-01 오후 5 46 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a4418bca-daf2-4303-801f-c522de3eea96">

External memory에 의존하지말고, 특수한 형태의 모델 아키텍처를 사용하면, memory의 역할을 수행할 수 있다!  
- RNN? : 너무 작은 메모리 공간. Prior experience을 담긴 힘듦.
- SNAIL : 1D temporal convolutions(high-bandwidth memory access) + soft attention mechanism(one to pinpoint specific experience)
  - 1D temporal conv: Temporal convolution: 높은 bandwidth 를 가지게
  - Self-attention: 구체적인 경험 중 어떤 것이 필요한지 pinpoint
    
## Model-based Meta Learning - Simple Neural Attentive Meta-Learner (SNAIL; 2018)
<img width="500" alt="스크린샷 2023-09-01 오후 5 54 52" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a23aa610-039a-4cb9-aa7b-0486fcf6971e">

<img width="500" alt="스크린샷 2023-09-01 오후 5 55 09" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4fe5df18-d922-4381-8172-5fdf56191056">

3개의 block으로 이루어졌다.(TCBlock, DenseBlock, AttentionBlock)
- 바로 직전의 상황을 보는 Memory-augmented 방법들과 다르게, self-attention으로 동적의 영역으로 support set이 컨디션된 query set에서 좋은 prediction을 낸듯한 내부 dynamic을 찾는다.

장점?
- 높은 퍼포먼스.
- RL, 지도학습 둘다 적용가능!

## Model-based Meta Learning - SNAIL? : 2018년 논문 나왔던 시점 기준 SOTA에 가까운 퍼포먼스
<img width="400" alt="스크린샷 2023-09-01 오후 5 56 52" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ed39c935-a8c2-44e6-a755-70ce309af271">

<img width="453" alt="스크린샷 2023-09-01 오후 5 57 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/45001219-4b55-4b06-88ba-85cd77aba5cc">
