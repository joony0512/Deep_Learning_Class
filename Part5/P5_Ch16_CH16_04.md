# Meta Learning - 4. Optimization-based Meta Learning
## Optimization-based Meta Learning
- Optimization process(혹은 optimizer)를 스스로 학습할 수 있도록 한다. 
- Base-learner와 Meta-learner 두 가지를 사용해서 Base-learner는 실제로 맡은 업무를 train 하고 Meta-learner는 “base network를 optimize” 하도록 역할을 구성한다.

## Optimization-based Meta Learning - LSTM Meta-Learner (2016)
<img width="400" alt="스크린샷 2023-09-01 오후 6 02 38" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/eea845ae-f0e1-4ec4-8c21-7604291a56e7">

LSTM을 meta-learner (optimizer)로 모델링.   
Why?  
- LSTM의 cell state update와 gradient 기반 backpropagation은 닮았다
- Gradient update의 history를 아는 것은 단순히 업데이트 하는 것보다 낫다 (i.e. optimization의 momentum)

## Optimization-based Meta Learning - LSTM Meta-Learner (2016)
LSTM을 meta-learner (optimizer)로 모델링.
- Base learner(짧게 learner) model을 $𝑀_\theta$ , meta learner model을 $𝑅_\Theta$ 라고 하자.
- Learner model의 파라미터 업데이트는 원래의 SGD $𝜃_t = 𝜃_{t-1}: − 𝛼_t ∇_{\theta_{t-1}} 𝐿_t$
- 에서, LSTM에서의 cell state의 update는 다음을 따른다! (chapter 6참고) $𝑐_t = 𝑓_t ⨀ 𝑐_{t-1} + 𝑖_t ⨀ \tilde{𝑐_t}$
  - 만약, forget gate( $𝑓_t$ )를 항상 1이라 두고, cell state $𝑐_t$ 를 $𝜃_t$ , input gate( $𝑖_t$ )를 $𝛼_t$ 라 하면,
  - 위의 식은, $𝜃_t = 𝜃_{t-1}: − 𝛼_t ∇_{\theta_{t-1}} 𝐿_t$ 로 같아진다!

- 즉, LSTM의 cell state식은 SGD의 일반화 식이며, $𝑓_t,𝑖_t$ 는 학습 가능한 다른 값을 취해, dataset에 따라 adaptable하게 적용시킬 수 있다!

## Optimization-based Meta Learning - LSTM Meta-Learner (2016)
<img width="300" alt="스크린샷 2023-09-01 오후 6 13 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/90461993-d3c7-44af-a678-595deb811049">

일반화 하여, learner 모델의 업데이트 식을 정리하면 다음과 같다.

<img width="300" alt="스크린샷 2023-09-01 오후 6 13 28" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e6f864e0-4f0a-411f-ac0f-513e5b92411d">

-> $R_\Theta ( \nabla_{\theta_{t-1}} L_t, L_t, \theta_{t-1}) = f_t ⨀ \theta_{t-1} + i_t ⨀ \tilde{\theta_t}$

## Optimization-based Meta Learning - LSTM Meta-Learner (2016)
<img width="599" alt="스크린샷 2023-09-01 오후 6 16 42" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/573baac1-da40-4100-97ee-952eed903879">

## Optimization-based Meta Learning - Model-Agnostic Meta-Learning (MAML; 2017)
- SGD를 사용하는 어떤 모델이라도 적용가능한 meta-learning 알고리즘.
- 모델이 $𝑓_\theta$, task를 $𝜏_i$, 관련된 데이터 셋을 ( $𝐷_{train}^{(i)} , 𝐷_{test}^{(i)}$ )이라고 한다면, 
- 모델 파라미터를 1번 혹은 더 많은 gradient descent step으로 업데이트 가능 할 것이다.

  <img width="300" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/9bf2556d-2daf-43ca-8325-d47ae622d490">

- 만약, 1개 step이고, 1개의 dataset이라면,
- <img width="150" alt="스크린샷 2023-09-01 오후 6 22 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5ad1c95d-a677-4020-890f-a1b852cd8be2">일 것이고, 여러 task로 일반화 하면 meta-object는 아래의 식으로 최적화 한다.
- <img width="280" alt="스크린샷 2023-09-01 오후 6 22 48" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6d2f3ad0-10e5-4232-8a34-540494b889b5">

## Optimization-based Meta Learning - Model-Agnostic Meta-Learning (MAML; 2017)
<img width="300" alt="스크린샷 2023-09-01 오후 6 25 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d4ca6b56-779d-41f5-bbba-ed574aa229f6">
<img width="300" alt="스크린샷 2023-09-01 오후 6 25 58" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fbf515d8-a4f9-4e36-8e46-34d98b55af35">
<img width="300" alt="스크린샷 2023-09-01 오후 6 26 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fd4e58ae-278b-4b24-acf9-dd429a6c899d">

## Optimization-based Meta Learning - Model-Agnostic Meta-Learning (MAML; 2017) ‒ First-order version
<img width="300" alt="스크린샷 2023-09-01 오후 6 25 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d4ca6b56-779d-41f5-bbba-ed574aa229f6">

Meta-optimization은 [8] 부분! 만약 효율적으로 한다면?
- $𝜃_{meta} ← 𝜃_{meta} − 𝛽𝑔_{MAML}$

$𝐿_{\tau_i}^1$ 을metalearner의학습, $𝐿_{\tau_i}^0$ 을 learner의 학습이라하자. 

<img width="300" alt="스크린샷 2023-09-01 오후 6 29 59" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8a0484b5-3ca1-4c22-a84f-3cde0fda76c2">

- 으로 정리된다. First-order 는 $∇_{\theta_{i-1}} (∇_\theta 𝐿^0(𝜃_{i-1})$ 을 생략한 형태로, <img width="150" alt="스크린샷 2023-09-01 오후 6 31 11" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1d6fe36c-9bf7-4957-9cd2-9f41883e95d8"> 을 만족한다.

## Optimization-based Meta Learning - Latent embedding optimization (LEO; 2018-2019)
<img width="300" alt="스크린샷 2023-09-01 오후 6 37 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5faa1b18-d210-460e-a504-9ddd4cdab628">

<img width="400" alt="스크린샷 2023-09-01 오후 6 37 03" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b058b046-8191-451b-b706-a57c5475e6f9">

- 높은 차원의 파라미터 스페이스에서 gradient information을 사용가능하도록, 낮은 차원의 Latent variable(z)을 사용.  
- Task $𝜏_j$ 가 주어졌을 때, 해당하는 support set $D_{𝜏_j}^{tr}$ 를 encoder에 넣고, hidden code를 얻어낸다.
- 그 hidden code는 가능한 모든 방법으로 pair되고, concat 되어, N이 training set의 class수고, k가 class별 sample 수일때,
- $(𝑁𝑘)^2$ 의 pair가 된다.
- Paired codes는 metric-based방법의 relation network을 이용하여, latent 값을 얻는다.
- 그 값은, class 별로 나타내고, $𝑧_{n∈X}$ 으로 표현된다.
- $𝑥_n^l$ ∈ $D_{𝜏_j}^{tr}$ 을 class n의 𝑙 번째의 sample이고, $𝜙_e ,𝜙_r$ 이 encoder와 relation net의 parameter 라고 할 때 다음과 같이 표현될 수 있다.

  <img width="350" alt="스크린샷 2023-09-01 오후 6 36 34" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b9ecc400-48b7-4c05-b34d-f7cd71c74695">

## Optimization-based Meta Learning - Latent embedding optimization (LEO; 2018-2019)
<img width="600" alt="스크린샷 2023-09-01 오후 6 38 24" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b5732933-ca75-464c-8121-a88f94912f06">
