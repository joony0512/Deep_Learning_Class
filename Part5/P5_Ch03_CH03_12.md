## CH03_12-Regularization-L2-norm=Early-stopping[TheorySession1]

### Early Stopping과 L2-norm 정형화

- Early Stopping과 L2-norm 정형화는 사실 같다

### Recall :L2

- L2 식과 미분식

    ![Untitled (36)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/88910d33-d9c3-4a7f-a444-10467b716e0e)

    
- 학습에 의해 최적화 하는 값 weight w*에 대해 최적화 하는 목적함수가 있다고 해보자.
- 만약 weight 파라미터들이 모두 선형이고 이를 Taylor근사함수를 통해, 2차식까지 근사시킨다면
    ![Untitled (37)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e31ef735-dbb9-4869-8f5a-ab89af77faa2)

    
    - 여기에 L2를 붙이면 다음과 같다.  
        ![Untitled (38)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d4c997e8-56b3-4705-8162-11c926c59068)

        
    - 우리는 $J^{hat}(w)$가 최적화되는 때를 구할것이다.
        
        $\nabla_w \hat J (w) =0$
        
    - 미분을 통해 $\tilde w$를 구할수있다.  
        ![Untitled (39)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/941ee414-bb62-4827-90f7-557e94a6465e)

        
    - Eigenvalue decomposition(고유값분해)에 의해 
    $H = Q\Lambda Q^T$로 표기할 수 있다.
        - $\Lambda$ : 고유값의 대각행렬
        - $Q$: 고유값의 직교행렬
    - 이때 $\tilde w= Q(\Lambda + \alpha I )^{-1}\Lambda Q^Tw^*$를 만족한다.
        - $w$는 $w^*$에 비례해 scaling되고, $\alpha I$에 의해 decay효과가 있다.
        - 즉, H의 i번째 eigenvector를 $\lambda_i$라고 하면 $\lambda_i \over \lambda_i +\alpha$ 로 스케일링된다.
        - $\alpha$가 $\lambda$보다 클수록 큰 regularization효과를 준다.

### Early Stopping :점화식을 통해 보기

- 학습에 의해 최적화하는 값 weight $w^*$에 대해 최적화하는 목적함수가 있다고 하자.
- 만약 weight 파라미터들이 모두 선형이고 이를 Taylor근사함수를 통해, 2차식까지 근사시킨다면
    ![Untitled (40)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/3531b2eb-df44-415d-afe9-7297df8408f0)

    
    - w에 대해 미분하면, gradient는 $\nabla_w \hat J (w) = H(w-w^*)$가 된다.
    - 즉 모델 업데이트 식은
    $w^T = w^{t-1} - \eta\nabla_w \hat J (w^{t-1}) = w^{t-1} -\eta H( w^{t-1}- w^*)$
    라고 할 수 있다.
    - 양변에 $w^*$을 빼고 정리하면
    $w^{t-1}- w^* = (I-\eta H)(w^{t-1}- w^*)$ 이 된다.
        - 여기서 H를 고유값분해($H = Q\Lambda Q^T$)하고 ,
        양변에 $Q^T$곱하면 다음과 같이 정리된다.
            ![Untitled (41)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/daddc489-e5f0-44a6-9a30-aa0aabc947b8)

            
            위 등비수열 점화식에서 $w^0 = 0$, 그리고 $\eta$가 잘 골라져, 충분히 작게 $|1-\eta\lambda_i| <1$을 만족한다면, 일반항을 구하면
            ![Untitled (42)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8d6c0a87-88a9-499f-b8f3-9a4b728c919d)

            
            이다.
            
        - 이때 L2에서 봤던식을 다시보면,
         $\tilde w= Q(\Lambda + \alpha I )^{-1}\Lambda Q^Tw^*$에서
            ![Untitled (43)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7731ac65-0174-4521-a9a2-1b7e5f76a1e0)

            
            을 만족했었다.
            
    - $\eta, t, \alpha$는 하이퍼 파라미터이므로 조절하여,
    $(I -\eta \Lambda)^t = (\Lambda + \alpha I)^{-1} \alpha$를 만족시킨다면, 두수식은 같게 된다.
    - 즉 L2와 Early Stopping이 매칭된다.
- 따라서 L2나 Early Stopping을 둘다쓰기보다는 둘중 하나만 골라서 쓰는 경우가 대부분이다.
