# <Generative model series #5> Distribution Alignment - 3. Variations & Application
## StarGAN (2018) - 단일모델로 다중 도메인 변환을 쉽게할수있을까?
- CycleGAN, DiscoGAN, pix2pix, cGAN 등에서는 한 개의 특징 만을 학습해서 변환.
  - Cycle loss로 구현된 신경망은 웃는 얼굴을 우는 얼굴로 바꾸는 작업 밖에 하지 못하고, 각 특징 별로 기능을 추가하여야 한다.
- 이런 환경에서 다양한 도메인으로 변환하려면 도메인 D개가 있을 때, O(D^2)만큼 모델과 loss반영이 필요하다!

  <img width="320" alt="스크린샷 2023-08-24 오후 4 59 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/cd79e413-85f6-4a90-b8bb-1d8a29e5d001">

- 단일 모델로 줄일 수 있을까? - StarGAN!
  - 하나의 신경망을 이용해서 많은 도메인으로 변환하기 때문에 일반적인 지식을
- 학습하여 더 높은 퀄리티의 이미지를 생성. (multi-task learning?)
  - 측면에서도 매우 경제적 !
 
## StarGAN (2018) - 모델 아키텍처와 키 아이디어
<img width="500" alt="스크린샷 2023-08-24 오후 5 00 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1f3496c9-9d3f-481a-b1e7-975cb2a5b1ad">

- Vanilla GAN에서는 잠재 변수(z)을 입력 값으로 받는 반면, StarGAN에서는 변환하고자 하는 도메인 정보(c)와 원본 이미지(x)을 input 으로 한다.
- Discriminator D(x)는 원본 이미지의 Real/Fake여부에 더해서 특정 도메인 정보까지 맞추는 것이 목표!
- Generator: G(x, c)는?
- 하나의 손실함수로 많은도메인 학습필요
- 원본 이미지(x)와 타켓 도메인(c; one-hot vec.)가 주어졌을 때, 원본 이미지를 타겟 도메인으로 변환필요

## StarGAN (2018) - 목적함수
<img width="380" alt="스크린샷 2023-08-24 오후 5 06 04" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/9dd1083a-d32c-4f91-99db-2e13ab510492">

Adversarial loss
- 기존 GAN(i.e. vanilla GAN, WGAN..)의 손실함수이되, generator는 z를 input으로 받는 것이 아닌, x, c를 input으로 받는다.  

Domain classification loss (discriminator)
- Discriminator는 주어진 이미지가 원본인지 가짜인지 구분하는데 더해 원본 이미지의 도메인 정보까지 예측

Domain classification loss (generator)
- generator의 결과물 역시, 도메인 정보 예측 필요!

Reconstruction loss
- Cycle consistency loss로, 이미지의 퀄리티 유지!

x: 원본 이미지 , c: 바꾸고자 하는 도메인, cʼ: 원래 이미지의 도메인

## StarGAN (2018) - 최종목적함수
$L_D = - L_{adv} + \lambda_{cls} L^\gamma_{cls}$  
$L_G = L_{adv} + \lambda_{cls} L^f_{cls} + \lambda_{rec} L^f_{rec}  $
• $\lamba_{cls}, \lambda_{rec}$ 은 하이퍼 파라미터.
• 논문에서는 $\lamba_{cls}$ =1, $\lambda_{rec}$ =10로사용

## StarGAN (2018) - 결과
<img width="500" alt="스크린샷 2023-08-24 오후 5 12 17" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/02d7af20-e7a8-489c-a313-708dd8c9e1c1">

<img width="200" alt="스크린샷 2023-08-24 오후 5 12 34" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e213fcf4-a60f-4ed8-b488-844af3a44ce6">

<img width="200" alt="스크린샷 2023-08-24 오후 5 12 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e1dbf670-1b10-45d6-8acb-1710782d27b1">

- 2개 이상의 도메인에서도 잘 된다!

## StarGAN v2 (2020) - 모델
- 기존 StarGAN에서 mapping network와 style encoder 그리고 목적 함수(손실 함수)을 개선
- StarGAN 에서는 각각의 도메인에 대해 동일한 변형만 가능했다면 domain-specific style code로 변경하여  
image to image translation도 가능하도록 하며, 다양한 도메인에 대한 style transfer가 가능하게 됨

<img width="450" alt="스크린샷 2023-08-24 오후 5 13 58" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/296b2b2e-9f79-4d67-a59b-09c303bbbee7">

Notation
- Mapping network $𝐹_y (𝑧) → 𝑠̃ $ 는 target domain y에 있을 법한 스타일 코드 s를 생성하는 것이 목표!
- Generator: 𝐺(𝑥, 𝑠) → 𝑥′ 는 style(s)과 이미지 x를 input으로 받는다. s를 통해 도메인 y의 분포와 같이 이미지를 생성하는 것이 목표!
- Style encoder: $𝐸_y(𝑥) = 𝑠̂$ 는 이미지 x에서 도메인 y에 대한 스타일 벡터(𝑠̂)를 return 한다.

## StarGAN v2 (2020) - 목적함수
<img width="300" alt="스크린샷 2023-08-24 오후 5 17 12" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4b13962d-75a6-4a1f-b5fd-9c4aa636c21b">

- $L_{sty}$ : generator가 이미지를 생성할 때, 𝑠̃를 따르하도록 하기 위함.
  - 단일 encoder로 여러 도메인에 대해 다양한 출력을 뽑을 수 있게 해준다.
    
- $L_{ds}$ : generator가 다양한 스타일의 이미지를 생성할 수 있도록 한다.
  - 여기서 $\tilde{s_1}$ , $\tilde{s_2}$ 는 mapping network F가 만들어낸 스타일벡터이고,
  - 𝑠̃, = 𝐹((𝑧,)를 최대화 하여 G가 다양한 이미지를 생성할 수 있는 style vector를 찾게 한다.
    
- $L_{adv}, L_{cyc}$ 는 기존과 거의 동일하되 style로만 바꿈.

## StarGAN v2 (2020) - 결과
<img width="450" alt="스크린샷 2023-08-24 오후 5 22 23" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/8742017d-b288-4eee-94ac-b03f9beb1166">

<img width="240" alt="스크린샷 2023-08-24 오후 5 22 42" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bf692138-318d-4d23-813a-e02c3465c9a3">
<img width="300" alt="스크린샷 2023-08-24 오후 5 23 03" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4cbb3622-0969-4fd9-917d-1706f1f18a27">


## NLP 도메인 - Unsupervised monolingual translation
<img width="800" alt="스크린샷 2023-08-24 오후 5 23 58" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f9df8a27-1035-4cba-b539-feae9fe9b326">

NLP 도메인의 기계 번역에도 적용할 수 있다! (굳이 pair로 없어도 학습 가능하다!)
- Monolingual language models (= marginal matching)
- Back translation (= cycle consistency)
