# Meta Learning - 1. Learning to Learn
## Meta Learning이란?
- Meta-learning은 몇몇 training 예제를 통해서 모델로 하여금, 새로운 기술을 배우거나, 새로운 환경에 빠르게 적응할 수 있도록 설계하는 방법이다.
- “Meta”: 한 단계 더 상위 버전의 의미.
- 즉, 학습하는 것을 학습하는 방법으로, “Learning To Learn” 이라고도 알려져있다.
  - 적은 샘플로의 Domain 적응 (domain adaptation)이나, few-shot learning 등을 위해 활용된다!
 
## Meta Learning 이전의 기본적인 접근법? - Fine-tuning (transfer learning)
- Meta training data를 통째로 사용해 먼저 학습
  - 실제 적용하려는 도메인에 fine-tuning 을 적용.
    
단점
- 다른 도메인에 곧바로 적용이 불가하다.(Fine-tuning에도 적당한 레벨의 데이터 역시 필요하다, 즉, few-shot이 불가!)
  - 다른 방법은..?

<img width="300" alt="스크린샷 2023-08-31 오후 9 18 29" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c7a0cc07-c44f-4717-9569-dcbefd3f22cd">

## Meta Learning - Recap: Few-shot learning
Few-shot learning은?
- 데이터 수가 매우 적은 문제로 few-shot training에 사용하는 서포트 데이터(support data)와 test에 사용하는 쿼리 데이터(query data)로 구성된다.
- 범주(class)의 수를 N, 범주 별 support data의 수를 K라 할 때, 'N-way K-shot' 문제라고 부른다! 만약, K가 1이라면, one-shot learning, K가 0이라면 zero-shot learning이라고도 부른다! (Remind GPT2, GPT3)
- Meta learning은 few-shot learning의 일반적인 해결방법이다!

## Meta Learning 문제
좋은 meta-learning model은?
- 학습하려는 task의 다양성(variety)을 학습할 수 있어야 하며, 인지되지 못한 잠재 task를 포함하여
- 여러 task의 분포 상에서도 좋은 성능을 낼 수 있도록 최적화되어야 한다.
- 각 task들이 dataset 𝐷 로 구성되어 있다면, 여기에 각각 feature vector들과 true label들이 포함되어 있다!
- 이때 optimal model의 parameter는 다음과 같다.

  <img width="200" alt="스크린샷 2023-09-01 오후 3 40 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6132c4b8-c158-4ea7-9821-db6f95096d8d">

- 즉, 여러 개의 데이터 셋 중에서 샘플링 된 dataset 𝐷에 대해, loss function $𝐿_\theta(𝐷)$ 을 최소화할 수 있는 𝜃을 찾는다!

## Meta Learning 문제
<img width="500" alt="스크린샷 2023-09-01 오후 3 42 22" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/dcaef813-3214-4d22-82dc-9554fa57d233">

Meta learning model의 optimal model의 parameter는 다음과 같다.

<img width="200" alt="스크린샷 2023-09-01 오후 3 40 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6132c4b8-c158-4ea7-9821-db6f95096d8d">

위의 식은 일반적인 learning task와 유사하지만, 하나의 dataset 자체가 하나의 data sample로 활용되고 있다.  
Few-shot classification? -> supervised learning 상에서 meta-learning을 활용한 예시.

## Meta Learning - Training을 Testing과 같은 방법으로 바라보는 관점
<img width="200" alt="스크린샷 2023-09-01 오후 3 40 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6132c4b8-c158-4ea7-9821-db6f95096d8d">

- 에서, classification이라면,
- dataset D는 여러 쌍의 feature vector와 label들을 포함하고 있고, 𝐷 = { $(𝑥_i,𝑦_i)$ } 로 표현할 수 있다 이때 $y_i$ 는 각 label set $𝐿_{all}$ 에 포함되어있다고 해보자.
- 이때 파라미터 𝜃를 가진 classifier $𝑓_\theta$ 는 주어진 데이터가 feature vector x에 대해 class y에 속할 확률인 $𝑃_\theta (𝑦|𝑥)$ 를 출력으로 내보낼 것이다.
- 이때, training batch를 B라고 나타내면, 위의 식은 아래와 같이 표현될 수 있다.

  <img width="400" alt="스크린샷 2023-09-01 오후 3 50 17" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5f5f4df3-66e8-491d-9779-01db4801142c">

## Meta Learning - Training을 Testing과 같은 방법으로 바라보는 관점
- Few-shot classification의 목표는 "fast learning" 을 위해서 추가한, 약간의 support set을 가지고, unknown label에 대한 데이터의 prediction error를 줄이는 것이다. ("fine-tuning"이 수행되는 과정과 유사)

- 모델이 모든 label에 대해서 인지하고, optimization procedure를 수정하는 것 없이, 궁극적으로 fast learning이 이뤄질 수 있도록 하자.
  - Inference 중에도 training process를 모방한 과정을 넣기 위해서, dataset에 약간의 수정.

1. Label set에서 일부를 샘플링 한다. $𝐿 ⊂ 𝐿_{all}$ 
2. Support set과 training batch를 dataset로부터 샘플링한다. ( $𝑆^L ⊂ 𝐷, 𝐵^L ⊂ 𝐷$ )
   - 𝐿에 속하는 label을 가진 데이터만 가지고 있어야 한다. 𝑦 ∈ 𝐿, ∀(𝑥,𝑦) ∈ $𝑆^L, 𝐵^L$ 
3. Support set( $𝑆^L$ )은 model input의 부분이다.
4. Final optimization 단계에서 supervised learning에서 하는 것과 동일한 방법으로 mini-batch $𝐵^L$ 을 이용하여 loss를 계산하고 backpropagation을 통해 model parameter을 업데이트 한다.


<img width="400" alt="스크린샷 2023-09-01 오후 3 56 22" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4febc6b5-fe43-49e1-9556-77bb66cdbd17">
은, 앞의 1~4과정을 다른 dataset을 포함하도록 일반화할 수 있다.   

즉, 다음의 meta learning 식으로 다시 표현될 수 있다. 
<img width="300" alt="스크린샷 2023-09-01 오후 3 57 03" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ace0ee93-ed91-41d0-bbbb-49b762ee07aa">

-> Transfer learning (pre-training + fine-tune)도 넓은 의미에서 위 식에 포함될 수 있다.

## Meta Learning - Learner와 Meta-learner의 2가지 학습과정으로 보는 관점
Meta learning을 바라보는 또다른 관점은 model update하는 과정!

- 보통 모델 update는 두 단계로 나타내질 수 있다.
  - $𝑓_\theta$ 를 전통적인 classifier형태의 learner 모델이라 하고, 주어진 task을 수행할 수 있도록 학습한다.
  - 그동안, optimizer $𝑔_\phi$ 는 주어진 support set S을 가지고, learner model의 parameter 𝜃을 update하는 방법을 학습한다.
    - (𝜃′ = $𝑔_\phi$ (𝜃, 𝑆))
- Final optimization step에서는 𝜃와 𝜙을 둘다 업데이트 한다!

<img width="345" alt="스크린샷 2023-09-01 오후 4 05 21" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/81bd07c3-c071-4cbd-a049-f456b977b42c">

## Meta Learning의 종류
보통 3개 정도의 접근 방식이 있다.
  
1.(metric-based) efficient distance metric을 학습하고 이를 이용하는 방식  
   
   <img width="200" alt="스크린샷 2023-09-01 오후 4 06 46" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/025a9c9c-f8c2-4c05-876d-d11bc3c51b20">
(k: similarity measure)   

  - 14강에서 다뤘던 metric learning을 응용!
    
2. (model-based) external/internal memory를 가진 모델을 사용하는 방식
   - $𝑃_\theta (𝑦|𝑥) → 𝑓_\theta(𝑥,𝑆)$  
3. (optimization-based) fast learning을 위한 model parameter를 최적화하는 방식.
   - $𝑃_\theta (𝑦|𝑥) → P_{g_\phi (\theta, S^L)} (y|x)$  
  
