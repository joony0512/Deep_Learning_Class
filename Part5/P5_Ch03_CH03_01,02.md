## CH03_01.Regularization소개

- 정형화(Regualrization)의 종류는?
    1. 제한(restrictions)을 거는 파라미터 값 등을 넣는 방법 
    2. 학습 데이터를 설명하는 여러개의 가설 모델들을 혼합하는 방법
    3. 최적화 프로세스를 수정하는 방법
    4. 데이터 분포의 이전정보(prior knowledge)를 이용하여 추가적인 학습데이터를 더해, 모델학습에 정형화하는 방법.ex) 확률분포 사용

## CH03_02.Noam기반Regularization

- 머신러닝은, 학습가능한 파라미터를 가진 목적함수를 튜닝하는것이다.
    - $J(\theta)=J(\theta) + \lambda\Omega(\theta)$
    - $\Omega(\theta)$: 정형화 (페널티) 함수
- 본정형화 함수중 가장 쉽게 더할 수 있는것중 하나는 파라미터$\theta$의 norm을 구하는 것이다.
    - Norm : $(\Sigma_i x_i^n)^{1/n}$

### L1 regularization(Lasso), L2 regularization(Ridge)

- L1(Lasso) (n=1)
    
    ![Untitled (8)](https://user-images.githubusercontent.com/109457820/236435445-3f294173-b985-4d11-a992-812825cef276.png)
    
- L2(Ridge) (n=2)
    
    ![Untitled (9)](https://user-images.githubusercontent.com/109457820/236435482-0c8132e7-d440-4a17-904c-fb1537bbe0b3.png)
    

### L1 regularization(Lasso) vs L2 regularization(Ridge)

![Untitled (10)](https://user-images.githubusercontent.com/109457820/236435522-523e0905-c5aa-4a3d-88e3-810213ab6e7f.png)

- L1, L2 Regularization은 Error를 증가시켜 최적화를 하는데 제약을 준다. → 과적합 방지
- L1그림에서 $\theta_{opt}$가 train시 loss가 최소가 되는 지점이라고 생각하면
    - L1의 경우 대부분 만나는 경우가 모서리 맨 끝이다. →$\theta$중 하나가 0이 된다(Sparcity가 생긴다).
    - Sparcity가 좋은점
        - 많은 파라미터들이 0이 되기 때문에, 모델이 압축되어 컴퓨팅 파워 코스트를 줄일 수 있다.
        - 0이 아닌 부분을 주로 볼 수 있기 때문에, 모델이 더 나은 해석 능력을 가진다.
        - 거의쓰지 않는 feature와 관련된 부분이 0이 되어, feature selection의 효과를 지닌다.
            
            > 높은차원의 학습이나, 데이터 주도 방법에 효과가 있다.(data-driven)
            
        
    - L1을 미분 할 경우, 유일 해가 아닐 수 도 있다. → solution에 대해 불안정하다
    - stochastic gradient descent로 구할 경우, 한번에 최적해를 구하는 것이 아니고, 점차 근사해 나가기 때문에, 결과적으로 sparse하게 만드는 solution이 아닐 수도 있다.
- L2의 경우 원(구)와 같은 형태이기 때문에, 만나는 지점이 원이 접하는 어디든 균등하게 될 수 있다(Grouping이 된다).

![Untitled (11)](https://user-images.githubusercontent.com/109457820/236435559-973228ff-fd68-4293-94b6-586a11ef0c0b.png)
