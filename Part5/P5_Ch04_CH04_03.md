## CH04_03_학습과최적화의차이와minibatch알고리즘

## **경험적 위험도(empirical risk), 그리고 머신 러닝의 일반화 (generalization)**

### ****일반화 에러(generalization error), 실제 위험도(true risk)****

- 일반적인 기계학습에서 음수가 아닌 실수인 손실함수(loss)를 머신러닝 모델 f에 대해서 나타낼때, $L(f(x), y)=L(\hat{y}, y)$라면, 
어떤 새로운 데이터 (x,y)에 대해, ML모델 f의 실제위험도를 아래와 같이 정의할 수 있다.
$R(f) = E[L(f(x)),y)] =\int L(f(x),y) dP(x,y)$
- 이때 이 값을 일반화에러(****generalization error****)라고 한다.
- 딥러닝을 포함한 머신러닝의 목표는 일반화 에러를 최소화 하는 최고의 모델  f를 찾는것이다.
$f^* = arg\ \underset{f\in F}min R(f)$

### 경험적 위험도(**empirical risk)**

- 그렇지만 일번적으로 우리는 실제환경데이터의 확률분포 P(x,y)를 알지 못한다 → 즉 실제 위험도를 알 수 없다.
- 그렇기 때문에 경험적위험도(**empirical risk)** 를 대신 최소화 하여 근사한다.
    - $R_{emp} (f) =$ $1\over n$ $\Sigma_{i=1}^n L(f(x_i),y_i)$
    - $\hat{f} = arg\ \underset{f\in F}min R_{emp}(f)$
    - 이러한 최소화 과정을 경험적 위험도 최소화(empirical risk minimization;ERM)이라고 한다.
    - 그러나 이 경험적 최소화는 ‘근사’라는 의미처럼, 실제위험도 최소화를 의미하는것은 아니기 때문에, train외에 vaild/test를 따로 해야한다.

### Batch와 minibatch

- 일반적인 ML에서 우리는 train데이터로 학습할 것이기에, empirical risk minimize 할것이다.
$\hat{f}(\theta) = arg\ \underset{f\in F}min R_{emp}(f(\theta)) =\Sigma_{i=1}^n f_i(\theta)$
- 예를 들어 MLE의 경우 $\theta \* = arg  \underset{\theta}max \Sigma_{i=1}^m log_{p_{model}}(x^i, y^i;\theta)$ 으로 튜닝하는 것이 목적이고, 이때 목적함수는 $J(\theta)= E_{x,y\sim \hat{p}}logp_{model}(x^i, y^i;\theta)$이다.
    - 그러나 모든것을 exact하게 한번에 하려면 매우 비싸기 때문에 학습데이터를 쪼개서 몇개씩 배치로 모아 학습하고 추후 test data로 따로 error구해서 테스트 하는 방법을 사용하는건 어떨까?
    
- 경사하강법에서 전체학습데이터를 사용하는것을 이를 batch혹은 결정론적(deterministic) 경사하강법이라고 한다.
이를 수식으로 나타내면 $\theta := \theta -t \Sigma_{i=1}^n \nabla f_i(\theta)$
- 만약 반대로 한번 최적화 할때 한개의 샘플만 골라서 한다면 이를 확률적(stochastic)혹은 online방법이라고 한다. $\theta := \theta -t\nabla f_i(\theta), i\in{1,...,n}$
- 많은 ML모델이 stochastic한 방법이되, 한개보다는 많은 샘플로 학습하는데 이를 Minibatch혹은 확률론적인 미니배치(minibatch stochastic)방법이라고 한다. 
$\theta := \theta -t \Sigma_{i=1}^n \nabla f_{r_i}(\theta), r_i\in1,...,n$
