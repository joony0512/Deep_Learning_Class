# Deep generative models #1 - Autoregressive vs autoencodervs embedding vs seq2seq - 3. Auto-encoder
## Auto-encoder (오토 인코더)
- 오토 인코더(auto-encoder)는 input 을 그대로 output 으로 복사하듯 생성하는 것을 목표로 하는 신경망
- 하지만,  이는 훈련과정에서 reconstruction error를 줄이는 것 이상을 의미할 수 있다! 아래 application 을 보자.
  
  <img width="541" alt="스크린샷 2023-07-27 오후 9 56 39" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ca44b538-b8a9-43eb-8e34-55cddbf3d954">

### Application

1. Embedding
  - 중간에 bottle-neck구조를 취해, 압축된 잠재 변수(latent variable; latent vector; representation)을 얻기 위한 목적

2. Generative models 
  - 생성물을 원본 대비 의도적인 변형(압축, 노이즈 제거등) 이 가해진 출력을 "생성"하기 위한 목적
  - 예) denoising auto-encoder

### 수식 / 그래프 표현식으로 쓰면 다음과 같다.
<img width="435" alt="스크린샷 2023-07-27 오후 10 06 44" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6ded6a09-a101-4ef5-93a9-a6291b58f508">

이때 encoder/decoder함수는 어떠한 함수, network여도 관계없다.
- Encoder
  - z = f(x)
- Decoder
  - $\hat x$ = y = g(f(x))
  <img width="300" alt="스크린샷 2023-07-27 오후 10 07 04" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/9746ef57-52a5-426f-9dc6-d79da042a4b9">

## Vanilla (pure) auto-encoder의 응용 - Dimension reduction (차원 축소) | image restoration
<img width="559" alt="스크린샷 2023-07-27 오후 10 08 38" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c02b1980-e98e-4d68-8661-d07633f18527">

- 잘 학습된 auto-encoder는 PCA 등 기존 ML보다 성능이 좋다.
  
<img width="400" alt="스크린샷 2023-07-27 오후 10 09 20" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fdf94312-aeb7-4990-ad8a-ee41df5ab365">

- Bigdeli, Siavash Arjomand, and Matthias Zwicker. "Image restoration using autoencoding priors." arXiv preprint arXiv:1703.09964 (2017).

## Auto-encoder의 종류 - encoder decoder에 따라
<img width="400" alt="스크린샷 2023-07-27 오후 10 10 23" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/0ecf5c69-50fd-4e64-8f21-058a4273bff0">
<img width="400" alt="스크린샷 2023-07-27 오후 10 10 35" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/46eebfa2-ab88-4922-8f96-1ca699e4d684">

<img width="400" alt="스크린샷 2023-07-27 오후 10 10 59" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6fd01934-b4ad-4f34-9421-5d8ee9b927c2">
<img width="400" alt="스크린샷 2023-07-27 오후 10 11 12" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/3c2645b0-5db7-4973-8cfa-206c1390ea7b">

## Auto-encoder의 종류 - 학습 방법 (목적 함수)에 따라…  (TBD)
- Variational Inference (VI)의 방법을 이용한 variational auto-encoder (VAE)
  
<img width="330" alt="스크린샷 2023-07-27 오후 10 13 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/21e6aca6-2516-406c-92ce-381a37d6c56d">

- Generative adversarial network (GAN)의 학습 방법을 이용한 adversarial auto-encoder (AAE)
- 
<img width="460" alt="스크린샷 2023-07-27 오후 10 14 08" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/94887fb8-5301-43e1-abe8-5a360670521f">
<img width="336" alt="스크린샷 2023-07-27 오후 10 14 26" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/de94ab56-e958-40a4-8324-ce8251406bde">
