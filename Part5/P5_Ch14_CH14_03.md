# Deep Metric Learning - 3. Contrastive Learning의 발달 (SIMCLR, Supervised Methods)
## Contrastive Learning
분류(classification), 생성(generation), 군집화(clustering) 등 task를 할 때,  
outer space 에서 model output 을 직접 이용하지 않고, representation space 에서 contrastive objective을 사용하여 손실(loss)을 계산하는 것을 "Contrastive Learning"이라 한다!   
이때, contrastive objective는 꼭 contrastive loss가 아니어도 된다!  
  
예를 들어, contrastive learning이 triplet loss여도 상관이 없다  
- 보통, contrastive learning에서의 contrastive objective는 input 간의 similarity/dissimilarity representation을 학습하길 기대한다.

<img width="300" alt="스크린샷 2023-08-27 오후 6 00 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/aa041f62-f6cb-452c-90b3-1f92e62974a4">

## Recap: Self-supervised learning (자기 지도 학습)
- 자기 지도 학습(Self-supervised learning)
  - 다량의 레이블이 없는 원데이터로부터 데이터 부분들의 관계를 통해 레이블을 자동으로 생성하여 지도학습에 이용
  - Pretext task를 설정(i.e. 데이터의 일부분을 은닉하여 모델이 그 부분을 예측하도록 학습)하여 이를 학습한 후, downstream task로 전이 학습 (transfer learning) 하여 다른 task에 적용.
- Pretext task로 contrastive task (data augmentation + similarity measure)을 수행하면 어떨까?
- 아니면 바로 loss식을 적용하여 pretext task없이 end-to-end로 한번에 학습하면 어떨까?

  -> Contrastive self-supervised learning!

## Semi-supervised Contrastive Learning - SimCLR (2020)
4가지 주요 구성요소로 2020 self-supervised SOTA. 

<img width="400" alt="스크린샷 2023-08-27 오후 6 18 16" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/12e8c9fb-5b03-4421-b722-a498d40cb731">

- Data augmentation
  - 같은 이미지 샘플을 다른 두 가지 버전(positive pair)로 변형시키는 stochastic data augmentation module이 존재.
    - Random cropping, random color distortions, random Gaussian blur 적용
      
- Encoder: f(·) -> DNN(ResNet)기반 encoder(f)로 representation vector을 뽑는다.
  
- Neural network projection head: g(·) -> representation들을 contrastive loss가 적용된 space로 매핑
  - 1 은닉층 MLP 사용
    
- Contrastive prediction task
  - Positive pair인 $x_i$ 와 $x_j$을 포함한 set { $𝑥_k$ } 가 주어졌을 때, contrastive prediction task는 주어진 $x_i$ 에 대해 { $𝑥_k$ } 𝑘 ≠ 𝑖 에서 $x_j$ 을 식별하는것을 목표로 한다.

## 목적 함수는?

- N개 example이라면, 파생된 augmented examples의 쌍에 대해 각각 N개 씩 총 2N data points가 생성.
- 나머지 2(N-1)을 negative sample로 처리 
- Pairwise similarity( $s_{i,j}$ )를 모든 𝑖, 𝑗 ∈ {1 ... , 2𝑁}에 대해 계산 -> 논문에서는 cosine similarity로 계산. <img width="100" alt="스크린샷 2023-08-27 오후 6 20 36" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/481fd8de-bea4-4687-a9f5-accbe44c6638">

- Loss function(𝑙(𝑖, 𝑗)): NT-Xent (normalized temperature-scaled cross entropy loss) (a.k.a. SimCLR loss) 모든 pair에 대해 계산된다! 즉, 아래와 같다.

  <img width="250" alt="스크린샷 2023-08-27 오후 6 21 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/26c4b3fe-4488-4eeb-b45e-8197526a2863">
  
  <img width="300" alt="스크린샷 2023-08-27 오후 6 21 44" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2b6fb5b4-9885-4976-8140-f76f317b326a">
  
  <img width="300" alt="스크린샷 2023-08-27 오후 6 22 01" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/840c7228-1059-4fc2-84c9-f73da430f3b5">

- Data augmentation을 contrastive learning에 적극적으로 이용
  - data augmentation 조합이 성능에 영향을 크게 미친다!

    <img width="300" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/a99428ea-4f05-4390-8ac8-a75568cbbd74">

    <img width="350" alt="스크린샷 2023-08-27 오후 6 24 53" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f6868b5d-0d19-4b83-aea6-41a22b8289ec">
    
- Contrastive task에서 positive pairs를 완벽하게 찾아내는 모델이더라도 single transformation은 좋은 representation을 만들지 못한다.
- Composed augmentations의 경우에는 contrastive prediction task가 더 어려워졌지만 representation의 퀄리티는 극적으로 향상!

<img width="500" alt="스크린샷 2023-08-27 오후 6 25 57" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5f093daa-90b1-491b-afe7-b0633b0688fe">

<img width="300" alt="스크린샷 2023-08-27 오후 6 26 09" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c0b0f454-6e04-4f09-a735-8e8be33c9e02">

- NT-Xent(Normalized Temperature-scaled Cross-Entropy) loss가 보다 나은 성능!

<img width="300" alt="스크린샷 2023-08-27 오후 6 27 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7c59fd0f-49c2-4c9f-8708-dd89ee9c7db1">

- ImageNet accuracy of models trained with few labels

<img width="500" alt="스크린샷 2023-08-27 오후 6 28 17" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ad8dd59b-01c1-4380-a077-f78c108817c0">

- Comparison of transfer learning performance

## Supervised Contrastive Learning (2020)
<img width="300" alt="스크린샷 2023-08-27 오후 6 28 55" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f6d787c0-8cfc-449b-89ee-d3a4018bcefd">

- Self-supervised 로만 보통 이용되던 contrastive learning 을 supervised learning로 확장!
  - 기존 사용하던 cross-entropy성능을 능가!

<img width="450" alt="스크린샷 2023-08-27 오후 6 30 11" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/011e4ada-9369-4866-b4ca-3c0e39ba200c">

- Self-supervised 일 때, 같은 class라도 같은 샘플에서 나오지 않았으면 negative로 구분되었음
  - 같은 class을 positive sample로 정의
  - 보다 많은 positive sample과 많은 negative sample을 사용가능
 
## Supervised Contrastive Learning (2020) - Cross-entropy vs Self-supervised Contrastive vs Supervised Contrastive

SIMCLR와 유사하게, 아래의 4개의 모듈 로 이루어져 있다
1. Data Augmentation module
2. Encoder Network
3. Projection Network
4. Contrastive prediction task

<img width="350" alt="스크린샷 2023-08-27 오후 6 31 57" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/554d9e45-987c-49f4-8922-06215e05768c">

## Supervised Contrastive Learning (2020) - 목적함수
𝑖: 𝑎𝑛𝑐h𝑜𝑟, 𝑗(𝑖) : 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒 𝑠𝑎𝑚𝑝𝑙𝑒, {𝑘 ∈ 𝐴(𝑖) \𝑗(𝑖)} : 𝑛𝑒𝑔𝑎𝑡𝑖𝑣𝑒 𝑠𝑎𝑚𝑝𝑙𝑒 (2(𝑁 − 1) 𝑖𝑛𝑑𝑖𝑐𝑒𝑠)   
𝑧 = 𝑃𝑟𝑜𝑗(𝐸𝑛𝑐 $\tilde{x}_i$ ) ∈ $𝑅^{Dp}$ , 𝐴(𝑖) = 𝐼\{𝑖}, 𝑡𝑒𝑛𝑝𝑒𝑟𝑎𝑡𝑢𝑟𝑒 𝑝𝑎𝑟𝑎𝑚𝑒𝑡𝑒𝑟 ∶ 𝜏 ∈ $𝑅^+$  일때 self-supervised contrastive loss는 아래와 같이 나타낼 수 있을 것이다,

<img width="340" alt="스크린샷 2023-08-27 오후 6 35 56" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1d5b829e-f706-458b-8d47-4ca5c2a1dc82">

이를 label이 있는 supervised 버전으로 바꾸면, 𝑃(𝑖) = {𝑝 ∈ 𝐴(𝑖) : $\tilde{y}_p = \tilde{y}_i$ }라면,

<img width="380" alt="스크린샷 2023-08-27 오후 6 37 31" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fa68de73-34fb-4019-8460-329cb0fac5c7">
이 된다.   

참고: 논문에서는 2개 버전의 loss를 제안했다!

<img width="400" alt="스크린샷 2023-08-27 오후 6 38 08" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b30dad6d-e75c-4561-90d1-0efc72059076">

- SIMCLR처럼 2개 augmented된 positive pair사용. (2N개 batch)
- 이때, 같은 class내의 다른 이미지도 positive로 사용하여 많은 positive를 활용

## Supervised Contrastive Learning (2020) - 결과적으로, SimCLR loss와 N-pair loss의 일반화!
<img width="295" alt="스크린샷 2023-08-27 오후 6 38 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bb7155b6-9db5-4c0d-b0f4-3c5865a0148d">

## Supervised Contrastive Learning (2020) - 결과
<img width="400" alt="스크린샷 2023-08-27 오후 6 39 19" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/85b5825a-9d0d-464c-92ec-3415b43240f8">

<img width="400" alt="스크린샷 2023-08-27 오후 6 39 38" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d6cb72ec-a213-469b-b4e7-83c07be42fe0">
