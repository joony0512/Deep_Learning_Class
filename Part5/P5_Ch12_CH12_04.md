# <Generative model series #4> - Implicit Models - 4. GAN의 발전 - part 1
## Deep Convolutional GAN(DCGAN; 2015-2016) - Convolutional Net + GAN 

- 기본 GAN의 fully-connected layer을 CNN로 바꾸면 어떨까?
	- 이때 generator는 up-sampling을 위해 de-convolution layer를 쓰자! 
- Spatial max pooling을 지우고, 대신 strided convolution을 쓰자!
- 또한, Batch-normalization을 각 layer 뒤에 넣어보자! (그러나, generator의  output, discriminator의 input 에는 X)
- Generator에 ReLU를 hidden layer에 쓰고, Tanh를 output layer에 쓰자!
- Discriminator에는 Leaky ReLU를 쓰고, sigmoid output을 쓰자.

  <img width="407" alt="스크린샷 2023-08-20 오후 6 33 28" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/164aabfc-c3a3-41d5-88ae-2f6d6091c87d">

## Deep Convolutional GAN(DCGAN; 2015-2016) - 결과 – Vector arithmetic, Interpolation, representation learning
<img width="300" alt="스크린샷 2023-08-20 오후 6 34 36" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/93f13ea3-8f47-47d9-9647-d7db13417c14">

<img width="200" alt="스크린샷 2023-08-20 오후 6 34 59" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b04c93f3-8e29-4814-9bf0-1a3198c67d8f">

<img width="250" alt="스크린샷 2023-08-20 오후 6 35 19" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fad4493f-ac93-4dbc-9c36-9a2e1ca08dd2">

## Deep Convolutional GAN(DCGAN; 2015-2016) - 의의와 남은 문제
GAN이 좋은 품질로 생성되고 interpolation도 가능함을 보임!

그러나, 아래 문제들은 개선될 여지가 많음!
- 불안정한 학습
- 아키텍처에 따라 성능이 많이 달라진다!
- 하이퍼 파라미터의 변경에 의해 성능이 많이 달라진다!

## Improved techniques for training GAN (2016) - OpenAI팀에 의해 GAN의 추가 발전 방향이 제시됨!
- Feature matching
- Historical averaging
- Minibatch discrimination
- Virtual batch-normalization
- One-side label smoothing
- Semi-supervised learning
- Inception Score(exp($𝐸_x 𝐷_{KL}$ (𝑝(𝑦|𝑥)||𝑝(𝑦)))도 여기서 제안되었다.
  - 모델의 성능과 사람의 판단을 correlate 시킨다!
  - 생성물의 다양성을 보장할 수 있다!

## Improved techniques for training GAN (2016) - Feature matching
