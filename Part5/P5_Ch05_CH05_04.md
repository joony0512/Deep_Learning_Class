# 합성곱 신경망(CNN) - 4 Recent trends of CNN models
## CNN의 발전 방향 - SeNet(2017 -2018)
- SE Block을 Convolutional layer뒤에 병렬적으로(skip connection과 함께) 붙여 성능을 개선 !

  <img width="249" alt="스크린샷 2023-06-30 오후 7 00 26" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/14555a04-6517-4830-9e65-5d803567cce9">

  <img width="451" alt="스크린샷 2023-06-30 오후 7 00 53" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e69bfb49-943b-485c-9553-acd1106ca2d2">

- 1. $F_{tr}$ : conv transformation을 수행 : 사이즈 변환된다  
  -> conv연산 ($v_c$가 필터일때):<img width="147" alt="스크린샷 2023-06-30 오후 7 09 06" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bf3e6cd4-7c36-4ae0-84f6-f85147d88e60">
- 2. $F_{sq}$ : squeeze : U의 output의 각 채널별 정보를 global average pooling등으로 squeeze(추출)한다.  
  -> <img width="187" alt="스크린샷 2023-06-30 오후 7 11 40" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/9b26e657-2f67-44c2-809e-af98e50a8018">
- 3. $F_{ex}$ : excitation : 스칼라의 가중치를 계산한다. $\sigma$b : sigmoid, $W_1$,$W_2$ : fully-connected, $\delta$ =ReLU
  -> $s = F_{ex}(z, W) = \sigma(g(z, W)) = \sigma (W_2 \delta (W_1 z))$
- 4. $F_{scale}$ : 스칼라 가중치를 U의 출력값에 더한다.
 
## SE block의 장점
1. 유연하다 -> convolutional net에도 붙일 수 있다.
2. 추가적인 계산량이 적다.
   - 파라미터 증가량이 조금 있으나, 성능 향상이 확실하다.
   - 파라미터가 $W_1$,$W_2$ 가 추가되지만, ratio를 작게 설정하면 파라미터 수가 작아진다.
   - convolutional layer 하나당 $2C^2 /r$개의 파라미터만 늘어난다.
       - 논문에서는 r=16일때가 보통 적절하다.
  - 2017 imagenet challenge (ILSVRC)기준 SOTA
    <img width="692" alt="스크린샷 2023-06-30 오후 7 23 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/de1a984c-f049-488c-b74b-9fb1b2e2af0b">
## CNN의 발전 방향 - SeNet (2017-2018)의 성능
<img width="666" alt="스크린샷 2023-06-30 오후 7 23 53" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c2ebc0f5-2f85-4740-a51a-24ec11d09401">

- 모든 블록 모듈이 각 모델들에 붙을 경우, 성능이 조금씩 상승!

## CNN의 발전 방향 - Self-training(자가 학습 기법)
- 자가 학습(self-training)

  - 준지도 학습 (Semi-supervised learning)
    - 레이블된 데이터와 레이블 되지 않는 데이터 모두 사용되는 학습.
    - 일반적으로, 다수의 레이블되지 않는 데이터와 레이블 된 골드 레이블 (gold label) 데이터로 구성.

  - 자기 지도 학습(Self-supervised learning)
    - 다량의 레이블이 없는 원데이터로부터 데이터 부분들의 관계를 통해 레이블을 자동으로 생성하여 지도 학습에 이용
    - Pretext task를 설정(i.e. 데이터의 일부분을 은닉하여 모델이 그 부분을 예측하도록 학습)하여 이를 학습한 후, downstream task로 전이 학습 (transfer learning) 하여 다른 테스크에 적용.
    - Pretext task:  데이터 내의 semantic한 정보를 이해할 수 있도록 새로 정의한 임의의 문제
   
- 자가 학습(self-training) : 셀프 트레이닝의 원리는 높은 확률 값이 나오는 데이터 위주로 가져가, 먼저 학습을 진행한다 ! 

<img width="464" alt="스크린샷 2023-07-01 오후 6 32 52" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/dcc44872-7350-4294-9253-0b9343b5b93f">

## CNN의 발전 방향 - Self-training(자가 학습 기법)과 Noisy Student (2020) 
- 순서

1. EfficientNet 모델을 teacher 모델로, ImageNet데이터(약 1천만 이미지)로 학습시킨다.

2. 학습 된 teacher 모델로 라벨이 매겨져 있지 않은 3 억장의 이미지에 라벨을 매긴다.

3. teacher 모델보다 크기가 같거나 큰 student network를 생성한 뒤, ImageNet 데이터와 라벨을 매긴 데이터를 합쳐서 학습시킨다.
  - 이때, data augmentation, dropout, stochastic depth 등을 적용한다!

4. 학습된 student 모델을 teacher 모델로 바꾸고, 2-4 과정을 반복한다.

- 원 논문의 설명
<img width="334" alt="스크린샷 2023-07-01 오후 6 34 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/47e51b47-a391-4ffa-9d8f-bfe8caea745a">

<img width="265" alt="스크린샷 2023-07-01 오후 6 34 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/12e84767-3e2f-4431-a16a-743047f2b494">

- 결과
  
<img width="434" alt="스크린샷 2023-07-01 오후 6 36 08" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f99faca8-054d-4c89-9da5-5eaeb8f519a8">

<img width="181" alt="스크린샷 2023-07-01 오후 6 36 28" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/52165525-8bf0-4498-afc1-6704e3b6a6c2">

- 노이즈와 adversarial attack(적대적 공격)에 튼튼하다.

<img width="261" alt="스크린샷 2023-07-01 오후 6 38 48" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5bb0b372-bfa4-4ac6-a23c-8f826eb9caa1">

- 참고: ImageNet-A,C,P
  - 모델의 robustness을 테스트하기 위해 ImageNet의 corruption을 담은 데이터
  - burring, fogging, rotation, scaling 등이 들어있음
    
<img width="195" alt="스크린샷 2023-07-01 오후 6 39 49" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6fae9440-224c-4fb4-853b-7c6395b12e7e">

## CNN의 발전 방향 - Pseudo Labeling
<img width="378" alt="스크린샷 2023-07-01 오후 6 40 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/67226e2b-936c-4eb8-b1d3-e6291c0b9bff">

1. Labeled Data로 Model을 먼저 학습시킨다.
2. 그렇게 학습된 모델을 사용하여, Unlabeled data를 예측하고 그 결과를 Label로 사용하는 pseudo-labeled data를 만든다.
3. Pseudo-labeled data와 Labeled data를 모두 사용하여 다시 그 모델을 학습시킨다.

- Pseudo-labeled data는?
  - 각 샘플에 대하여, 예측된 확률이 가장 높은것.
  - <img width="195" alt="스크린샷 2023-07-01 오후 6 42 18" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d35486c1-d6bb-4f3d-874c-df965dc79e4c">
- 단점
  - 예측된 확률이 가장 높은 것을 label로 선정한다고 했을때, 제대로 학습을 마치지 못한 모델로 하였을 경우, 모델의 학습을 저해하는 데이터를 만들뿐
- 이 두개의 작업을 따로 하는 것이 아닌 동시에 적용하여야 한다.

- Pseudo-labeling의 손실함수
  - 다음과 같이 원래학습과 Pseudo-labeling된 데이터의 학습을 동시에 진행한다.<img width="339" alt="스크린샷 2023-07-01 오후 6 46 29" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d4cc183a-8a20-448a-93f2-436f95a0e3cb">
    - n : labeled data의 배치 사이즈
    - $f_i^m$ : m번째 labeled data 샘플을 input으로 넣은 모델의 output
    - $y_i^m$ : 위의 input에 매칭되는 label
    - n' : unlabeled data의 배치 사이즈
    - $f_i^{'m}$ : m번째 unlabeled data 샘플을 input으로 넣은 모델의 output
    - $y_i^{'m}$ : 위의 unlabeled input에 매칭되는 현재의 Pseudo-label
    - $\alpha (t)$ : 두식을 balancing하는 coefficient -> 매우중요
- Pseudo labeling 이 작동하는 이유?
  - 모델의 분류과정에서 decision boundary를 결정할 때, 그 경계를 구분하는 지점의 데이터가 몰려있는 밀도가 낮으면 낮을수록, 더 미세한 차이점도 구별한다고 생각할 수 있기 때문에, 전체적인 성능을 높일 수 있다! 
  - :다른 semi-supervised learning방법에서도 통용되는 장점
  - Entropy 정형화(regularization) 효과

## CNN의 발전 방향 - Meta Pseudo Labels (2021)
<img width="553" alt="스크린샷 2023-07-01 오후 7 05 26" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c8105655-441c-4d59-b52f-ca06204f3d5d">

- Meta Pseudo Labels는 teacher와 student를 동시에 학습!
  - 이때, student의 labeled data에 대한 performance가 teacher에 학습에 영향을 준다! (일종의 reward signal)
 
  <img width="553" alt="스크린샷 2023-07-01 오후 7 07 13" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/369ca03a-0ae9-45df-8408-b0b205e95691">

  1. Teacher의 x결과로 Pseudo-label($q_\psi$(x))을 만들고 student에게 주고 student의 weight를 supervised learning(cross entropy)로 업데이트 한다.
  2. student의 validation loss 를 재사용하여, teacher의 weight역시 업데이트한다.<img width="400" alt="스크린샷 2023-07-01 오후 7 13 04" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/43ef118a-f074-478a-879c-50758ef43f8d">
  3. 부가적으로 UDA(unsupervied data augmentation for consistency training)에서 제안된, UDA objective을 조금 더해 보완하여 완성

- Noisy student보다 나은 성능
  
<img width="261" alt="스크린샷 2023-07-01 오후 7 15 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b744c28c-0884-453a-ae0a-fecfe4d3e956">

<img width="288" alt="스크린샷 2023-07-01 오후 7 16 07" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/2ca54bfa-b577-42eb-ad75-37f8c4df11e3">


## CNN의 발전 방향 - EfficientNet (2018-2019)
<img width="248" alt="스크린샷 2023-06-30 오후 7 26 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/9d05f39c-d335-44a4-9d2c-3fdeb3d8ef73">
- 모델이 항상 깊은 게 좋은 것이 아니다 ! 
- 적절한 깊이의 튜닝을 잘하면 모델 성능이 충분히 나오고 SOTA에 근접하다!
- 발견 및 실험: AutoML(Hyper Parameter Optimization; HPO)를 도입하여 search space내에서 최적의 값을 찾음

![image](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fdca6bfb-2e6b-41b2-bd88-a6dabb789337)

<img width="618" alt="스크린샷 2023-06-30 오후 7 28 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6c387ba8-0399-40a2-8d64-c0b3dd43c745">

- 모델의 Scaling에 대해 여러가지 관점으로 실험 & 분석
- 80% 까지는 Top1 Acc. 가 상승하지만, 
- 특히 depth의 경우 그 이후에는 saturation된다. 

<img width="280" alt="스크린샷 2023-06-30 오후 7 29 13" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bba79577-ecc1-439a-a43a-95f3d11d627c">

- Depth와 Resolution을 고정하고, width만 조절하여 성능 그래프를 보면…
- “Resolution”을 scaling하는 것이 ”Depth”보다 영향을 크게 준다는 것을 파악할 수 있다!

-  ResNet, DenseNet보다 빠르고, 가볍고 성능이 좋다
    - 참고: FLOPS: Floating point operations per seconds로 속도의 지표.
      
<img width="362" alt="스크린샷 2023-06-30 오후 7 30 06" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/49e2f836-1cd0-4850-b7fb-34a08d03e2e5">

<img width="356" alt="스크린샷 2023-06-30 오후 7 32 09" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bf14fab8-3db2-4f09-b5d4-4d7af1c2317d">

## CNN의 발전 방향 - self-training(자가 학습 기법)과 Data augmentation (2019)
- EfficientNet이 등장한 이후, 발전 방향은 모델 보다, 데이터나 학습 과정을 개선하는 것으로 트랜드가 바뀌었다.
- 2019년 SOTA였던, Touvron, Hugo, et al. "Fixing the train-test resolution discrepancy." arXiv preprint arXiv:1906.06423 (2019)은, 
- EfficientNet의 data augmentation기법에 맞춰 train/test에 사용하는 augmentation을 할때에 맞춰 모델의 scaling을 개선한 방법이었다!

<img width="364" alt="스크린샷 2023-06-30 오후 7 33 55" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/e6950112-72d8-42bf-980f-1e9540a216d3">
