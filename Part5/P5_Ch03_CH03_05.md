## CH03_05-Regularization-Early-stopping

### Early Stopping (수치 최적화(numerical optimization)에 따른 정형화)

- 큰모델을 학습할 때,  Train error는 학습이 진행되면서 점점 내려가지만, Validation error는 감소하다가 어느 순간부터 다시 증가한다.
    - 이때 멈춘다면, 최적의 결과를 얻을 수 있지 않을까?
    - → Early Stopping
    ![Untitled (12)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b38d6a77-ce23-426c-9e3e-3488567bb8bb)

    
- Early Stopping은 사실 L2정형화와 같다.
    - w*로 가기전, $\tilde{w}$에서 멈춰라!
    
    ![Untitled (13)](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ddff68d0-8af8-4dd7-8bee-3a83cbc3e0db)

- Early Stopping은 모델을 한번만 학습하면 되는 반면, L2을 위한 weight decay는 적절한 hyperparameter값을 찾기 위해 여러번 학습을 돌려야한다.
- 사람마다 선호하는 방법이 다르기 때문에 사용하면서 선택한다.
