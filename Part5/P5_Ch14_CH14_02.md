# Deep Metric Learning - 2. Deep Metric Learning의 종류
## Metric learning의 구분 (task에 따라)

Pair-wise loss
- (positive) D(f(A), f(Aʼ)) << 0, (negative) D(f(A), f(B)) >> 0
  - 전통적인 방식: Contrastive loss (binary) 
  - 발전된 방식: NCE loss, InfoNCE loss 등 
  - Multi-class
- Softmax (LogSumExp) 기반: A-softmax, Large margin cosine loss 등

Triplet loss
- f(A), f(Aʼ), f(B) 동시에 받아 계산, D(f(A), f(Aʼ)) < D(f(A), f(B))
  - 전통적인 방식: Triplet loss (binary)
  - Multi-class / continuous class
    - N-pairs loss: triplet loss를 일반화하여 multiple negative sample로 확장
      
    - Log-ratio loss: triplet loss를 기반으로 regression, continuous label로 적용 가능하게 확장

Instance-level discrimination
- class를 인위적으로 생성하는 것이 아닌, instance를 기반으로 학습
  
<img width="350" alt="스크린샷 2023-08-24 오후 6 05 05" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/c4bc1fc7-c5c6-4f51-b901-050ee0861140">
<img width="350" alt="스크린샷 2023-08-24 오후 6 05 31" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/5879505c-79bc-4cea-8db5-defb4c8cd34b">

## Contrastive loss
- 데이터쌍(pair) $𝑥_i, 𝑥_j$ ~𝑋가주어졌을때, positive, negative pair로 묶는다.
  - Positive: $𝑦_{ij}$ = 1
  - Negative: $𝑦_{ij}$ = 0
      
이때 loss는 아래와 같다.
<img width="450" alt="스크린샷 2023-08-27 오후 4 30 40" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4c894d9d-d435-4fcd-9966-798ef0f8ca0a">

일반적으로, $𝑑 (𝑥_i,𝑥_j) = ||𝑓 (𝑥_i) −𝑓 (𝑥_j)||^2_2$ 이다.(Euclideanmetric)  
같은 쌍(pos. pair)은 거리가 0이 되도록, 다른 쌍(neg pair)은 거리가 margin(𝛼) 이 되도록! 

<img width="429" alt="스크린샷 2023-08-27 오후 4 33 09" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/ab12c171-3077-4714-9b71-acdcc83769a0">

## Contrastive loss - 장단점
- 장점: 적용하기 쉽다. (self-supervised learning의 task로 자주 이용! ->contrastive learning)
- 단점:
  - Margin parameter (alpha)를 설정하기 어렵다!
  - negative sample간 차이를 반영하지 못하고, 동일한 margin으로만 차이가 난다.
 
## Noise contrastive estimation (NCE) loss - in word embedding (2013)
<img width="500" alt="스크린샷 2023-08-27 오후 4 35 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/13215b77-ed24-4658-b9fb-60a03b51b84a">

전체 softmax 분류하면 너무 비싸다 -> 일치하는 것과 아닌 것만 binary classification로 비교하자!

<img width="380" alt="스크린샷 2023-08-27 오후 4 36 22" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f12f9a5a-70dc-4153-add1-448bac853777">

실제 값로 부터 대조되는 단어를 noise distribution $𝑃_{noise}$ 으로 부터 sampling하여 Monte-Carlo 평균을 구한다.

## InfoNCE loss - In contrastive predictive coding (CPC) (2018)
- 참고: CPC는 Auto-regressive 모델에서 정의되어, time 이 고려됨!

<img width="500" alt="스크린샷 2023-08-27 오후 4 38 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/66c161ee-2ce1-4ddf-b7b0-4a18a9ef5e05">

- Input feature x와 context c 가 존재할 때, 둘 사이의 mutual information은

<img width="300" alt="스크린샷 2023-08-27 오후 4 39 42" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/97b8150b-639e-4765-8699-87c4e5bbc4e8">
와 같다. 즉, $log {{p(x|c)}\over{p(x)}}$ density ratio에 비례한다!

- Generative model의 $𝑝(𝑥_{t+k}|𝑐_t)$ 에서,미래의 관찰값인 $x_{t+k}$ 을 직접 생성하는 것이 아닌, $x_{t+k}, c_t$ 관계 density ratio( $f(x_{t+k}, c_t) ∝ {{p(x_{t+k}|c_t)}\over{p(x_{t+k})}}$ 을 모델링 하자
  - Positive sample 1개를 $𝑝(𝑥_{t+k}|𝑐_t)$ 에서 뽑고 negative sample을 distribution $𝑝(𝑥_{t+k},𝑐_t)$ 에서 N-1개를 뽑는다. (NCE loss) 이때 loss는 다음을 만족한다.
  
  <img width="350" alt="스크린샷 2023-08-27 오후 4 46 35" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/f08af19f-6140-45ef-857c-8312af7f6806">

- 이때 ,  $f(x_{t+k}, c_t) ∝ {{p(x_{t+k}|c_t)}\over{p(x_{t+k})}}$ 이므로, 이를 기반으로 loss를 최적화 해보면,

  <img width="500" alt="스크린샷 2023-08-27 오후 4 48 08" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7a0af585-7625-40ae-86cb-3f3597aa45e5"> 이다.

  - $𝐼(x_{t+k}, c_t) ≥ log 𝑁 − 𝐿^* $

- 즉, negative sample의 수가 올라가 log(N)이 커진다면,  $𝐼(x_{t+k}, c_t)$ 의 lower boundary을 높이게 된다.
  - Negative sample (batch size)이 늘어나면 성능이 좋아진다!
 
## Angular-softmax (A-Softmax) - In SphereFace (2017)
Softmax에 angular metric를 적용할 수 있을까?
- Softmax에서 고려하지 않는 class간 관련도를 알아낼 수 있고, 좀더 flexible할 수 있지 않을까?

<img width="450" alt="스크린샷 2023-08-27 오후 5 05 33" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/70fb2f6d-8ff5-4d9f-8726-e3dff2a2b1fe"> 
에서, weight vector ||w||=1로 고정하고 bias을 없애면, angular로만 결정하게 된다.
  
<img width="350" alt="스크린샷 2023-08-27 오후 5 10 39" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4a6a7ebf-d61e-47bf-80d0-022ac2d2e36e">

최종적으로 margin (𝑚)을 두어 각 class사이를 멀게 하자 <img width="450" alt="스크린샷 2023-08-27 오후 5 11 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bfcf570b-bb97-41d3-86eb-49c46eb37092">

## Large Margin Cosine Loss (LMCL) - In CosFace, Additive margin softmax (2018)
<img width="300" alt="스크린샷 2023-08-27 오후 5 15 47" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b8416670-ec5e-467a-b93e-079031f944f5">

<img width="300" alt="스크린샷 2023-08-27 오후 5 15 16" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b995d3c6-f3df-49cf-9def-c5c0fa5c79ea">

- Additive Margin Softmax라고도 한다. (동기간에 나왔다)
- Angular-softmax에서 margin을 angular에 multiplier로 두는 것이 아닌, cos function 밖에 addictive하게 정의

  <img width="500" alt="스크린샷 2023-08-27 오후 5 14 56" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b1b9aa1e-20c3-431b-8632-0230ba46ae72">

## Addictive Angular Margin Loss과 Generalized form - In ArcFace (2019)
Angular-softmax에서 margin을 angular에 multiplier로 두는 것이 아닌, addictive하게 정의!
<img width="315" alt="스크린샷 2023-08-27 오후 5 18 33" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/cf50d92e-9393-4393-b582-93124d6f95ea">


<img width="500" alt="스크린샷 2023-08-27 오후 5 17 43" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/dc714bf0-7515-418c-a8f4-c1bde50b173b">

셋을 하나로 합쳐 일반화하면,
<img width="500" alt="스크린샷 2023-08-27 오후 5 18 12" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/7ba5fb54-c368-4fb4-89aa-b2ff6fc6c238">

## Triplet loss - In FaceNet (2015)
- Contrastive loss가 절대적 거리(margin)을 고려한다면, triplet loss는 상대적 거리를 학습한다!
- 데이터 𝑥 ∈ 𝑋 를 anchor라 하면, 관련된 positive sample( $𝑥^+$ )과 negative sample( $x^-$ )을 만들어 학습한다.

  <img width="400" alt="스크린샷 2023-08-27 오후 5 20 54" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6df2fa05-b001-462b-968b-dbcaef00f7bc">
  - Anchor-pos와의 거리는 최소화하고, anchor-neg 와의 거리는 최대화

- 일반적으로, $𝑑 (𝑥_i,𝑥_j) = ||𝑓 (𝑥_i) −𝑓 (𝑥_j)||^2_2$ (Euclidean distance) 이고 𝛼는 margin이다.
- 보통의 경우, $𝑥^+$ 는, 𝑥에서 positive sampling (i.e. data augmentation) 하여 얻고, $x^-$ 는 negative sampling 을 하여 얻는다.

## Triplet loss의 종류
<img width="400" alt="스크린샷 2023-08-27 오후 5 22 58" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/816f3c0e-7ae0-4b6b-8cf0-cb7e39db399c">

- Negative sampling의 방법에 따라 Easy, semi-hard, hard triplet로 나눈다!
  - Easy Triplet: anchor와 negative sampling거리가 먼 경우
    - $𝑑 (𝑥, 𝑥^+)^2 + 𝛼 < 𝑑 (𝑥, 𝑥^-)^2$ 인 negative sampling을 사용시.
    - Anchor와 완전히 다른 샘플을 찾기는 쉬우나, 유사한 샘플을 찾기는 어렵다.
  - Hard Triplet: anchor와 negative sampling의 거리가 짧은 경우 
    - $𝑑 (𝑥, 𝑥^-)^2 + 𝛼 < 𝑑 (𝑥, 𝑥^+)^2$ 인 negative sampling을 사용시.
    - 학습에 매우 중요한 batch를 구성(찾기) 매우 어렵다.
  - Semi-hard Triplet
    - $𝑑 (𝑥, 𝑥^+)^2 + 𝛼 < 𝑑 (𝑥, 𝑥^-)^2 < < 𝑑 (𝑥, 𝑥^+)^2 + 𝛼$ 인 negative sampling을 사용시.
    - 학습에 중요하면서 batch를 구성하기 상대적으로 쉽다.

      <img width="193" alt="스크린샷 2023-08-27 오후 5 35 11" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/bd41d744-4b7c-4d7d-890f-3616e37ee315">

## N-pair loss (2016)
- Triplet 구조를 일반화하여 (N+1)-Tuplet을 이용!
  - 1 anchor, 1 positive, (N-1) negative
  - N=2인 경우, triplet과 동일한 형태이다.

  <img width="380" alt="스크린샷 2023-08-27 오후 5 36 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/873e502a-37e3-4f51-a503-292ea2d70cae">

- f가 DNN을 통해 얻는 feature일때, loss는 아래와 같다

  <img width="400" alt="스크린샷 2023-08-27 오후 5 37 02" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6b933967-658a-40a0-b3c2-dd43a271bdf8">

## N-pair loss (2016) - N-pair-mc loss
<img width="500" alt="스크린샷 2023-08-27 오후 5 45 41" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b33653b7-bab6-4107-90cc-93fd57736418">

빠른 학습을 위해 pair를 generation을 좀더 최적화 하고 loss를 개선할 수 있다

<img width="380" alt="스크린샷 2023-08-27 오후 5 46 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4a61b64a-b8ee-4963-b843-c5d2c9473bfc">

## Log-ratio loss (2019)
<img width="350" alt="스크린샷 2023-08-27 오후 5 47 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d7b2cbb5-8cc5-4ee9-857d-39a2af61212f">

<img width="318" alt="스크린샷 2023-08-27 오후 5 48 33" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6d256470-d7c1-4d4c-b40a-614e6be8baf4">

- Positive, negative sampling 구분 없이, $𝒙_{𝒊,𝒑}, 𝒙_{𝒊,𝒏}$ 은 중복만 피해서 뽑는다!  
- Label의 경우, $𝒚_𝒊, 𝒚_{𝒊,𝒑}, 𝒚_{𝒊,𝒏}$ 의 continuous label을 loss term에 반영하여 ratio of label distance가 근사 되게 한다!  
- Dense triplet mining: (($𝑥_i$ , 𝑝, 𝑛)과 ($𝑥_i$ , 𝑛, 𝑝) 는 바뀌어도 관계 X)

  <img width="350" alt="스크린샷 2023-08-27 오후 5 50 06" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6440cc89-bb36-496d-b6a9-49eeded0e6a8">

## Non-parametric instance discrimination (2018)
<img width="500" alt="스크린샷 2023-08-27 오후 5 51 30" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b7856e07-9a63-4de6-ad93-88bac5c2e392">

- Class를 label로 나누는 것이 아닌, instance를 classification하여 representation을 얻어낸다.
- Softmax classifier의 $w_i^T v$ 를 L2 normalization layer로 $v_i^T v$ = 1 을 만족하게 하여 변환

  <img width="470" alt="스크린샷 2023-08-27 오후 5 52 51" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1c817615-4965-4adf-a52b-bfe487c07fa6">

- 𝜏 는 temperature parameter이고, 𝑉 = { $𝑣_j$ } 를 memory bank라고 하고, $𝑓_i = 𝑓_\theta (x_i)$ 를 $𝑥_i$ 의 feature로 정의
- $𝑓_i -> v_i$ 로 업데이트 된다
- 참고: N 이 너무 크면, cost가 너무 든다!
  - 결국 Noise contrastive estimation사용하여 연산을 줄임
