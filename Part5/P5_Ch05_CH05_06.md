# 합성곱 신경망(CNN0 - 6 모델학습과정의 병렬성(parallelism)

## 큰 신경망의 학습
- 모델의 object class 카테고리가 증가하거나, 파라미터가 증가하거나, 데이터 사이즈가 증가하면 메모리 비용과 학습에
걸리는 시간이 기하급수적으로 증가할 수 있다 !
  - Parallelism (병렬) 전략을 취할 수 있다!
  - 크게  model, data parallelism 으로 나눈다.
    
<img width="373" alt="스크린샷 2023-07-03 오후 7 20 29" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fa737688-a74a-44de-b0f4-bd662cda40b0">

## Data Parallelization
<img width="144" alt="스크린샷 2023-07-03 오후 7 21 03" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/25fb7a03-40cd-425c-b1e2-c7b04d5030bb">

- Data Parallelism
	- 각 프로세스 머신에, 완전히 각 모델들을 복사한다.
	- 학습데이터를 여러 개의 프로세서에 분산처리한다. 
	- 각 결과를 합치고(aggregation), 모델 파라미터 업데이트를 각 worker별로 synchronizing하여야 한다.
	- 쉽게 적용해 볼 수 있는 방법!

- 동기적 학습 vs 비동기적 학습
  - 동기적 학습: all-reduce 구조에 의해 support되고, gradient 가 각 step마다 동기화 되고 aggregation된다. : 가장 일반적인 방법.
  - 비동기적 학습: parameter server 구조에 의해 support된다 : 각 worker가 독립적으로 학습하고 파라미터들은 비동기적으로 
업데이트된다.

## Data Parallelization- Synchronous method
![image](https://github.com/joony0512/Deep_Learning_Class/assets/109457820/fae21b76-a811-446a-8c84-6ce41bc2818b)

- All-reduce 방법 혹은 중앙 계산 프로세스를 두어 업데이트 한다.

- Pytorch
  - Data Parallel (DP) (마스터 GPU Worker에서 관리)
  - Data Distributed Parallel (DDP) (all reduce; nvidia/nccl 활용)

- Tensorflow
  - Mirrored
    - Collective ops: nvidia/nccl
    - 디바이스당 모델 instance가 떠있다.

  - Multi Worker Mirrored  (Pytorch DDP와 가장 유사)
    - Collective ops: nvidia/nccl + grpc
    - 디바이스당, 프로세스당 모델 instance가 떠있다.

  - Central storage strategy (CPU에서 관리)

## Data Parallelization - Centralized parameter aggregating (Data Parallel, Central storage strategy )
<img width="850" alt="스크린샷 2023-07-03 오후 7 26 01" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/d94f45fe-93db-4040-97f2-7ecf91d3a68a">

## Data Parallelization - All-reduce 사용.
<img width="983" alt="스크린샷 2023-07-03 오후 8 03 48" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/1455c4c6-53c2-4912-9988-3983ad3ca58c">

## Data Parallelization - Async Training: Centralized parameter aggregating
- 각 worker에 현재 모델을 복사한다.
- 데이터의 subset을 각 worker가 분산해 학습하게 하고,parameter server 등에서 결과를 aggregation하여 반영한다.

-  Network communication과 synchronization costs를 신경 써야 한다.
  - 이때, 비용이 비싸다는 이유로, synchronizing update를 늦게 하면 곤란하다.
	- Why?
		- N개의 다른 local minima를 평균 내면 local minima를 그대로 찾는다는 보장이 없다!
  - 비동기적인 구현: aggregation시, 각 worker별로 weight (lambda)를 두어, 시간대 별로 weighted update를 실행한다.	

- Tensoflow Parameter server strategy 
  - 몇 대의 장비는 worker 역할을 하고, 몇 대는 파라미터 서버 역할을 하여 비동기적으로 통신
 
## Data Parallelization - Decentralized SGD 
- 중앙 파라미터 계산 서버가 시스템 상에 존재하지 않는다. 대신, peer-to-peer 통신을 하여 worker간 모델 업데이트를 진행한다.

<img width="216" alt="스크린샷 2023-07-03 오후 8 06 15" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/6345e369-4302-4467-89e2-f7467ca343b2">

## Model Parallelization - Naive Model Parallel (Vertical) and Pipeline Parallel
- Naive Model Parallel (MP)는 모델 layer를 여러개의 gpu에 뿌린다.
  - 그러나, gpu메모리를 제외한, 나머지 연산은 최적화가 불가능하다. (각 레이어가 계산되는 것을 기다려야 한다.)

- Pipeline Parallel (PP):
	- 데이터를 여러개의 배치를 더 작은 미니배치(chunk)로 쪼개고 파이프라인을 구성하여 학습!
	- 동시 학습이 어느정도 가능하지만, Bubble(학습 공백)이 발생!

- Interleaved pipeline:
	- Forward step과 back propagation step을 나누고 처리 순서를 보다 최적화!
	- AWS SageMaker, MS Deep Speed 등에서 제공
   
<img width="430" alt="스크린샷 2023-07-03 오후 8 08 14" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/194f4698-9640-40bd-a939-1531454b77ad">

   
## Model Parallelization - Tensor parallelism
<img width="295" alt="스크린샷 2023-07-03 오후 8 08 55" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/4a267f61-4c79-423b-8d07-6da87d80425a">

- Tensor matrix연산에서, 나눌 수 있는 것을 나누어 multi-gpu에 분산 처리.
- Tensor slicing이라고도 부른다.

## Model Parallelization - ZeRO
- 사실 Model Parallelism(MP)을 통해 큰 모델을 학습시키는 것은 굉장히 힘들다! 
  - 1 Trillion 파라미터 를 가지는 모델을 학습시킨다 해보자. 한 노드에 20 Billion씩 학습이 가능할 때 50노드가 필요하고 노드 당 16GPU라면 800-way parallelism이 된다.

- 메모리는 대부분 아래와 같은 요인 (OGP)으로 인해 낭비됨.
  - optimizer states (momentum etc.)
  - gradients
  - parameters

- ZeRO: Optimization Stage를 세 단계(OGP)로 나누고, DP이되 gpu마다 tensor partitioning하여 해결한다.
  - Partitioning Optimizer States
  - Partitioning Gradients
  - Partitioning Parameters

- 왜 잘될까?
  - Data parallelism(DP)은 scaling efficiency가 더 좋다. 한편 model parallelism은 computing을 복잡하게 만들면서 communication overhead를 늘린다. 
  - DP는 model states를 전부 다 저장하기 때문에 memory inefficient하다. 반면에, Model Parallelism은 Memory Efficient하다.
  - MP와 DP는 Model States를 training time동안 전부 저장한다. 하지만 계속해서 매 시간마다 필요한 것은 아니다.
    - OGP를 replication하는게 아닌 partitioning한다!

- ZeRO에서 Optimizer States만 최적화한 것을 ZeRO-OS라 부른다.
<img width="675" alt="스크린샷 2023-07-03 오후 8 11 42" src="https://github.com/joony0512/Deep_Learning_Class/assets/109457820/b452a9c6-7f0a-436a-b388-7f3eb5793d5b">

## Parallelism Libraries
- MS Deep Speed, Pytorch Fair Scale, Horovod

